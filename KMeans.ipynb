{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import pandas as pd\r\n",
                "import glob\r\n",
                "import os\r\n",
                "import json\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "from kneed import KneeLocator\r\n",
                "from sklearn.cluster import KMeans\r\n",
                "from scipy.spatial.distance import cdist\r\n",
                "from sklearn import metrics\r\n",
                "from tqdm import tqdm\r\n",
                "from scipy.spatial.distance import cdist\r\n",
                "import numpy as np\r\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "def cluster_data(df):\r\n",
                "    processed_articles = count_articles(df)\r\n",
                "    tfidf, words = convert_to_tfidf(processed_articles)\r\n",
                "    all_kmeans_models, common_words, mapping1, mapping2, K, distortions = calculate_kMeans(tfidf, words)\r\n",
                "    knee = calculate_knee(K, distortions)\r\n",
                "    cluster_words_list, df = gather_top_words(all_kmeans_models, knee, words, df)\r\n",
                "    df = assign_top_words(cluster_words_list, df)\r\n",
                "    df = date_month_publish(df)\r\n",
                "    create_cluster_files(df)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Load JSON Files into Pandas Dataframe"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "def count_articles(df):\r\n",
                "    amount_of_articles = len(df[\"filtered_maintext\"])\r\n",
                "    #print(f\"Amount of articles: {amount_of_articles}\")\r\n",
                "    processed_articles = df['filtered_maintext']\r\n",
                "    return processed_articles"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "def convert_to_tfidf(processed_articles):\r\n",
                "    tfidfconverter = TfidfVectorizer(lowercase=True, stop_words='english', min_df=0.05 , max_df=0.6)  \r\n",
                "    tfidf = tfidfconverter.fit_transform(processed_articles)\r\n",
                "    words = tfidfconverter.get_feature_names()\r\n",
                "    return tfidf, words"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "from sklearn.metrics.pairwise import cosine_distances\r\n",
                "\r\n",
                "#cosine_similarity = cosine_distances(tfidf)\r\n",
                "#cosine_similarity"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "from sklearn.cluster import AffinityPropagation"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "'''\r\n",
                "clustering = AffinityPropagation(convergence_iter=5, affinity='precomputed', random_state=10)\r\n",
                "clustering.fit(cosine_similarity)\r\n",
                "labels = clustering.labels_\r\n",
                "print(labels.dtype)\r\n",
                "#cluster_centers = clustering.cluster_centers_\r\n",
                "cluster_centers_indices = clustering.cluster_centers_indices_\r\n",
                "n_clusters_ = len(cluster_centers_indices)\r\n",
                "print(n_clusters_)'''"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "\"\\nclustering = AffinityPropagation(convergence_iter=5, affinity='precomputed', random_state=10)\\nclustering.fit(cosine_similarity)\\nlabels = clustering.labels_\\nprint(labels.dtype)\\n#cluster_centers = clustering.cluster_centers_\\ncluster_centers_indices = clustering.cluster_centers_indices_\\nn_clusters_ = len(cluster_centers_indices)\\nprint(n_clusters_)\""
                        ]
                    },
                    "metadata": {},
                    "execution_count": 7
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "'''\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "from itertools import cycle\r\n",
                "\r\n",
                "plt.close('all')\r\n",
                "plt.figure(1)\r\n",
                "plt.clf()\r\n",
                "\r\n",
                "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\r\n",
                "for k, col in zip(range(n_clusters_), colors):\r\n",
                "    class_members = labels == k\r\n",
                "    cluster_center = cosine_similarity[cluster_centers_indices[k]]\r\n",
                "    plt.plot(cosine_similarity[class_members, 0], cosine_similarity[class_members, 1], col + '.')\r\n",
                "    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\r\n",
                "             markeredgecolor='k', markersize=14)\r\n",
                "    for x in cosine_similarity[class_members]:\r\n",
                "        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\r\n",
                "\r\n",
                "plt.title('Estimated number of clusters: %d' % n_clusters_)\r\n",
                "plt.show()'''"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "\"\\nimport matplotlib.pyplot as plt\\nfrom itertools import cycle\\n\\nplt.close('all')\\nplt.figure(1)\\nplt.clf()\\n\\ncolors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\\nfor k, col in zip(range(n_clusters_), colors):\\n    class_members = labels == k\\n    cluster_center = cosine_similarity[cluster_centers_indices[k]]\\n    plt.plot(cosine_similarity[class_members, 0], cosine_similarity[class_members, 1], col + '.')\\n    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\\n             markeredgecolor='k', markersize=14)\\n    for x in cosine_similarity[class_members]:\\n        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\\n\\nplt.title('Estimated number of clusters: %d' % n_clusters_)\\nplt.show()\""
                        ]
                    },
                    "metadata": {},
                    "execution_count": 8
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "'''\r\n",
                "df['processed_articles'] = processed_articles\r\n",
                "df['affpropID'] = clustering.labels_'''\r\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "\"\\ndf['processed_articles'] = processed_articles\\ndf['affpropID'] = clustering.labels_\""
                        ]
                    },
                    "metadata": {},
                    "execution_count": 9
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "#df.head()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "def calculate_kMeans(tfidf, words):\r\n",
                "    max_clusters = 10\r\n",
                "    distortions = []\r\n",
                "    inertias = []\r\n",
                "    mapping1 = {}\r\n",
                "    mapping2 = {}\r\n",
                "\r\n",
                "    last_distortion = 0\r\n",
                "\r\n",
                "    all_kmeans_models = []\r\n",
                "\r\n",
                "    K = range(2,max_clusters)\r\n",
                "    X = np.matrix(tfidf.toarray())\r\n",
                "    for i in tqdm(K):\r\n",
                "        #print(\"Iteration: \" + str(i))\r\n",
                "        kMeans = KMeans(n_clusters=i, max_iter=400).fit(tfidf)\r\n",
                "        kMeans.predict(tfidf)\r\n",
                "        labels = kMeans.labels_\r\n",
                "        cluster_centers = kMeans.cluster_centers_\r\n",
                "        inertias.append(kMeans.inertia_)\r\n",
                "        distortions.append(sum(np.min(cdist(X, cluster_centers, 'euclidean'), axis=1)) / X.shape[0])\r\n",
                "\r\n",
                "        this_silhouette = metrics.silhouette_score(tfidf.toarray(), labels, metric='sqeuclidean')\r\n",
                "\r\n",
                "        #print(\"Silhouette Score: \" + str(this_silhouette))\r\n",
                "\r\n",
                "        mapping1[i] =  sum(np.min(cdist(X, cluster_centers, 'euclidean'), axis=1)) / X.shape[0]\r\n",
                "        mapping2[i] = kMeans.inertia_\r\n",
                "\r\n",
                "        all_kmeans_models.append(kMeans)\r\n",
                "\r\n",
                "        common_words = kMeans.cluster_centers_.argsort()[:,-1:-11:-1]\r\n",
                "        #for num, centroid in enumerate(common_words):\r\n",
                "            #print(str(num) + ' : ' + ', '.join(words[word] for word in centroid))\r\n",
                "    return all_kmeans_models, common_words, mapping1, mapping2, K, distortions"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "def calculate_knee(K, distortions):\r\n",
                "    #print(\"The elbow point of the curve is: \")\r\n",
                "    #print('K: ',len(K))\r\n",
                "    #print('dis: ', len(distortions))\r\n",
                "    kneedle = KneeLocator(K, distortions, S=1.0, curve=\"convex\", direction=\"decreasing\")\r\n",
                "    #print(kneedle.knee_y)\r\n",
                "    kneedle.plot_knee()\r\n",
                "    return kneedle.knee"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "#plt.plot(K, inertias, 'bx-')\r\n",
                "#plt.xlabel('Values of K')\r\n",
                "#plt.ylabel('Inertia')\r\n",
                "#plt.title('The Elbow Method using Inertia')\r\n",
                "#plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "#plt.plot(K, distortions, 'bx-')\r\n",
                "#plt.xlabel('Values of K')\r\n",
                "#plt.ylabel('Distortion')\r\n",
                "#plt.title('The Elbow Method using Distortion')\r\n",
                "#plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "def gather_top_words(all_kmeans_models, knee, words, df):\r\n",
                "    # save the clusterIDs to the dataframe\r\n",
                "    # minus 2 because we start checking with 2 clusters\r\n",
                "    df[\"kMeans_ID\"] = all_kmeans_models[knee-2].labels_\r\n",
                "    cluster_words_list = []\r\n",
                "    common_words = all_kmeans_models[knee-2].cluster_centers_.argsort()[:,-1:-11:-1]\r\n",
                "    for num, centroid in enumerate(common_words):\r\n",
                "        cluster_words = []\r\n",
                "        for word in centroid:\r\n",
                "            cluster_words.append(words[word])\r\n",
                "        cluster_words_list.append(cluster_words)\r\n",
                "    return cluster_words_list, df"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "def assign_top_words(cluster_words_list, df):\r\n",
                "    row_words = []\r\n",
                "    for index, row in df.iterrows():\r\n",
                "        cluster = row.kMeans_ID\r\n",
                "        row_words.append(cluster_words_list[cluster])\r\n",
                "    df['kMeans_words'] = row_words\r\n",
                "    return df\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Subcluster by release date\r\n",
                "\r\n",
                "We will determine each articles release date and sort them into individual json files."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "def getMonthYear(s):\r\n",
                "     return s.split('-')[0]+\"-\"+s.split('-')[1]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Generating folder structure\r\n",
                "\r\n",
                "The following code creates the desired folder hierarchy and names each cluster after the top 3 dominant words in each one. Within each cluster/folder we are subclustering all articles by their release date.\r\n",
                "The output json file has the format *year-month.json*. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "def date_month_publish(df):\r\n",
                "    df['date_publish'] = pd.to_datetime(df['date_publish'])\r\n",
                "    df['month_year'] = df['date_publish'].apply(lambda x: getMonthYear(str(x)))\r\n",
                "    return df"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "def create_cluster_files(df):\r\n",
                "    for cluster_id, data in df.groupby(df.kMeans_ID):\r\n",
                "        item = data.kMeans_words.tolist()\r\n",
                "        item = item[0]\r\n",
                "        os.makedirs(f'./event_clustered_json/cluster_{cluster_id}-{item[0]}_{item[1]}_{item[2]}')\r\n",
                "        for date, date_data in data.groupby(data.month_year):\r\n",
                "            json_data = date_data.to_json(orient='records', force_ascii=False, date_format='iso', date_unit='s')\r\n",
                "            parsed = json.loads(json_data)\r\n",
                "            with open(f'./event_clustered_json/cluster_{cluster_id}-{item[0]}_{item[1]}_{item[2]}/{date}.json', 'w', encoding='utf-8') as f:\r\n",
                "                f.write(json.dumps({\"data\": parsed}, indent=4, ensure_ascii=False))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "source": [
                "#filename = 'cluster_20-trump_ president_ king.json'\r\n",
                "path = 'lda_clustered_json/'\r\n",
                "\r\n",
                "for filename in tqdm(glob.glob(os.path.join(path, '*.json'))):\r\n",
                "    with open(filename, encoding='utf-8', mode='r') as currentFile:\r\n",
                "        df = pd.read_json(currentFile, orient='index')\r\n",
                "        cluster_data(df)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "100%|██████████| 8/8 [01:40<00:00, 12.51s/it]\n",
                        "100%|██████████| 8/8 [02:02<00:00, 15.36s/it]\n",
                        " 18%|█▊        | 2/11 [03:55<17:56, 119.57s/it]"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.11",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.11 64-bit ('kcc': conda)"
        },
        "interpreter": {
            "hash": "21ab713a94b9dff8ceab4d966c04cbd434fb99e8b3685c982045bb942eef746a"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}