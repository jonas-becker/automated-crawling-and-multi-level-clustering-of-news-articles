{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import pandas as pd\r\n",
                "import glob\r\n",
                "import os\r\n",
                "import json\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "from kneed import KneeLocator\r\n",
                "from sklearn.cluster import KMeans\r\n",
                "from scipy.spatial.distance import cdist\r\n",
                "from sklearn import metrics\r\n",
                "from tqdm import tqdm\r\n",
                "from scipy.spatial.distance import cdist\r\n",
                "import numpy as np\r\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "def cluster_data(df):\r\n",
                "    processed_articles, amount_of_articles = count_articles(df)\r\n",
                "    tfidf, words = convert_to_tfidf(processed_articles)\r\n",
                "    all_kmeans_models, common_words, mapping1, mapping2, K, distortions = calculate_kMeans(tfidf, words)\r\n",
                "    knee = calculate_knee(K, distortions)\r\n",
                "    cluster_words_list, df = gather_top_words(all_kmeans_models, knee, words, df)\r\n",
                "    df = assign_top_words(cluster_words_list, df)\r\n",
                "    df = date_month_publish(df)\r\n",
                "    create_cluster_files(df)\r\n",
                "    return amount_of_articles"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Load JSON Files into Pandas Dataframe"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "def count_articles(df):\r\n",
                "    amount_of_articles = len(df[\"filtered_maintext\"])\r\n",
                "    processed_articles = df['filtered_maintext']\r\n",
                "    return processed_articles, amount_of_articles"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "def convert_to_tfidf(processed_articles):\r\n",
                "    tfidfconverter = TfidfVectorizer(lowercase=True, stop_words='english', min_df=0.05 , max_df=0.6)  \r\n",
                "    tfidf = tfidfconverter.fit_transform(processed_articles)\r\n",
                "    words = tfidfconverter.get_feature_names()\r\n",
                "    return tfidf, words"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "from sklearn.metrics.pairwise import cosine_distances\r\n",
                "\r\n",
                "#cosine_similarity = cosine_distances(tfidf)\r\n",
                "#cosine_similarity"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "from sklearn.cluster import AffinityPropagation"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "'''\r\n",
                "clustering = AffinityPropagation(convergence_iter=5, affinity='precomputed', random_state=10)\r\n",
                "clustering.fit(cosine_similarity)\r\n",
                "labels = clustering.labels_\r\n",
                "print(labels.dtype)\r\n",
                "#cluster_centers = clustering.cluster_centers_\r\n",
                "cluster_centers_indices = clustering.cluster_centers_indices_\r\n",
                "n_clusters_ = len(cluster_centers_indices)\r\n",
                "print(n_clusters_)'''"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "\"\\nclustering = AffinityPropagation(convergence_iter=5, affinity='precomputed', random_state=10)\\nclustering.fit(cosine_similarity)\\nlabels = clustering.labels_\\nprint(labels.dtype)\\n#cluster_centers = clustering.cluster_centers_\\ncluster_centers_indices = clustering.cluster_centers_indices_\\nn_clusters_ = len(cluster_centers_indices)\\nprint(n_clusters_)\""
                        ]
                    },
                    "metadata": {},
                    "execution_count": 7
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "'''\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "from itertools import cycle\r\n",
                "\r\n",
                "plt.close('all')\r\n",
                "plt.figure(1)\r\n",
                "plt.clf()\r\n",
                "\r\n",
                "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\r\n",
                "for k, col in zip(range(n_clusters_), colors):\r\n",
                "    class_members = labels == k\r\n",
                "    cluster_center = cosine_similarity[cluster_centers_indices[k]]\r\n",
                "    plt.plot(cosine_similarity[class_members, 0], cosine_similarity[class_members, 1], col + '.')\r\n",
                "    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\r\n",
                "             markeredgecolor='k', markersize=14)\r\n",
                "    for x in cosine_similarity[class_members]:\r\n",
                "        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\r\n",
                "\r\n",
                "plt.title('Estimated number of clusters: %d' % n_clusters_)\r\n",
                "plt.show()'''"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "\"\\nimport matplotlib.pyplot as plt\\nfrom itertools import cycle\\n\\nplt.close('all')\\nplt.figure(1)\\nplt.clf()\\n\\ncolors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\\nfor k, col in zip(range(n_clusters_), colors):\\n    class_members = labels == k\\n    cluster_center = cosine_similarity[cluster_centers_indices[k]]\\n    plt.plot(cosine_similarity[class_members, 0], cosine_similarity[class_members, 1], col + '.')\\n    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\\n             markeredgecolor='k', markersize=14)\\n    for x in cosine_similarity[class_members]:\\n        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\\n\\nplt.title('Estimated number of clusters: %d' % n_clusters_)\\nplt.show()\""
                        ]
                    },
                    "metadata": {},
                    "execution_count": 8
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "'''\r\n",
                "df['processed_articles'] = processed_articles\r\n",
                "df['affpropID'] = clustering.labels_'''\r\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "\"\\ndf['processed_articles'] = processed_articles\\ndf['affpropID'] = clustering.labels_\""
                        ]
                    },
                    "metadata": {},
                    "execution_count": 9
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "#df.head()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "def calculate_kMeans(tfidf, words):\r\n",
                "    max_clusters = 10\r\n",
                "    distortions = []\r\n",
                "    inertias = []\r\n",
                "    mapping1 = {}\r\n",
                "    mapping2 = {}\r\n",
                "\r\n",
                "    last_distortion = 0\r\n",
                "\r\n",
                "    all_kmeans_models = []\r\n",
                "\r\n",
                "    K = range(2,max_clusters)\r\n",
                "    X = np.matrix(tfidf.toarray())\r\n",
                "    print(\"Generating the K-Means model...\")\r\n",
                "    for i in tqdm(K):\r\n",
                "        #print(\"Iteration: \" + str(i))\r\n",
                "        kMeans = KMeans(n_clusters=i, max_iter=400).fit(tfidf)\r\n",
                "        kMeans.predict(tfidf)\r\n",
                "        labels = kMeans.labels_\r\n",
                "        cluster_centers = kMeans.cluster_centers_\r\n",
                "        inertias.append(kMeans.inertia_)\r\n",
                "        distortions.append(sum(np.min(cdist(X, cluster_centers, 'euclidean'), axis=1)) / X.shape[0])\r\n",
                "\r\n",
                "        this_silhouette = metrics.silhouette_score(tfidf.toarray(), labels, metric='sqeuclidean')\r\n",
                "\r\n",
                "        #print(\"Silhouette Score: \" + str(this_silhouette))\r\n",
                "\r\n",
                "        mapping1[i] =  sum(np.min(cdist(X, cluster_centers, 'euclidean'), axis=1)) / X.shape[0]\r\n",
                "        mapping2[i] = kMeans.inertia_\r\n",
                "\r\n",
                "        all_kmeans_models.append(kMeans)\r\n",
                "\r\n",
                "        common_words = kMeans.cluster_centers_.argsort()[:,-1:-11:-1]\r\n",
                "        #for num, centroid in enumerate(common_words):\r\n",
                "            #print(str(num) + ' : ' + ', '.join(words[word] for word in centroid))\r\n",
                "    return all_kmeans_models, common_words, mapping1, mapping2, K, distortions"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "def calculate_knee(K, distortions):\r\n",
                "    try:\r\n",
                "        #print(\"The elbow point of the curve is: \")\r\n",
                "        #print('K: ',len(K))\r\n",
                "        #print('dis: ', len(distortions))\r\n",
                "        kneedle = KneeLocator(K, distortions, S=1.0, curve=\"convex\", direction=\"decreasing\")\r\n",
                "        #print(kneedle.knee_y)\r\n",
                "        kneedle.plot_knee()\r\n",
                "        return kneedle.knee\r\n",
                "    except:\r\n",
                "        print(\"Could not find an elbow point. Continuing with the lowest distortion.\")\r\n",
                "        min_distortion = max(distortions)\r\n",
                "        min_index = distortions.index(min_distortion)\r\n",
                "        return K[min_index]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "#plt.plot(K, inertias, 'bx-')\r\n",
                "#plt.xlabel('Values of K')\r\n",
                "#plt.ylabel('Inertia')\r\n",
                "#plt.title('The Elbow Method using Inertia')\r\n",
                "#plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "#plt.plot(K, distortions, 'bx-')\r\n",
                "#plt.xlabel('Values of K')\r\n",
                "#plt.ylabel('Distortion')\r\n",
                "#plt.title('The Elbow Method using Distortion')\r\n",
                "#plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "def gather_top_words(all_kmeans_models, knee, words, df):\r\n",
                "    # save the clusterIDs to the dataframe\r\n",
                "    # minus 2 because we start checking with 2 clusters\r\n",
                "    df[\"kMeans_ID\"] = all_kmeans_models[knee-2].labels_\r\n",
                "    cluster_words_list = []\r\n",
                "    common_words = all_kmeans_models[knee-2].cluster_centers_.argsort()[:,-1:-11:-1]\r\n",
                "    for num, centroid in enumerate(common_words):\r\n",
                "        cluster_words = []\r\n",
                "        for word in centroid:\r\n",
                "            cluster_words.append(words[word])\r\n",
                "        cluster_words_list.append(cluster_words)\r\n",
                "    return cluster_words_list, df"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "def assign_top_words(cluster_words_list, df):\r\n",
                "    row_words = []\r\n",
                "    for index, row in df.iterrows():\r\n",
                "        cluster = row.kMeans_ID\r\n",
                "        row_words.append(cluster_words_list[cluster])\r\n",
                "    df['kMeans_words'] = row_words\r\n",
                "    return df\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Subcluster by release date\r\n",
                "\r\n",
                "We will determine each articles release date and sort them into individual json files."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "def getMonthYear(s):\r\n",
                "     return s.split('-')[0]+\"-\"+s.split('-')[1]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Generating folder structure\r\n",
                "\r\n",
                "The following code creates the desired folder hierarchy and names each cluster after the top 3 dominant words in each one. Within each cluster/folder we are subclustering all articles by their release date.\r\n",
                "The output json file has the format *year-month.json*. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "def date_month_publish(df):\r\n",
                "    df['date_publish'] = pd.to_datetime(df['date_publish'])\r\n",
                "    df['month_year'] = df['date_publish'].apply(lambda x: getMonthYear(str(x)))\r\n",
                "    return df"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "def create_cluster_files(df):\r\n",
                "\r\n",
                "    item_LDA = df.iloc[0][\"topic_keywords\"]  # the top words from the lda clustering\r\n",
                "    item_LDA = item_LDA.split(\", \") # make string a list\r\n",
                "    cluster_id_LDA = df.iloc[0][\"LDA_ID\"]\r\n",
                "    print(\"ILOC: \" + str(cluster_id_LDA))\r\n",
                "    level1_directory = f'./clustered_json/cluster_{cluster_id_LDA}-{item_LDA[0]}_{item_LDA[1]}_{item_LDA[2]}'\r\n",
                "    os.makedirs(level1_directory)   # create the directory for the LDa clustering level\r\n",
                "\r\n",
                "    for cluster_id_kMeans, data in df.groupby(df.kMeans_ID):\r\n",
                "        item_kMeans = data.kMeans_words.tolist()[0]     # the top words from the kMeans clustering\r\n",
                "        os.makedirs(f'{level1_directory}/cluster_{cluster_id_kMeans}-{item_kMeans[0]}_{item_kMeans[1]}_{item_kMeans[2]}_{item_kMeans[3]}_{item_kMeans[4]}')     #create the directory for the level 2 kMeans clustering\r\n",
                "        for date, date_data in data.groupby(data.month_year):\r\n",
                "            json_data = date_data.to_json(orient='records', force_ascii=False, date_format='iso', date_unit='s')\r\n",
                "            parsed = json.loads(json_data)\r\n",
                "            with open(f'{level1_directory}/cluster_{cluster_id_kMeans}-{item_kMeans[0]}_{item_kMeans[1]}_{item_kMeans[2]}_{item_kMeans[3]}_{item_kMeans[4]}/{date}.json', 'w', encoding='utf-8') as f:  #create the json file for the level 3 timed events\r\n",
                "                f.write(json.dumps({\"data\": parsed}, indent=4, ensure_ascii=False))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "path = 'lda_clustered_json/'    # the path of the folder where the lda clustered articles are in\r\n",
                "\r\n",
                "amount_of_articles = 0\r\n",
                "i = 0\r\n",
                "for filename in glob.glob(os.path.join(path, '*.json')):\r\n",
                "    print(\"Executing code for main cluster \", str(i))\r\n",
                "    with open(filename, encoding='utf-8', mode='r') as currentFile:\r\n",
                "        df = pd.read_json(currentFile, orient='index')\r\n",
                "        amount_of_articles = cluster_data(df)\r\n",
                "    print(\"Finished multi level clustering of main cluster \" + str(i) + \". Processed \" + str(amount_of_articles) + \" articles.\")\r\n",
                "    i = i+1"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Executing code for main cluster  0\n",
                        "Generating the K-Means model...\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "100%|██████████| 8/8 [02:07<00:00, 16.00s/it]\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "ILOC: 3\n",
                        "Finished multi level clustering of main cluster 0. Processed 3776articles.\n",
                        "Executing code for main cluster  1\n",
                        "Generating the K-Means model...\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        " 88%|████████▊ | 7/8 [02:29<00:22, 22.61s/it]"
                    ]
                },
                {
                    "output_type": "error",
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Exception ignored in: 'sklearn.cluster._k_means_fast._relocate_empty_clusters_sparse'\n",
                        "Traceback (most recent call last):\n",
                        "  File \"<__array_function__ internals>\", line 2, in where\n",
                        "KeyboardInterrupt: \n",
                        "100%|██████████| 8/8 [02:51<00:00, 21.44s/it]\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "ILOC: 0\n",
                        "Finished multi level clustering of main cluster 1. Processed 4946articles.\n",
                        "Executing code for main cluster  2\n",
                        "Generating the K-Means model...\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "  0%|          | 0/8 [00:00<?, ?it/s]"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.4",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.4 64-bit ('kccs': conda)"
        },
        "interpreter": {
            "hash": "d7b8994cdf06398bb1d6bc43ff8b2ebd874fbdc1b32ac998f9bfa73841ea6f5e"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}