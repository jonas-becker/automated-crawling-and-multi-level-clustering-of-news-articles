{
  "0":{
    "title":"[P] Noisy Labels and Label Smoothing : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-funny-pics-tifu-worldnews-aww-todayilearned-gaming-videos-Jokes-Showerthoughts-movies-LifeProTips-OldSchoolCool-television-mildlyinteresting-explainlikeimfive-gifs-dataisbeautiful-personalfinance-science-IAmA-books-askscience-sports-space-nosleep-Futurology-gadgets-Art-TwoXChromosomes-food-history-UpliftingNews-WritingPrompts-photoshopbattles-GetMotivated-Music-EarthPorn-Documentaries-nottheonion-DIY-creepy-philosophy-listentothis-announcements-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  30 Sep 201728 points (85% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave815,241 readers3,903 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X165  \u00b7 63 comments [D] Why is this so painful493  \u00b7 81 comments [N] Hikvision marketed ML surveillance camera that automatically identifies Uyghurs, on its China website34  \u00b7 9 comments [N] Free 100$ GCP credits13  \u00b7 4 comments [1911.04252] Self-training with Noisy Student improves ImageNet classification21  \u00b7 11 comments [D] AI clones voice from 5 second recording18 [D] History of NLP: How Andrey Markov and Claude Shannon Made Language Models for Text Generation6  \u00b7 9 comments [D] AMD vs Nvidia GPU3  \u00b7 1 comment [D] Neural Differential Equations67  \u00b7 9 comments [D] What is the proper etiquette for extending someone's research code?5 [P] Traffic Analysis in Original Video DataWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7272829Project[P] Noisy Labels and Label Smoothing (github.com)submitted 2 years ago by longinglove12 commentssharesavehidereportall 12 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]longinglove[S] 3 points4 points5 points 2 years ago\u00a0(0 children)In this short experiment, I wanted to see if label smoothing is effective a) when there's noise in all labels b) when there's noise in one label. I think I could learn a lesson from this, but I have no intention of generalizing it since this is based on simple, limited settings.\n\npermalinkembedsavegive award[\u2013]ballgame75 3 points4 points5 points 2 years ago\u00a0(1 child)what kind of context would you apply this too? like NLP, maybe topic detection? I'm just curious, but what would be an example with a labeled output that would be up for interpretation? \n\npermalinkembedsavegive award[\u2013]NicolasGuacamole 6 points7 points8 points 2 years ago\u00a0(0 children)Pretty much anything which is mined or crowdsourced.\nMany datasets in computer vision are obtained through mechanical turk and have enormous amounts of noise.\nOne of Google's internal datasets is called JFT-300M and contains 300 million images. It's safe to say it has significant label noise.\nAnother thing to consider is things like dense prediction of things such as semantic classes or boundaries for pixels over videos or images. By their very nature classes may be subjective, and different people may label with different acuity, add to this the class imbalance problem.\n\npermalinkembedsaveparentgive award[\u2013]kacifoy 3 points4 points5 points 2 years ago\u00a0(0 children)My best guess that this 'label smoothing' thing isn't going to change the optimal classification boundary at all (in a maximum-likelihood sense) if the \"smoothing\" is symmetrical wrt. the labels, and even the non-symmetric case can be addressed in a rather more straightforward way, simply by adjusting the weight of more \"uncertain\" points in the dataset. Other considerations ultimately boil down to a sort of \"regularization\", but that's going to depend on plenty of other factors anyway, not just noise in the predicted variable. \n\npermalinkembedsavegive award[\u2013]lugiavn 1 point2 points3 points 2 years ago\u00a0(4 children)Isn't label smoothing for regularization, I don't see why it's supposed to help with noisy labels. And it seems there's nothing insightful came out of the experiments either?\n\npermalinkembedsavegive award[\u2013]NicolasGuacamole 0 points1 point2 points 2 years ago\u00a0(3 children)Presumably because we can interpret the labels as being probabilities in a very frequentist sense. When we minimise the loss we are literally considering our labels as probabilities with all the mass at the observed class, whether or not there is noise.\nSurely if we know there is noise then a smoothed set of labels is a more honest distribution to represent our data as.\n\npermalinkembedsaveparentgive award[\u2013]lugiavn 1 point2 points3 points 2 years ago\u00a0(2 children)Not sure if that's true,\nLets say labels with no noise is distribution 1\nFrom distribution 1, add label noise, we get distribution 2\nFrom distribution 2, add label smoothing, we get distribution 3\nAre you saying it's better to fit distribution 3 because it's closer to 1 (than 2 is to 1)?\n\npermalinkembedsaveparentgive award[\u2013]NicolasGuacamole 0 points1 point2 points 2 years ago\u00a0(1 child)Pretty much.\n\npermalinkembedsaveparentgive award[\u2013]lugiavn -1 points0 points1 point 2 years ago*\u00a0(0 children)Then that is wrong I think. Consider simple example: classify gender from height\n2 classes are balanced. Lets say for male (label y=0), input height x follows gaussian distribution N1 (or whatever kind of distribution you like)\nfor class female (label y=1), input x follow distribution N2.\n\nWith noise, say 10%, 2 classes are still balanced\nNow class 0, x follows mixture of Gaussians N1 N2 with weight 0.9 0.1\nSimilarly class 1, x  follows mixture of Gaussians N1 N2 with weight 0.1 0.9\n\nNow add label smoothing, say 10%\nNow for class 0, x follows mixtures of N1, N2 with weight 0.82 and 0.18\nFor class 1, x follows mixture of N1, N2 with weight 0.18 and 0.82\nSo how is this closer to the original distribution\n\npermalinkembedsaveparentgive award[\u2013]NicolasGuacamole 0 points1 point2 points 2 years ago\u00a0(0 children)Nice start but it probably needs more work.\nI think that your conclusion could prove interesting if we were able to mine an estimate of our label noise during collection and provide it as part of a dataset.\n\npermalinkembedsavegive award[\u2013]datatatatata 0 points1 point2 points 2 years ago\u00a0(0 children)Another approach would be to tune the loss function so that mis-labeling x% of the measured set is considered 0 error. Basically you ignore the first m errors.  \nI wonder how this would lead to different solutions \/ results.\n\npermalinkembedsavegive award[\u2013]keidouleyoucee 0 points1 point2 points 2 years ago\u00a0(0 children)https:\/\/arxiv.org\/abs\/1706.02361 Somehow related, I measured how much negative labels are noisy in music tagging dataset. \n\npermalinkembedsavegive awardaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 12070 on  r2-app-0a8ab4ff2a2626708  at 2019-11-13 01:40:20.639073+00:00 running 0cdf71e country code: US."
  },
  "1":{
    "title":"[R] How can we fool LIME and SHAP? Adversarial Attacks on Post hoc Explanation Methods -- post hoc explanation methods can be games to say whatever you want : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-funny-gaming-pics-tifu-movies-worldnews-aww-todayilearned-gifs-TwoXChromosomes-videos-OldSchoolCool-Jokes-Showerthoughts-mildlyinteresting-television-explainlikeimfive-science-LifeProTips-personalfinance-dataisbeautiful-history-nottheonion-IAmA-askscience-nosleep-sports-Futurology-books-Art-space-food-photoshopbattles-EarthPorn-UpliftingNews-DIY-WritingPrompts-Music-Documentaries-gadgets-GetMotivated-philosophy-listentothis-announcements-creepy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsother discussions (1)Want to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  07 Nov 201937 points (92% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave815,428 readers956 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X260  \u00b7 104 comments [D] Why is this so painful43  \u00b7 11 comments [1911.04252] Self-training with Noisy Student improves ImageNet classification62  \u00b7 9 comments [N] Free 100$ GCP credits520  \u00b7 85 comments [N] Hikvision marketed ML surveillance camera that automatically identifies Uyghurs, on its China website48  \u00b7 24 comments [D] AI clones voice from 5 second recording15  \u00b7 15 comments [D] AMD vs Nvidia GPU35 [D] History of NLP: How Andrey Markov and Claude Shannon Made Language Models for Text Generation[P] What is the best way to read data in batches from a datastore?7  \u00b7 7 comments [D] Neural Differential Equations16  \u00b7 1 comment [P] Traffic Analysis in Original Video DataWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7363738Research[R] How can we fool LIME and SHAP? Adversarial Attacks on Post hoc Explanation Methods -- post hoc explanation methods can be games to say whatever you want (arxiv.org)submitted 5 days ago by agamemnonlost18 commentssharesavehidereportall 18 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]AGI_aint_happening 7 points8 points9 points 5 days ago\u00a0(12 children)This is awesome work, but not at all surprising. SHAP\/LIME are really bad at explaining what a model is doing, and are only popular because they're the only tools that can be applied to arbitrary models.\n\npermalinkembedsavereportgive awardreply[\u2013]arnaudvl 2 points3 points4 points 4 days ago\u00a0(1 child)There are other methods\/tools that have quality open source implementations and can be applied to black box models like Anchors or Counterfactuals, implemented in https:\/\/github.com\/SeldonIO\/alibi. One of the implemented methods is called \"Counterfactuals Guided by Prototypes\" (https:\/\/docs.seldon.io\/projects\/alibi\/en\/stable\/methods\/CFProto.html; https:\/\/arxiv.org\/abs\/1907.02584) and explicitly deals with the \"out-of-distribution\" issue of the perturbations mentioned in the \"How can we fool LIME and SHAP?\" paper.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]eric_he 0 points1 point2 points 4 days ago\u00a0(0 children)Thanks for sharing, will check it out\n\npermalinkembedsaveparentreportgive awardreply[\u2013]eric_he 3 points4 points5 points 5 days ago\u00a0(9 children)Can you expand on why you think SHAP is really bad? I use it all the time, it always says stuff that aligns with my intuition and it\u2019s helped me debug datasets when I thought predictions didn\u2019t look quite right.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]arnaudvl 5 points6 points7 points 4 days ago\u00a0(1 child)One of the issues is the treatment of categorical variables and the need for a non-informative background value for the KernelExplainer. This is carefully explained here: https:\/\/github.com\/slundberg\/shap\/issues\/451. This could however be addressed by adding a conversion from categorical to numerical values inferred from a training set as in https:\/\/docs.seldon.io\/projects\/alibi\/en\/stable\/methods\/CFProto.html#Categorical-Variables.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]eric_he 1 point2 points3 points 4 days ago\u00a0(0 children)So I use shap for xgboost, in which case all categorical values are mapped to integers. This would be why I never ran into this problem?\nAnd thank you for the informative answer!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]dddetr 6 points7 points8 points 5 days ago\u00a0(0 children)I think SHAP is pretty good about determining what's going on in a model as well.  I think this paper is just pointing out that how it goes about sampling can be exploited\u2014not that there's something inherently flawed with the shapley value technique.\nNo need to stop using SHAP, just maybe think twice if it's a sensitive situation where someone could have a reason to try and trick you.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]AGI_aint_happening -2 points-1 points0 points 5 days ago\u00a0(5 children)To make the SHAP scores sum up to the prediction, it bakes in interactions into the scores in weird ways that are hard to track. I've seen instances where half the time when a variable equals some value, it has positive score and the other half negative score - how do you interpret that?\nYou'd be better off computing the correlation between an input and the model's prediction, imo.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]eric_he 1 point2 points3 points 4 days ago\u00a0(2 children)Well, I think the a fixed feature value having positive score in some situations and negative scores in others is actually a feature of non linear models rather than a bug. The fact that SHAP can mirror such a capability is a plus rather than a minus to me.\nThe most concrete example for why this is desired and expected is when I was measuring how much users would like an e-commerce listing. An expensive listing would have a negative SHAP value for my listing price feature if the user historically clicked or browsed normal or cheap listings, and a positive SHAP value if the user clicked or bought mostly expensive listings. \nSeeing this firsthand really validated to me how powerful the model was and how flexible SHAP values were.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]AGI_aint_happening 1 point2 points3 points 4 days ago\u00a0(1 child)So, in your example, the problem is you don't know if the shap score is positive because a user likes cheap listings or not. It could be positive because they are from a certain region, clicked on a similar link in the past, haven't clicked on anything in a week, or an interaction with any other feature fed into the model. And you have no way of knowing. Worse, it gives you just enough information that you can make up a convincing story about it being due to user's historical preferences.\nThere is some information in the scores, no doubt, but treating them as a full description of the model will get you in trouble. For e-commerce that may be fine, I'm more worried about sensitive areas (e.g. loan applications, healthcare).\n\npermalinkembedsaveparentreportgive awardreply[\u2013]eric_he -1 points0 points1 point 4 days ago\u00a0(0 children)\nyou don\u2019t know if the shap score is positive because a user likes cheap listings or not\n\nI used shap\u2019s partial dependence plot on the listing price feature, which automatically labeled user preferred price as the feature affecting most of the interaction in aggregate across the sample. I can\u2019t see how this wouldn\u2019t be just fine as an explanation, so long as we are not in an adversarial situation. \nAnd I\u2019m not sure it would even be possible to break down such an explanation to the level you\u2019re looking for. If we had to enumerate every single interaction effect then we would have the entire model, and obviously nobody can internalize in their head the model function of a gradient boosting tree! SHAP just looks in the local area to obtain its SHAP values, but clearly a good explanation must either lose some information of the model\u2019s global structure or lose some level of granularity.\n\nI\u2019m more worried about sensitive areas\n\nI\u2019d agree that we have a long way to go before society can be fully comfortable using black box models in such spaces. \nBut I do think it\u2019s strange that we hold models to such a different standard than actual people - it\u2019s not like I can truly understand the recommendations my doctor can give me either.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]deeceeo 2 points3 points4 points 4 days ago\u00a0(1 child)Can't this happen if you have an XOR-like condition in the input data where the effect of a variable changes depending on another variable? It seems like this could be a fairly common occurrence, and a correlation could make it look like the variable doesn't matter at all.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]eric_he 1 point2 points3 points 4 days ago\u00a0(0 children)This is my understanding as well\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sameer_s 2 points3 points4 points 3 days ago\u00a0(1 child)Coauthor on this paper here, and also a coauthor on LIME, if anybody has any questions.\n\npermalinkembedsavereportgive awardreply[\u2013]AfgCric 1 point2 points3 points 1 day ago\u00a0(0 children)Hah! I gotta say, that's just awesome. It takes the edge away from \"attack\" to here are the limitations of this model.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]arXiv_abstract_bot 1 point2 points3 points 5 days ago\u00a0(0 children)Title:How can we fool LIME and SHAP? Adversarial Attacks on Post hoc Explanation Methods  \nAuthors:Dylan Slack, Sophie Hilgard, Emily Jia, Sameer Singh, Himabindu Lakkaraju \n\nAbstract: As machine learning black boxes are increasingly being deployed in domains such as healthcare and criminal justice, there is growing emphasis on building tools and techniques for explaining these black boxes in an interpretable manner. Such explanations are being leveraged by domain experts to diagnose systematic errors and underlying biases of black boxes. In this paper, we demonstrate that post hoc explanations techniques that rely on input perturbations, such as LIME and SHAP, are not reliable. Specifically, we propose a novel scaffolding technique that effectively hides the biases of any given classifier by allowing an adversarial entity to craft an arbitrary desired explanation. Our approach can be used to scaffold any biased classifier in such a way that its predictions on the input data distribution still remain biased, but the post hoc explanations of the scaffolded classifier look innocuous. Using extensive evaluation with multiple real-world datasets (including COMPAS), we demonstrate how extremely biased (racist) classifiers crafted by our framework can easily fool popular explanation techniques such as LIME and SHAP into generating innocuous explanations which do not reflect the underlying biases.  \n\nPDF Link | Landing Page | Read as web page on arXiv Vanity\n\npermalinkembedsavereportgive awardreply[\u2013]Gisebert 1 point2 points3 points 4 days ago\u00a0(0 children)I wrote some stuff about the disadvantages of LIME in a seminar called \"Limitations of Interpretable Machine Learning\".\nThe finished work of all students was collected in a single (and free) online book; check it out if you want (not entirely finished, yet):\nhttps:\/\/compstat-lmu.github.io\/iml_methods_limitations\/_book\/index.html\n\npermalinkembedsavereportgive awardreply[\u2013]YoungStellarObject 0 points1 point2 points 3 days ago\u00a0(0 children)There's another recent work on fooling explanation methods, focussing on gradient-based and propagation-based methods (and how to make them more robust):\nhttps:\/\/arxiv.org\/abs\/1906.07983\n\npermalinkembedsavereportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 27763 on  r2-app-0a4d50df89bf18e39  at 2019-11-13 09:10:37.954571+00:00 running 0cdf71e country code: US."
  },
  "2":{
    "title":"thegdb comments on [D] Gary Marcus Tweet on OpenAI still has not changed misleading blog post about \"solving the Rubik's cube\"",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-funny-gaming-pics-tifu-movies-worldnews-aww-todayilearned-gifs-TwoXChromosomes-videos-OldSchoolCool-Jokes-Showerthoughts-mildlyinteresting-television-explainlikeimfive-science-LifeProTips-personalfinance-dataisbeautiful-history-nottheonion-IAmA-askscience-nosleep-sports-Futurology-books-Art-space-food-photoshopbattles-EarthPorn-UpliftingNews-DIY-WritingPrompts-Music-Documentaries-gadgets-GetMotivated-philosophy-listentothis-announcements-creepy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  20 Oct 201955 points (78% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave816,075 readers2,298 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X163  \u00b7 40 comments \"[D]\" John Carmack stepping down as Oculus CTO to work on artificial general intelligence (AGI)179  \u00b7 5 comments [R] NVIDIA's Kaolin: A PyTorch Library for Accelerating 3D Deep Learning Research[R] Teaching a neural network to use a calculator45  \u00b7 56 comments [D] What stupid things did you use to do?\u00b7 2 comments [D] Working on an ethically questionnable project...[D] BERT for non-textual sequence data29  \u00b7 20 comments A New Paper from Francois Chollet where he disconnects Artificial General Intelligence from Training on Larger and Larger Datasets.30  \u00b7 4 comments [D] Gaussian Processes, Not Quite for Dummies2  \u00b7 2 comments [D] Thoughts about this conversation?\u00b7 1 comment [R] HOList: An Environment for Machine Learning of Higher-Order Theorem ProvingWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7545556Discussion[D] Gary Marcus Tweet on OpenAI still has not changed misleading blog post about \"solving the Rubik's cube\" (self.MachineLearning)submitted 25 days ago by chansung1880 commentssharesavehidereportloading...sorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an accountyou are viewing a single comment's thread.view the rest of the comments\u00a0\u2192[\u2013]thegdbOpenAI 43 points44 points45 points 25 days ago\u00a0(9 children)\nGranted, many newspapers reported is as if the ML part had also worked out how to solve the cube, and OpenAI have not tried to correct the misreporting, but I'm not sure that's feasible or even necessary.\n\nWe ping journalists to ask them to correct factual errors in reporting when we see them (though they may not always agree with our corrections). For example, the Washington Post article (https:\/\/www.washingtonpost.com\/technology\/2019\/10\/18\/this-robotic-hand-learned-solve-rubiks-cube-its-own-just-like-human\/) feels misleading, so we've emailed them and linked them to the relevant sections in our blog post (namely, that we use Kociemba's algorithm as you mention).\nIf you see other articles that need correcting, always feel free to let me know \u2014 gdb@openai.com!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tradediscount 6 points7 points8 points 25 days ago\u00a0(0 children)I stand corrected. Nice one!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]openaievolution 1 point2 points3 points 24 days ago*\u00a0(1 child)Tbf this is an artifact of your \"science by press release\" strategy as well. If you release a public preprint first, journalists will have an easier time sourcing opinions from other well informed folks in the field, and presumably the reporting would get better.Zach Lipton elaborates more on this point in this thread here: https:\/\/twitter.com\/zacharylipton\/status\/1184237037622136832 \nPS: To be clear, I am not arguing for not doing press releases, but rather putting out a preprint first and allowing some time b\/w the preprint and the press release.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]whatevenarecomputers 2 points3 points4 points 24 days ago\u00a0(0 children)When has a reporter ever erred on the side of measured response from experts in the field instead of writing up the most sensationalized version they could concoct and still maintain plausible deniability?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus -2 points-1 points0 points 25 days ago\u00a0(4 children)why not post some sort of clarification on your own site? it is clear that your blog was prone to misinterpretation.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Ghenlezo 31 points32 points33 points 25 days ago*\u00a0(3 children)I am a little baffled by your reaction to this. You worked with robots before, yes? The fact that they actually got a hand to sort of work on an intricate task, and to the point that it is able to adapt to many perturbations, is astonishing. \nDid they make any deep algorithmic breakthroughs? No, but nor did they claim to. They scale things up and see how far they can push them. This is super useful work. AI is an engineering discipline not a science, and unfortunately is half-ashamed of this fact. \nWas anyone with any literacy fooled into thinking the cube-solver was learned? It says right in the post it was done symbolically. Even if the solver was learned that is, frankly, much less impressive than demonstrating modestly robust physical dexterity.\nYour critique of the major deep learning figures is of naked emperors. But I see scholars constantly apologizing for their state of undress, baffled at how well they are weathering ever-colder temperatures.  \nOne begins to wonder if invisible wool does, in fact, exist.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus 1 point2 points3 points 25 days ago\u00a0(1 child)Curious for your take compared to the much less hyped Baoding balls the week before. Here's what I said in the tweet that you apparently didn't read: I will say again that the work itself is impressive, but mischaracterized, and that a better title would have been \"manipulating a Rubik's cube using reinforcement learning\" or \"progress in manipulation with dextrous robotic hands\" or similar lines.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Ghenlezo 32 points33 points34 points 25 days ago*\u00a0(0 children)I read your \u201cdetailed analysis\u201d meme. I have not read every tweet you wrote on the matter. I am glad you admit that the progress on the actual task they were attempting was good.\nYour image macro makes it look as if you are dismissing impressive work for trivial misunderstandings.  Anyone with any experience in this stuff knows, watching the video not even reading the paper, that what is impressive is the dexterity, and that solving a cube is trivial symbolically.\nImagine we\u2019re watching a ski race on television and someone said, \u201cYou know they may be able to ski down fine but what they don\u2019t show you is they don\u2019t ski up! They use a chairlift!\u201d\nThat\u2019s the impression your image macro gives me.\nThey say right in the post that it was done symbolically. Failure to spoon feed journalists is not a sin in my book.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tristes_tigres 0 points1 point2 points 24 days ago\u00a0(0 children)\nAI is an engineering discipline not a science\n\nEngineering consists in applying known scientific principles to solve the real-world problems. AI at this point is barely more than alchemy - a compendium of techniques that seem to work from time to time for unknown reasons, that is very useful for extracting funding from wealthy patrons hoping to expand their riches.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]master_yoda_1 -2 points-1 points0 points 24 days ago\u00a0(0 children)The same nonsensical hype you guys created with gpt-2 by not releasing it, and later on you proved yourself wrong and released it.\nWhat is your comment about that?\n\npermalinkembedsaveparentreportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 24965 on  r2-app-0e27d6cf2c9b3e66a  at 2019-11-14 10:51:30.039630+00:00 running 0eef139 country code: US."
  },
  "3":{
    "title":"[D] How does FaceApp work? : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-funny-pics-tifu-worldnews-aww-todayilearned-gaming-videos-Jokes-Showerthoughts-movies-LifeProTips-OldSchoolCool-television-mildlyinteresting-explainlikeimfive-gifs-dataisbeautiful-personalfinance-science-IAmA-books-askscience-sports-space-nosleep-Futurology-gadgets-Art-TwoXChromosomes-food-history-UpliftingNews-WritingPrompts-photoshopbattles-GetMotivated-Music-EarthPorn-Documentaries-nottheonion-DIY-creepy-philosophy-listentothis-announcements-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  27 Apr 201779 points (86% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave815,108 readers3,859 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X433  \u00b7 71 comments [N] Hikvision marketed ML surveillance camera that automatically identifies Uyghurs, on its China website81  \u00b7 34 comments [D] Why is this so painful17  \u00b7 8 comments [N] Free 100$ GCP credits10  \u00b7 5 comments [D] AI clones voice from 5 second recording7 [D] History of NLP: How Andrey Markov and Claude Shannon Made Language Models for Text Generation63  \u00b7 9 comments [D] What is the proper etiquette for extending someone's research code?[D] AI Coverage Best Practices, According to AI Researchers4 [P] Traffic Analysis in Original Video Data\u00b7 2 comments [D] What are the most reputable VC firms \/ Accelerators for machine learning startups?2  \u00b7 8 comments [D] Are there any papers that do Birds Eye View Pose Estimation?Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7787980Discussion[D] How does FaceApp work? (self.MachineLearning)submitted 2 years ago by clbam8I came across this app on play store today called FaceApp. Does anyone know how it works? I don't remember seeing any paper about this recently.\n\n27 commentssharesavehidereportall 27 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]neoteat 21 points22 points23 points 2 years ago\u00a0(0 children)in this article from February: https:\/\/techcrunch.com\/2017\/02\/08\/faceapp-uses-neural-networks-for-photorealistic-selfie-tweaks\/ they said \"FaceApp makes use of \u201cdeep generative convolutional neural networks\u201d.\n\npermalinkembedsavegive award[\u2013]schmook 17 points18 points19 points 2 years ago*\u00a0(2 children)There are plenty of papers that use tasks like taking features from one face and applying to another to demonstrate the quality of a generative model. Things like putting on or taking out glasses, changing gender, etc. \nFor example, if you have a good autoencoder for faces you can try to:\n\nget latent representations for a photo of a person with and without glasses, \nsubtract them and add to a latent representation of your face without glasses\ngenerate a new face with the result\n\nProbably this would be a face of you wearing glasses, with varying degrees of success and quality. Kind of like the \"king - man + woman = queen\" in Word2vec? Many recent generative models can do something similar for pictures too.\nSomething like the DiscoGAN or CycleGAN can do even better by learning how to map from the subset of faces with glasses to the subset of faces without glasses even if you don't have explicit glasses\/no-glasses pairs of otherwise similar photos.\nI am pretty sure that a CycleGAN\u200b could be trained to do exactly what this app do and probably would have results as good as the ones in the app. It's just a question of manually tagging the celeb faces dataset with age\/gender\/etc labels and training the maps (and the results of the app look a lot like typical results using this dataset, so I suspect that's exactly what they did).\nBut I suspect that you could even do it (probably with less quality) with a  dcGAN based adversarial autoencoder, with the procedure I described above. I don't know if it would match the quality of the results from this app but it would be an initial version.         \n\npermalinkembedsavegive award[\u2013]alexmlamb 1 point2 points3 points 2 years ago\u00a0(0 children)I guess these are all ways that FaceApp could work, but do you have any indications into how it does work?  \nIt's not too surprising that it uses convnets, but I could see many specific technologies being in play here.  \n\npermalinkembedsaveparentgive award[\u2013]andreasblixt 17 points18 points19 points 2 years ago*\u00a0(6 children)Usually the solution is deceptively simple. In this case they may use OpenCV to get the Pose of the person to then apply masked textures on the shape of the face. \nHere's a Google result I found on the topic http:\/\/www.learnopencv.com\/facial-landmark-detection\/\nEdit: to clarify, I don't mean what they do is super simple but that state of the art deep learning probably didn't play any part in the app.\nEdit 2\nSee comment thread below, I was a bit quick to judge. There appears to be artifacts in FaceApp's output images akin to what you get from convolutional filters, and it's able to handle several cases that a simple cut & paste OpenCV application would not be able to do (especially wrt lighting conditions and hair shape).\nI think it's fair to say that they do use neural networks and some pretty good ones at that, since it works so well. As others have suggested, this could be based on one of the more recent GAN papers. I would wager the face still goes through an initial pass with OpenCV (or something similar) to normalize orientation and to crop away the background (and maybe also the eyes since they seem constant in all filters but the ->female one), considering how good it is at leaving a large part of the photo alone.\nEdit 3\nAlright I managed to produce a few failure cases which gives away some information. You can see that they pick a square around the face and process only that part and then putting it back into the original photo. Secondly, in the last picture you can see that in some cases they do apply hand crafted textures onto the image, which becomes obvious when they fail to correctly get the orientation of the head.\nhttp:\/\/imgur.com\/a\/itQp1\n\npermalinkembedsavegive award[\u2013]iwantedthisusername -4 points-3 points-2 points 2 years ago*\u00a0(4 children)This answer is 100% 53% wrong. \n\npermalinkembedsaveparentgive award[\u2013]andreasblixt 5 points6 points7 points 2 years ago\u00a0(3 children)Even if I'm wrong, I think it's an exaggeration to say I'm 100% wrong. As I wrote in another comment:\n\nI think even the most recent GANs have trouble cleanly separating the features of a face that make up its identity from the features that make up its expression, as shows in [the @smilevector] Twitter feed (the person's identity appears to change with the \"smile vector\").\nI think FaceApp's resolution, speed, and quality shows it is using more traditional and handcrafted methods to modify the face expression.\n\n\npermalinkembedsaveparentgive award[\u2013]iwantedthisusername 2 points3 points4 points 2 years ago\u00a0(2 children)Yeah but the thing is when you use the app with weird lighting or  paintings of faces the errors you see more resemble what you'd see in a GAN or a cVAE.\nI suppose 100% is an exaggeration. They probably have some photo editing elements in addition, but as far as I can tell they're being honest about their technology.\n\npermalinkembedsaveparentgive award[\u2013]andreasblixt 0 points1 point2 points 2 years ago\u00a0(1 child)I've tried the app some more and in some cases it does produce the kind of artifacts you'd get from convolutional filters, so that would indicate they are indeed using neural networks to some extent.\nIt'd be very impressive if it's all the result of a neural network though, maybe they are extracting the face texture using OpenCV, doing style transfer on it and then putting it back in the picture?\n\npermalinkembedsaveparentgive award[\u2013]iwantedthisusername 2 points3 points4 points 2 years ago\u00a0(0 children)Yeah that's what I'm figuring, I'm surprised by the resolution though, and they're obviously using multiple techniques.\nI think your theory is pretty reasonable. I think the smiles are definitely a combined technique, we're probably both right lol.\nRegarding the \"100%\" I probably should have applied a softmax instead of a one-hot to my opinion ;)\n\npermalinkembedsaveparentgive award[\u2013]gecko39 2 points3 points4 points 2 years ago\u00a0(2 children)https:\/\/twitter.com\/smilevector has been adding smiles to photos for a while. I believe he is using GANs\n\npermalinkembedsavegive award[\u2013]andreasblixt 1 point2 points3 points 2 years ago\u00a0(0 children)I think even the most recent GANs have trouble cleanly separating the features of a face that make up its identity from the features that make up its expression, as shows in this Twitter feed (the person's identity appears to change with the \"smile vector\").\nI think FaceApp's resolution, speed, and quality shows it is using more traditional and handcrafted methods to modify the face expression.\n\npermalinkembedsaveparentgive award[\u2013]Progr4mmatic 0 points1 point2 points 2 years ago\u00a0(0 children)That is so creepy.\n\npermalinkembedsaveparentgive award[\u2013]shaggorama 2 points3 points4 points 2 years ago\u00a0(0 children)Almost certainly cycleGAN\/discoGAN, maybe with an added attention mechanism. The discoGAN paper even had a gender-bending model as one of its examples. After reading that paper I actually immediately thought of building an app like this but just never got around to it.  \n\npermalinkembedsavegive award[\u2013]zergling103 2 points3 points4 points 2 years ago\u00a0(0 children)Only deep learning could be capable of this sort of satanisn https:\/\/twitter.com\/Zergfriend\/status\/857053793393012736?s=09\nPlus when it glitches you get characteristic convolutional neural network artifacts.\nThey are probably using a technique like this https:\/\/t.co\/lXb4eWUFw3 https:\/\/t.co\/DNOK2SCJC5\n\npermalinkembedsavegive award[\u2013]bakmanthetitan329 7 points8 points9 points 2 years ago\u00a0(5 children)If this is a bad enough question to be downvoted this badly, could someone please explain why? Not OP by the way, I was curious about this same app.\n\npermalinkembedsavegive award[\u2013]schmook 13 points14 points15 points 2 years ago\u00a0(1 child)It's not a bad question. My guess is that people downvoted because they felt that op was asking out of lack of familiarity with some recent and very hyped literature on generative models. \nWhich is ok if you ask me. It's absolutely ok not to know things.\n\npermalinkembedsaveparentgive award[\u2013]lucidrage 1 point2 points3 points 2 years ago\u00a0(0 children)Exactly, I'm sure everyone who's gone through college was thought that there's no such thing as \"stupid questions\".\n\npermalinkembedsaveparentgive award[\u2013]jordo45 1 point2 points3 points 2 years ago\u00a0(2 children)\n23 points (82% upvoted), top post on \/r\/machinelearning\n\nAm I missing something?\n\npermalinkembedsaveparentgive award[\u2013]schmook 2 points3 points4 points 2 years ago\u00a0(1 child)At first there were quite a few downvotes. \n\npermalinkembedsaveparentgive award[\u2013]jordo45 6 points7 points8 points 2 years ago\u00a0(0 children)You'd think people on this sub would know that you need a larger amount of data.\n\npermalinkembedsaveparentgive award[\u2013]olBaa 4 points5 points6 points 2 years ago\u00a0(0 children)I'd bet that they do not actually use the GANs there, just the plain and simple editing algorithms. It's done on mobine in reasonably high resolution, I don't think texture synthesys by Gatis (& extensions by Ulyanov (prisma) can be applied to do that.\n\npermalinkembedsavegive award[\u2013]pmigdal 1 point2 points3 points 2 years ago\u00a0(0 children)I don't know exactly how this particular app works. However, two months ago I came across this paper:\n\nGrigory Antipov, Moez Baccouche, Jean-Luc Dugelay, Face Aging With Conditional Generative Adversarial Networks, arXiv:1702.01983\n\n\npermalinkembedsavegive award[\u2013]StuntHacks 2 points3 points4 points 2 years ago\u00a0(0 children)I am wondering this too. My guess would be that they use some kind of machine learning algorithm bundled with some photo editing algorithms that are already established. So they got really lucky that they got all this hype around the app because that way they had huge amounts of training data very fast.\n\npermalinkembedsavegive award[\u2013]iwantedthisusername 0 points1 point2 points 2 years ago\u00a0(0 children)Probably generative deep networks. Maybe a conditional variational auto encoder.\n\npermalinkembedsavegive award[\u2013]senorstallone 0 points1 point2 points 2 years ago\u00a0(0 children)I've been playing a lot with the app, and I'm almost sure it's some kind of Interpolation in Latent space. The results are better for females than to males which are usually the case for GAN's papers I guess.\n\npermalinkembedsavegive award[\u2013]ItalianPizza91 0 points1 point2 points 2 years ago\u00a0(0 children)Defenitely late to the party, but could they be using cGANs? the generator gets an input image to transform to either female\/old\/young etc, and the discriminator has to learn to recognize them as such\n\npermalinkembedsavegive award[\u2013]themoosemind 0 points1 point2 points 2 years ago*\u00a0(0 children)My highlights of FaceApp examples \/ news:\n\nHusky\nArt\n\n\nMisc by Olly Gibbs\nMona Lisa\nEdward Burne-Jones\n\nSlides22\nFinal Fantasy\nFemale filter\nFaceApp sorry for 'racist' filter that lightens skin to make users 'hot' (example)\n\n\npermalinkembedsavegive awardaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 13312 on  r2-app-064f883af2bde15cc  at 2019-11-12 21:28:07.989308+00:00 running e0c00f8 country code: US."
  },
  "4":{
    "title":"[D] Gary Marcus Tweet on OpenAI still has not changed misleading blog post about \"solving the Rubik's cube\" : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-funny-gaming-pics-tifu-movies-worldnews-aww-todayilearned-gifs-TwoXChromosomes-videos-OldSchoolCool-Jokes-Showerthoughts-mildlyinteresting-television-explainlikeimfive-science-LifeProTips-personalfinance-dataisbeautiful-history-nottheonion-IAmA-askscience-nosleep-sports-Futurology-books-Art-space-food-photoshopbattles-EarthPorn-UpliftingNews-DIY-WritingPrompts-Music-Documentaries-gadgets-GetMotivated-philosophy-listentothis-announcements-creepy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  20 Oct 201958 points (79% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave816,102 readers2,385 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X187  \u00b7 45 comments \"[D]\" John Carmack stepping down as Oculus CTO to work on artificial general intelligence (AGI)186  \u00b7 5 comments [R] NVIDIA's Kaolin: A PyTorch Library for Accelerating 3D Deep Learning Research\u00b7 15 comments [D] Working on an ethically questionnable project...6  \u00b7 1 comment [R] Teaching a neural network to use a calculator43  \u00b7 60 comments [D] What stupid things did you use to do?3  \u00b7 2 comments [D] Thoughts about this conversation?3  \u00b7 2 comments [D] BERT for non-textual sequence data26  \u00b7 20 comments A New Paper from Francois Chollet where he disconnects Artificial General Intelligence from Training on Larger and Larger Datasets.32  \u00b7 4 comments [D] Gaussian Processes, Not Quite for Dummies\u00b7 1 comment [R] HOList: An Environment for Machine Learning of Higher-Order Theorem ProvingWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7575859Discussion[D] Gary Marcus Tweet on OpenAI still has not changed misleading blog post about \"solving the Rubik's cube\" (self.MachineLearning)submitted 25 days ago by chansung1880 commentssharesavehidereportloading...all 80 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]Veedrac 80 points81 points82 points 25 days ago*\u00a0(29 children)Gary's summary is much more misleading than the blog post.\nConcerns 1-4: \u201cNeural networks didn't do the solving; a 17-year old symbolic AI algorithm did\u201d\nFTA: \u201cWe train neural networks to solve the Rubik\u2019s Cube in simulation using reinforcement learning and Kociemba\u2019s algorithm for picking the solution steps.\u201d\n(NB: I would prefer this to be stated more prominently in less technical terms.)\nConcern 5: \u201cOnly ONE object was manipulated, and there was no test of generalizability to other objects\u201d\nFTA: Five different prototypes were used, a locked cube, a face cube, a full cube, a giiker cube, and a \u2018regular\u2019 Rubik\u2019s cube. The article never claims to do anything other than solve Rubik's cubes.\nConcern 6: \u201cThat object was heavily instrumented (eg with bluetooth sensors). The hand was instrumented with LEDs, as well.\u201d\nFTA: The five different prototypes had different levels of instrumentation. The \u2018regular\u2019 Rubik's cube had none, except small corners cut out of the centre squares to remove symmetry.\nFTA: Videos of the LEDs. They're blinking and red, FFS.\nConcern 7: \u201cSuccess rate was only 20%; hand frequently dropped cube\u201d\nFTA: \u201cOur robot still hasn\u2019t perfected its technique though, as it solves the Rubik\u2019s Cube 60% of the time (and only 20% of the time for a maximally difficult scramble).\u201d\nFTA: A whole section dedicated to this issue.\n\npermalinkembedsavereportgive awardreply[\u2013]briggers 36 points37 points38 points 25 days ago\u00a0(2 children)This is what his book, Rebooting AI, is like.\nMany misrepresentations, and a general argumentation style of \"it isn't perfect, therefore it isn't good.\"\nThere is definitely a case for being much more cautious about ML\/DL than many over-hyped journalists are, but this guy is just looking to fill a contrarian niche.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]mimomusic 20 points21 points22 points 24 days ago\u00a0(1 child)I think Marcus is a well-spoken and intelligent man.\nI also think he is exceedingly pedantic to such a degree that he detracts from the actual problem at hand while most laymen are well capable to read between the lines and see research or blogposts for what they are.\nSure, precision in academia is not something you can just forego without regard for making yourself understood, but the people who actually care about that stuff are very likely to dive into the nitty-gritty anyway. Those who succumb to hype would misunderstand and fall for nonsense headlines even if they were 100% unambiguous and perfectly constructed - but who cares about what The Sun is trying to convey?\nAlmost all of us were well-aware of all the caveats parent poster mentioned, at least most of them. They are almost irrelevant in this context, even something as arguably crucial as generalizability (what a goddamn word!) takes a back seat to the main issue of robotic dexterity. \nI understand that different people approach subjects with different degrees of rigor, and I can feel Marcus' concerns, but I also think they are very much nitpicky and not at all important to the discussion as far as OpenAI's due diligence and openness to critique is concerned.\nHe sure is someone who will always be at odds with the community at large, but whether it's time well-spent is something I view with a healthy portion of skepticism; I think way too much effort goes into scrutinizing things that, as far as we can tell at this stage, barely matter in the long run.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sanxiyn 17 points18 points19 points 25 days ago\u00a0(20 children)I was actually disappointed by corner cutout for regular Rubik's cube. I consider that a significant instrumentation, and I think it is entirely justified to say that OpenAI did not solve vision part of regular Rubik's cube.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]whatevenarecomputers 2 points3 points4 points 24 days ago\u00a0(19 children)They also didn't claim to solve the vision part of Rubik's cube solving (and explicitly said so), so it can't really be used as a way to detract from the OpenAI article. It was an article about the physical manipulation.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]nrmncer 4 points5 points6 points 24 days ago\u00a0(10 children)tbh though what exactly has been achieved here then? Robots built to solve Rubik's cubes have been around for a while, most do it faster than that hand. The accuracy is low, it doesn't generalise well, there's a lot of hacks involved.. I guess the fact that it can fend off the giraffe is a novelty.\nBut without any generalisation and given the low accuracy there's not much news here.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]whatevenarecomputers 5 points6 points7 points 24 days ago\u00a0(1 child)There is a ton of generalization and resilience to new input here - putting scrunches around the fingers, putting it in a glove. Poking it as it solves. The breakthrough is the motion planning and object manipulation is done entirely through RL.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sheeplearning 2 points3 points4 points 23 days ago\u00a0(0 children)Yes but it is unclear if any of that is useful given it is not sufficient to solve the cube. Perhaps new approaches and additional experiments are needed and celebrating mediocrity just makes it harder for anyone to actually solve it. Robot does not really \"solve\", warcraft does not really \"see\", GPT2 is too harmful to the world and BERT outperforms and releases the model without any fuss -- everyone knows what is really going on here.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tshadley 3 points4 points5 points 24 days ago\u00a0(7 children)But why has no one built a Rubik's cube robot implementing a one-handed solve?  It's relatively easy to build a 5 fingered hand mock-up with servomotors.   It has to be because the controller algorithm to hold the cube, turn it, and solve it with 5 fingers is vastly complicated-- way beyond any traditional approach.  The Deep-Neural-Network dexterity algorithm is the amazing accomplishment here.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]kit_hod_jao 2 points3 points4 points 24 days ago\u00a0(0 children)I think this is part of the issue with the demo - it's hard to get a sense of how hard it is. I can certainly imagine it's very difficult to achieve, but one of the benefits of existing benchmarks is our expectations are finely calibrated to detect unusually good performance.\nStill, new benchmarks have to come from somewhere and IMO this is very impressive. It's just hard to appreciate how challenging it is.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]AnvaMiba 1 point2 points3 points 23 days ago\u00a0(3 children)\nIt's relatively easy to build a 5 fingered hand mock-up with servomotors.\n\nIt's not. Five finger robotic hands that can move accurately are crazy expensive. They are only used for research as prosthetics, not as standalone robots, which is why you don't see many people using them to do stunts like this.\nManipulation of objects of known shape and mass with stationary robots is a technologically mature task, there are plenty of industrial robots working on assembly lines which can manipulate objects much faster and more reliably than this. They don't use any fancy RL, just good old control theory and motion planning.\nSo what's the innovation there? That they used RL?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tshadley 0 points1 point2 points 23 days ago\u00a0(1 child)\nManipulation of objects of known shape and mass with stationary robots is a technologically mature task, there are plenty of industrial robots working on assembly lines which can manipulate objects much faster and more reliably than this. They don't use any fancy RL, just good old control theory and motion planning.\n\nAny specific example of comparable complexity?  From what I've seen, industrial robots motion environments are tightly constrained and limited.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]AnvaMiba 0 points1 point2 points 23 days ago\u00a0(0 children)\nFrom what I've seen, industrial robots motion environments are tightly constrained and limited.\n\nYes, for safety reasons. The OpenAI robot hand isn't strong or fast enough to cause injury, which is why they can fiddle with it while it's moving.\nThere are also robots designed for safe interaction with humans, or robust enough to resist external perturbations\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tshadley 0 points1 point2 points 23 days ago\u00a0(0 children)\n\nIt's relatively easy to build a 5 fingered hand mock-up with servomotors.\n\nIt's not. Five finger robotic hands that can move accurately are crazy expensive. They are only used for research as prosthetics, not as standalone robots, which is why you don't see many people using them to do stunts like this.\n\nTo more accurately make my point, I'll say it's relatively easy to obtain a 5-fingered hand mockup.  ShadowRobot seems to have built the first \"dexterous hand\" in 2005.  The hard part is controlling it.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]nrmncer 0 points1 point2 points 24 days ago\u00a0(1 child)\nBut why has no one built a Rubik's cube robot implementing a one-handed solve?\n\nmostly because if you're going to build a specialised machine it makes more sense to build.. well a regular machine. If all it can do is solve the cube then there's no need to make it to resemble a hand.  It's a nice video to look at but they already had dextrous movements down a year ago. This is essentially the same thing with a slightly more modular task.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tshadley 0 points1 point2 points 23 days ago*\u00a0(0 children)\nmostly because if you're going to build a specialised machine it makes more sense to build.. well a regular machine. If all it can do is solve the cube then there's no need to make it to resemble a hand.\n\nBut all regular machines for Rubik's solving have been built; clamps, rotating platforms, etc..  This was an obvious next step.\n\nIt's a nice video to look at but they already had dextrous movements down a year ago\n\nManipulating a solid cube with one hand is a vastly simpler than rotating individual planes of a Rubik's cube with one hand.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sanxiyn 2 points3 points4 points 24 days ago\u00a0(3 children)Isn't vision (or state estimation by vision) fundamental part of manipulation? I guess with Bluetooth instrumentation OpenAI showed manipulation \"would have worked\" if vision was working. But they couldn't get vision working.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]whatevenarecomputers 1 point2 points3 points 24 days ago\u00a0(2 children)I think it's much more likely that they wanted to focus on a solution for the physical motion planning. I would not be surprised if there were independent projects to handle the object recognition\/position portion (which is effectively a separate problem).\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sanxiyn 0 points1 point2 points 24 days ago\u00a0(1 child)OpenAI directly stated in the paper that they couldn't get vision working. See page 16. To quote:\n\nWe experimented with a recurrent vision model but found it very difficult to train to the necessary performance level. Due to the project\u2019s time constraints, we could not investigate this approach further.\n\n\npermalinkembedsaveparentreportgive awardreply[\u2013]whatevenarecomputers 0 points1 point2 points 24 days ago\u00a0(0 children)https:\/\/openai.com\/blog\/learning-dexterity\/\nThis appears to be their ongoing effort to implement the vision portion.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]ispeakdatruf -1 points0 points1 point 24 days ago\u00a0(3 children)So what does \"solve\" in the title mean? For a human, the harder part is figuring out the steps involved. I can teach a 5yo how to rotate the cube in a minute. But teaching the kid to actually solve the cube will take much longer.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]whatevenarecomputers 2 points3 points4 points 24 days ago*\u00a0(2 children)Yes, a rule of thumb for AI is the more intuitive for a human, the harder it is to make a computer do, and vice versa. We see this phenomena everywhere. Resilient motion planning and balance, object recognition, natural language processing, object location estimation. Humans do all this by the age of of 5.\nIt's easy to make a computer to solve (symbolically) Sudoku or a Rubik's cube. Hard or time consuming for a human (without lots of training). \"Can we figure out the order of rotations to solve a cube\" is not what OpenAI is trying to solve. That's a well explored, solved problem.\nConversely, human brains find spacial manipulation very intuitive past the age of like 3. But it's hard to build a system, even with fine-grained closed-loop feedback, that can manipulate physical objects. We have to design all sorts of loops and heuristics to estimate the physics of the object, how to move it in space, how to not drop it, how it can be folded or rotated or whatever. Letting reinforcement learning figure out all these nitty-gritty details represents novel progress being made in this space. \nThey have a system which seems to have figured out how to compensate for all sorts of messy inconsistencies like actuators not responding exactly how the model would expect it to (they mention it being resiliant even when actuators entirely break), all the way up to \"how do we figure out the individual finger movements to grasp and rotate a cube face\".\n\npermalinkembedsaveparentreportgive awardreply[\u2013]ispeakdatruf 0 points1 point2 points 24 days ago\u00a0(1 child)In my limited experience with robotics, I totally concur with you.\nIt would have be somewhat OK to title an academic paper with that title. People in the area would understand.\nBut that's not what OpenAI did. They put out a blog post with that title, which is clearly intended for the general lay audience. The average person, who knows nothing about how hard actuator control, sensors, etc., are, will naturally assume that the harder, cognitive problem is being solved.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]whatevenarecomputers 0 points1 point2 points 24 days ago\u00a0(0 children)What's the harder cognitive problem to solve here? If it's symbolically solving a cube, that's just not an interesting problem to solve, and we don't need ML to do it. It's not a game of Go. The interesting cognitive problem is the motion planning.\nI just disagree that the blog post is misrepresenting what OpenAI has accomplished. Its entire focus is on the hand, its motion, and the feedback systems involved.\nEven the title is \"Solving Rubik\u2019s Cube with a Robot Hand\". Sure, somebody could read only the title and come to the wrong conclusion. But that's not really OpenAI's problem.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]yuvalpinlp 1 point2 points3 points 23 days ago\u00a0(3 children)So, about 1-4, in what sense does the RL net \"solve\" the cube?\n\"train to solve... picking the solution steps\" you don't find this phrasing very misleading?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Veedrac 0 points1 point2 points 23 days ago\u00a0(2 children)They say they \u201csolve the Rubik\u2019s Cube with a human-like robot hand.\u201d This is true.\nI agree that the phrasing of \u201cand Kociemba\u2019s algorithm for picking the solution steps\u201d is too technical to be properly transparent to the average reader, even many readers with ML background, and I agree it is not nearly prominent enough\u2014I said as much in my post.\nIf Gary's tweet was about that only\u2014as in, it did not make his other claims, and it was phrased so it was obvious the issue is clarity rather than honesty\u2014I'd have supported his commentary unreservedly.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]yuvalpinlp 0 points1 point2 points 22 days ago\u00a0(1 child)I'm sorry, I find it impossible to interpret \"solve\" as anything other than \"figure out what to do at each step\", which is the one thing their RL system *didn't* do.\nAs Gary noted, there are other, much more accurate verbs to use, my vote goes to \"manipulate\".\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Veedrac 0 points1 point2 points 22 days ago\u00a0(0 children)I disagree that bringing a cube to the solved position cannot be described as solving it, but your disaffection is understandable and this wasn't one of my points of disagreement with the original post. I agree that \u2018manipulate\u2019 would be a much clearer term.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]SkiddyX 55 points56 points57 points 25 days ago*\u00a0(6 children)This subreddit\u2019s unquenchable thirst for drama continues... \ud83d\ude02\n\npermalinkembedsavereportgive awardreply[\u2013]booleyan 30 points31 points32 points 25 days ago\u00a0(2 children)Siraj started a fire we can't put out.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]egrefen 10 points11 points12 points 24 days ago\u00a0(0 children)It's always been burning \ud83c\udfb6\nSince GPUs been churning \ud83c\udfb5\n\npermalinkembedsaveparentreportgive awardreply[\u2013]ispeakdatruf 2 points3 points4 points 24 days ago\u00a0(0 children)You_again would beg to differ...\n(with due apologies to Prof Schmidhuber, who has been shafted by the rest of the community)\n\npermalinkembedsaveparentreportgive awardreply[\u2013]LaVieEstBizarre 12 points13 points14 points 25 days ago\u00a0(1 child)Experts hate hype machines\n\npermalinkembedsaveparentreportgive awardreply[\u2013]dod_worker 12 points13 points14 points 24 days ago\u00a0(0 children)And hypers hate expert machines!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]MonstarGaming 3 points4 points5 points 23 days ago\u00a0(0 children)For real. We ban beginner tutorials only to fill the gap with community drama. WTF? I wish we could tag and filter this content at the very least.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]balls4xx 12 points13 points14 points 25 days ago\u00a0(0 children)A lego bot can solve (rotate until each side has a single color) a Rubik\u2019s cube, even I can solve one after inputting the tile pattern into some website. I think what they \u2018solved\u2019 here was making a robotic hand do it while being accosted by a stuffed giraffe.\n\npermalinkembedsavereportgive awardreply[\u2013]tradediscount 36 points37 points38 points 25 days ago*\u00a0(17 children)I think Marcus is being a little disingenuous here. The key achievement of the OpenAI research he refers to is using reinforcement learning for really hard real world manipulation of physical objects using a robot hand.\nThe Rubik's cube is used as a prop to represent a hard real world problem (hard as in difficult to manipulate effectively).\nOpenAI's blog post explicitly (but perhaps not prominently enough for Marcus or seemingly many subeditors who missed it in their reporting) states they use Kociemba's algorithm to determine the next move. This non AI shortcut was presumably used to reduce the number of steps, given the already high difficulty physical manipulation task they'd set themselves.\nGranted, many newspapers reported is as if the ML part had also worked out how to solve the cube, <and OpenAI have not tried to correct the misreporting>, but I'm not sure that's feasible or even necessary.\nEdit: bit between angle brackets not true, see u\/thegdb comment below.\nIn addition, the cube has been solved using deep nets by several other teams (a quick Google shows published in reputed journals too) so while not trivial I have no doubts OpenAI could also solve it if they chose to.\nFinally, Marcus seems to like creating controversy to publicise his view that a lot of the DL community misrepresent the promise and capabilities of DL, which in my view simply isn't true. Hinton, Bengio, Le Cun, Chollet et al have all in my view been very open, measured and fair about the technology.\n\npermalinkembedsavereportgive awardreply[\u2013]thegdbOpenAI 42 points43 points44 points 25 days ago\u00a0(9 children)\nGranted, many newspapers reported is as if the ML part had also worked out how to solve the cube, and OpenAI have not tried to correct the misreporting, but I'm not sure that's feasible or even necessary.\n\nWe ping journalists to ask them to correct factual errors in reporting when we see them (though they may not always agree with our corrections). For example, the Washington Post article (https:\/\/www.washingtonpost.com\/technology\/2019\/10\/18\/this-robotic-hand-learned-solve-rubiks-cube-its-own-just-like-human\/) feels misleading, so we've emailed them and linked them to the relevant sections in our blog post (namely, that we use Kociemba's algorithm as you mention).\nIf you see other articles that need correcting, always feel free to let me know \u2014 gdb@openai.com!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tradediscount 7 points8 points9 points 25 days ago\u00a0(0 children)I stand corrected. Nice one!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]openaievolution 1 point2 points3 points 24 days ago*\u00a0(1 child)Tbf this is an artifact of your \"science by press release\" strategy as well. If you release a public preprint first, journalists will have an easier time sourcing opinions from other well informed folks in the field, and presumably the reporting would get better.Zach Lipton elaborates more on this point in this thread here: https:\/\/twitter.com\/zacharylipton\/status\/1184237037622136832 \nPS: To be clear, I am not arguing for not doing press releases, but rather putting out a preprint first and allowing some time b\/w the preprint and the press release.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]whatevenarecomputers 2 points3 points4 points 24 days ago\u00a0(0 children)When has a reporter ever erred on the side of measured response from experts in the field instead of writing up the most sensationalized version they could concoct and still maintain plausible deniability?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus -1 points0 points1 point 25 days ago\u00a0(4 children)why not post some sort of clarification on your own site? it is clear that your blog was prone to misinterpretation.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Ghenlezo 30 points31 points32 points 25 days ago*\u00a0(3 children)I am a little baffled by your reaction to this. You worked with robots before, yes? The fact that they actually got a hand to sort of work on an intricate task, and to the point that it is able to adapt to many perturbations, is astonishing. \nDid they make any deep algorithmic breakthroughs? No, but nor did they claim to. They scale things up and see how far they can push them. This is super useful work. AI is an engineering discipline not a science, and unfortunately is half-ashamed of this fact. \nWas anyone with any literacy fooled into thinking the cube-solver was learned? It says right in the post it was done symbolically. Even if the solver was learned that is, frankly, much less impressive than demonstrating modestly robust physical dexterity.\nYour critique of the major deep learning figures is of naked emperors. But I see scholars constantly apologizing for their state of undress, baffled at how well they are weathering ever-colder temperatures.  \nOne begins to wonder if invisible wool does, in fact, exist.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus 1 point2 points3 points 25 days ago\u00a0(1 child)Curious for your take compared to the much less hyped Baoding balls the week before. Here's what I said in the tweet that you apparently didn't read: I will say again that the work itself is impressive, but mischaracterized, and that a better title would have been \"manipulating a Rubik's cube using reinforcement learning\" or \"progress in manipulation with dextrous robotic hands\" or similar lines.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Ghenlezo 31 points32 points33 points 25 days ago*\u00a0(0 children)I read your \u201cdetailed analysis\u201d meme. I have not read every tweet you wrote on the matter. I am glad you admit that the progress on the actual task they were attempting was good.\nYour image macro makes it look as if you are dismissing impressive work for trivial misunderstandings.  Anyone with any experience in this stuff knows, watching the video not even reading the paper, that what is impressive is the dexterity, and that solving a cube is trivial symbolically.\nImagine we\u2019re watching a ski race on television and someone said, \u201cYou know they may be able to ski down fine but what they don\u2019t show you is they don\u2019t ski up! They use a chairlift!\u201d\nThat\u2019s the impression your image macro gives me.\nThey say right in the post that it was done symbolically. Failure to spoon feed journalists is not a sin in my book.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tristes_tigres 0 points1 point2 points 24 days ago\u00a0(0 children)\nAI is an engineering discipline not a science\n\nEngineering consists in applying known scientific principles to solve the real-world problems. AI at this point is barely more than alchemy - a compendium of techniques that seem to work from time to time for unknown reasons, that is very useful for extracting funding from wealthy patrons hoping to expand their riches.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]master_yoda_1 -2 points-1 points0 points 24 days ago\u00a0(0 children)The same nonsensical hype you guys created with gpt-2 by not releasing it, and later on you proved yourself wrong and released it.\nWhat is your comment about that?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]m_nemo_syne 2 points3 points4 points 24 days ago\u00a0(3 children)(I have to be pedantic for a moment: you call Kociemba's algorithm a \"non AI shortcut\", but it is AI, just not machine learning. This is an instance of the \"AI effect\": https:\/\/en.wikipedia.org\/wiki\/AI_effect)\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tradediscount 1 point2 points3 points 23 days ago*\u00a0(1 child)I strongly disagree. You are being precise, not pedantic, and I appreciate it thoroughly.\nedit: would \"non ml\" be better?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]m_nemo_syne 1 point2 points3 points 23 days ago\u00a0(0 children)Thanks! I think so :)\n\npermalinkembedsaveparentreportgive awardreply[\u2013]WikiTextBot 0 points1 point2 points 24 days ago\u00a0(0 children)AI effect\nThe AI effect occurs when onlookers discount the behavior of an artificial intelligence program by arguing that it is not real intelligence.Author Pamela McCorduck writes: \"It's part of the history of the field of artificial intelligence that every time somebody figured out how to make a computer do something\u2014play good checkers, solve simple but relatively informal problems\u2014there was a chorus of critics to say, 'that's not thinking'.\" AIS researcher Rodney Brooks complains: \"Every time we figure out a piece of it, it stops being magical; we say, 'Oh, that's just a computation.'\"\n\n[ PM | Exclude me | Exclude from subreddit | FAQ \/ Information | Source ]\nDownvote to remove | v0.28\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus -3 points-2 points-1 points 25 days ago\u00a0(1 child)i am not aware of any system that has solved the cube with pure RL; the ones i have seen are hybrids that also include monte carlo tree search. correct me if i am wrong...\n\npermalinkembedsaveparentreportgive awardreply[\u2013]nikitau 1 point2 points3 points 21 days ago*\u00a0(0 children)DeepCubeA for example does it with A* and trains the heuristic using function approximation and value iteration. While I haven't seen a system that reliably solves the cube using just RL without search, I feel like the same case could be made about Go too.\nDo you feel that lookahead is somewhat \"cheating\" in this case? Just curios, because at the end of the day, what gives such systems the edge over pure search ones is the fact that they learned how to guide the search.\nupdate: I actually read your write-up about innateness in AlphaZero in the meantime and understand a bit more where your statement is coming from. Its a good read and gave me a bit more insight into your point of view and I will say that I agree that in the philosophical context of AGI, using search definitely equates to injecting priors and is far from a tabula rasa approach.\nI get why you consider why their success may be uninteresting wrt. AGI; however within the domain of fully observable, deterministic environments, search methods could be seen as a common and rather simple denominator of all solvers, which one would be foolish not to use. If we are referring only to this small subset of all environments (which does model a lot of useful processes still) wouldn't AlphaZero (say apart from its use of CNNs) be one of the least biased solvers? I am curios on your thoughts about this.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus -2 points-1 points0 points 25 days ago\u00a0(0 children)Hinton in particular sometimes over promised quite a bit; i will likely write about that soon.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]JonathanFly 12 points13 points14 points 25 days ago*\u00a0(7 children)I don't have the expertise to comment on the physical simulation part of this, so there may be some valid critique on that end, but I don't understand the primary criticism in this particular post.\nIsn't it obvious that solving the Rubik's cube is just a proxy for any dexterity challenge?  Learning how to solve a Rubik's cube is trivial, it's inconsequential.\nFor example, if OpenAI's project was 'robot that plays Tic Tac Toe in adverse conditions' and then in the video we see the Tic Toe paper oriented in different directions or moving around the table, in a room with dark or very bright light, on a table that's vibrating, with leaves blowing all around obstructing vision, using random types of pens and pencils that the robot arm has to adapt to on the fly -- this would basically be the same paper.  Would you apply your same top-line criticisms to that project? Would you say the 'neural network isn't actually playing Tic Tac Toe, it's the 2000 year old Tic Tac Toe algorithm?'\nMaybe the problem is Rubik's cube have a mystique around them when I thought it was pretty clear that figuring out what to rotate is a trivial problem that any robot or human can already solve.\n\npermalinkembedsavereportgive awardreply[\u2013]ispeakdatruf 2 points3 points4 points 24 days ago\u00a0(3 children)\nLearning how to solve a Rubik's cube is trivial, it's inconsequential.\n\nSo, you have an RL algorithm that figured out how to solve Rubik's Cube?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sanxiyn 1 point2 points3 points 23 days ago\u00a0(1 child)You may like Solving the Rubik's Cube Without Human Knowledge.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]ispeakdatruf 0 points1 point2 points 23 days ago\u00a0(0 children)Thank you, I was unaware of that work. Upvoted!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus 0 points1 point2 points 25 days ago\u00a0(1 child)many many people misunderstood the article given how it was framed; the washington post coverage is a case in a point.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Ghenlezo 18 points19 points20 points 25 days ago*\u00a0(0 children)Journalists have terrible incentives, as a rule no technical training, and little time. \u201cJournalists misunderstand you in the manner most likely to grab clicks\u201d is a universal argument against anyone who has interacted with a journalist.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]subsampled 5 points6 points7 points 25 days ago*\u00a0(0 children)I think Marcus regularly raises interesting objections and ideas in the nature vs nurture (and symbolic vs connectionist) debate. Here, however, he may have missed the main point of this work, which emerges pretty clearly from the series of works by the same group.\nThe main progress is clearly is in the context of in-hand manipulation via RL, whose complexity is very well-known to roboticists.\nControlling a complex tendon-driven hand like the Shadow Hand to reconfigure an object with several degrees of freedom in presence of multiple contacts and disturbances has been a moonshot in robotics since forever. It's also true that OpenAI may have done better with choosing the title, but the work seems still a significant breakthrough, for sure in its robotics and transfer parts.\nAnd yes, in my experience 60% performance for the average case is definitely a good result for robotics demos standards of similar complexity.\n\npermalinkembedsavereportgive awardreply[\u2013]garymarcus 8 points9 points10 points 25 days ago\u00a0(1 child)what\u2019s most notable about many of the comments here is that it is largely just ad hominem attacks; nobody can really argue that the screenshot on the left half of the slide of analysis (ie the opening of openAI\u2019s blog) actually matches what the paper did, and few people here are willing to acknowledge how widely the result was misinterpreted.  \nPR that invites serious misinterpretation is the definition hype; in the long run ML will suffer from a pattern of overpromising, just as earlier approaches (eg expert systems) have.\n\npermalinkembedsavereportgive awardreply[\u2013]adventuringraw 21 points22 points23 points 24 days ago\u00a0(0 children)man, I came here ready to jump on OpenAI for being overly hyped, but their coverage itself really did seem measured, in spite of the press apparently misunderstanding it. Reading through the comments, I see mostly praise for you, combined with everyone roughly saying 'but in this case, it seems like Marcus jumped the gun, here's why'.\nYou taking such a measured community reaction here as being nothing but 'ad hominem attacks' really makes me question what thread you were reading, because it apparently wasn't this one. If you're going to dig around to make sure claims are perfectly represented with no room for misinterpretation (a worthwhile activity given the current AI hype, don't get me wrong) you really don't get to so badly misrepresent your own treatment on a little subreddit like this. Literally anyone can read the other 30 comments on here. Does anyone else see 'ad hominem attacks'? Because I sure don't. Aside from a passing comment about 'filling a contrarian niche' it seems to be more about OpenAI's coverage, your specific critiques, and what people think about the issue. I saw your post, I read the blog post, it might have been easier than it should have been for a lay audience to misinterpret, but I really don't buy that it was on purpose. I don't even buy that it needs to be changed now that the mainstream reporters have come and gone, I honestly read OpenAI's coverage as intended, this was an impressive milestone in physical dexterity, that's it. As another comment pointed out, doing the whole solution (solving and all) in one learned architecture probably wouldn't have been radically harder than what was achieved even, assuming the other comment was correct, and there are other papers doing the actual Rubik's Cube solution finding. The reasons given in other comments for not buying your reasoning matches my own. My (honestly mostly unformed, I don't know your work well) opinion of you as a person doesn't factor into my not accepting your analysis in this case.\nAside from one apparently actually rude ad hominem attack (that was called out by someone else, the original user deleted their post now) what's left is a long ways away from being unfair to you. If you're going to misrepresent your own treatment in such an obvious way, I'm not impressed when the topic you're trying to push is another group misrepresenting their research.\nThat said, even if you were maybe a little overzealous in this case, and even if you're taking it a little personally that not everyone else here agrees with you, I wholeheartedly wish that mainstream reporting was more realistic, so Godspeed on your quest.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus 4 points5 points6 points 25 days ago\u00a0(13 children)you may have caught a minor error here but mostly you are comparing apples and oranges. \nmy main point was that the popular presentation (ie the blog) was misleading; finding stuff in the fine print in the technical paper doesn\u2019t fix that.  and even so,  note that the title of the article itself is misleading, as is the opening framing, as i detailed in a previous tweet. so the article itself has its own issues. \ni am really most concerned though with your anemic defense of point 5: it doesn\u2019t matter whether openAI claimed to have looked at more than one object or not; the point is that if you don\u2019t have stronger tests of generalization, you can\u2019t make profound claims.  5 slightly different cubes doesn\u2019t mean you could not tighten a screw, open a lock, or button a shirt.\n\npermalinkembedsavereportgive awardreply[\u2013]Veedrac 15 points16 points17 points 25 days ago\u00a0(7 children)You replied to the post rather than me.\n\nfinding stuff in the fine print in the technical paper\n\nEverything I said was from the blog post, and not even a particularly close read of it. I don't expect the press to read dense technical papers, but I do expect them to read more than the title of the summarizing blog.\n\n5 slightly different cubes doesn\u2019t mean you could not tighten a screw, open a lock, or button a shirt.\n\nOpenAI never claimed otherwise.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus -2 points-1 points0 points 25 days ago\u00a0(6 children)perhaps i should have said blog abstract (ie the part reproduced in my slide); the Washington Post story stands as a testament to how prone the piece was to being misread, \nit\u2019s not just the title, but the full framing in the abstract i reproduced. and how much emphasis there is in the article on learning relative to the small space devoted to the large innate contribution, etc\n.and even on your last point \u201cunprecedented dexterity\u201d at top suggests that they ought to be able to do this in general in some\nform; they haven\u2019t actually tested that (aside from variants on a cube). as someone apparently in Ml, you should recognize how unpersuasive that is. there is a long history of that sort of thing having seriously trouble generalizing.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Veedrac 14 points15 points16 points 25 days ago\u00a0(1 child)The quote is \u201cThis shows that reinforcement learning isn\u2019t just a tool for virtual tasks, but can solve physical-world problems requiring unprecedented dexterity.\u201d I find it very hard to understand where your objection is coming from; that sentence is plenty reasonable.\nAt this point I think my comments stand on their own, so I'm going to bow out.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus 4 points5 points6 points 25 days ago\u00a0(0 children)Which problems? without a test of generalizability to other noncubic, noninstrumented objects, and without a comparison to the Baoding result from a week before, I think the sentence is overstated. what are the plural \"problems\" even? I see one problem, no test of transfer. By know we should know that this is a red flag.\nWhich doesn't mean that I am unimpressed. In fact,  I  said the following, in a immediate reply to my own tweet that you must not have read: \"I will say again that the work itself is impressive, but mischaracterized, and that a better title would have been \"manipulating a Rubik's cube using reinforcement learning\" or \"progress in manipulation with dextrous robotic hands\" or similar lines.\"\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sanxiyn 1 point2 points3 points 25 days ago\u00a0(3 children)We can all agree that move finding was innate, but why does that mean \"large innate contribution\"? It was a small part of the work, so innate contribution was small.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus 2 points3 points4 points 25 days ago\u00a0(2 children)I guess this depends on how you define solving. But: You take out the innate part, and it no longer solves the cube.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sanxiyn 1 point2 points3 points 24 days ago\u00a0(1 child)I am all for retitling the post to \"Manipulating Rubik's Cube\" as you suggested. After retitling, innate contribution was small.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus -1 points0 points1 point 24 days ago\u00a0(0 children)That title would certainly help a lot, and reduce the importance of innate component, though elsewhere there is still a fair amount of carefully engineered innate detail of different sorts in the precise structuring of the visual system etc. It's not like it was a big end-to-end network fed from a bunch of sources that worked everything out for itself.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]simpleconjugate 12 points13 points14 points 25 days ago*\u00a0(4 children)As time has progressed, your criticisms come off as \u201cbad faith criticisms\u201d.\nIn this case you disguise problems with science and tech journalism as problems with OpenAI\u2019s communication of achievement. GDB is right, they never made any large claims outside being able to manipulate the cubes.\nIt would be great to have people out there who are keeping conversation around AI grounded, but that doesn\u2019t seem to be your primary interest or goal.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus 8 points9 points10 points 25 days ago\u00a0(1 child)the problem here was with openAi\u2019s communication; i have been clear about that, posting repeatedly on twitter that result was impressive though not as advertised.  here is an example since you seem to have missed it: https:\/\/twitter.com\/garymarcus\/status\/1185680538335469568?s=21\nno person in the public would read the claim of \u201cunprecedented dexterity\u201d as being restricted to cubes.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]simpleconjugate 4 points5 points6 points 25 days ago*\u00a0(0 children)A change in title should be made for sake of honesty (social media isn\u2019t known for its in depth readings).\nHowever unprecedented dexterity is certainly a reasonable description of the impressive result.  I also don\u2019t think that the same \u201cperson in the public\u201d would read your tweets and think that OpenAI achieved anything important. In this sense, you mischaracterized OpenAI\u2019s own claims and achievements while reporting their own failures to communicate. \nYou are doing great work out there by pointing out the flaws in the hype. But at the same time, it feels that your criticisms serve Robust.AI more than the public. As someone who think ML needs to be become more rigorous in reporting results, I think recent posts highlight things that journalist irresponsibly reported on as well as mistakes made by OpenAI.\nSuffice to say, lately I feel the same about both you and OpenAI as you feel about OpenAI and the \u201cperson in the public\u201d.\n\npermalinkembedsaveparentreportgive awardreply[\u2013][deleted] 25 days ago\u00a0(1 child)[deleted]\n\n[\u2013]simpleconjugate 1 point2 points3 points 25 days ago\u00a0(0 children)That seems like an unnecessary personal attack.  There is a clear line between criticizing his ideas and attacking him. You crossed it.\n\npermalinkembedsavereportgive awardreply[\u2013]Rasko__ 0 points1 point2 points 23 days ago\u00a0(0 children)Jesus Christ who cares\n\npermalinkembedsavereportgive awardreply[+]SugarAdamAli comment score below threshold-11 points-10 points-9 points 25 days ago\u00a0(0 children)This is all way too over my head, but I\u2019ll take your word for it\n\npermalinkembedsavereportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 2160 on  r2-app-0b1b17546394c110c  at 2019-11-14 11:57:03.484736+00:00 running 0eef139 country code: US."
  },
  "5":{
    "title":"[D] Is Neural Magic a scam? : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-funny-gaming-pics-tifu-movies-worldnews-aww-todayilearned-gifs-TwoXChromosomes-videos-OldSchoolCool-Jokes-Showerthoughts-mildlyinteresting-television-explainlikeimfive-science-LifeProTips-personalfinance-dataisbeautiful-history-nottheonion-IAmA-askscience-nosleep-sports-Futurology-books-Art-space-food-photoshopbattles-EarthPorn-UpliftingNews-DIY-WritingPrompts-Music-Documentaries-gadgets-GetMotivated-philosophy-listentothis-announcements-creepy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  08 Nov 201945 points (80% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave816,395 readers2,293 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X139  \u00b7 112 comments [D] Working on an ethically questionnable project...394  \u00b7 137 comments \"[D]\" John Carmack stepping down as Oculus CTO to work on artificial general intelligence (AGI)31  \u00b7 7 comments [R] Momentum Contrast for Unsupervised Visual Representation Learning: \"the gap between unsupervised and supervised representation learning has been largely closed\"11 [Research] We trained a self-balancing physics-based character to follow interactive motion capture.196  \u00b7 5 comments [R] NVIDIA's Kaolin: A PyTorch Library for Accelerating 3D Deep Learning Research3  \u00b7 1 comment [R] \"Compressive Transformers for Long-Range Sequence Modelling\", Rae et al 201919  \u00b7 9 comments [D] Thoughts about this conversation?3  \u00b7 1 comment [D][R] Applications of AI\/ML in the field of Digital Pathology9  \u00b7 2 comments [R] HOList: An Environment for Machine Learning of Higher-Order Theorem Proving[D] Online paper reading \/ note taking software?Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7444546Discussion[D] Is Neural Magic a scam? (self.MachineLearning)submitted 6 days ago by isthataprogenjiiI recently learned about this new startup which advertises that they can provide GPU level learning using a CPU. There are already CPU versions of neural network training algorithms. Is neural magic doing false advertisement? What approach are they taking specifically to make the 'magic' happen?\n\n26 commentssharesavehidereportall 26 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]darkconfidantislife 85 points86 points87 points 6 days ago*\u00a0(9 children)\"Scam\" is far too strong a word. Their backgrounds are in multithreaded computing techniques, so I'm guessing that they're using a huge stack of approximations like induced sparsity,  low precision, hashing, compression, etc. and auto generating very high performance multithreaded code. That would also explain why they're targeting inference. \nIt's not a \"scam\", but my suspicion is that if you're a DL researcher it's not gonna be super useful to you.\nEDIT: \nThese things generally tend to not run so well on GPUs due to architectural and software reasons. That's why sparse graph workloads are usually run on CPUs in HPC today. \nI'll also add that sparsity is something that most competent machine learning accelerators will support. For example our processor supports sparsity even better than a CPU usually does, and competitors such as cerebras and graphcore also support sparsity acceleration.\n\npermalinkembedsavereportgive awardreply[\u2013]maxToTheJ 0 points1 point2 points 6 days ago\u00a0(8 children)Couldn\u2019t you do those things on a GPU too?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]darkconfidantislife 10 points11 points12 points 6 days ago\u00a0(7 children)Usually those particular things, i.e. sparsity and hashing, tend to be of lower efficiency on GPUs, due to architectural and software reasons.\n\npermalinkembedsaveparentreportgive awardreply[+]ithinkiwaspsycho comment score below threshold-8 points-7 points-6 points 5 days ago\u00a0(6 children)Hashing is usually magnitudes faster on a GPU compared to a CPU, which is why GPUs are heavily used in password cracking and bitcoin mining, etc. Do you mind citing your sources that say hashing is faster on CPU?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]darkconfidantislife 3 points4 points5 points 5 days ago\u00a0(0 children)Hash lookups\n\npermalinkembedsaveparentreportgive awardreply[\u2013]JayWalkerC 0 points1 point2 points 5 days ago\u00a0(4 children)Computer science is never so simple as \"X is faster on Y\". There's more to consider that is not mention here.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]maxToTheJ 2 points3 points4 points 5 days ago\u00a0(3 children)But isnt his answer in response to \u201cY is faster on X\u201d\n\npermalinkembedsaveparentreportgive awardreply[\u2013]JayWalkerC 1 point2 points3 points 5 days ago\u00a0(2 children)\"hashing\" is not specific. There are many different hash functions, some are faster on CPU and some are faster on GPU. That's the point.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]maxToTheJ 1 point2 points3 points 5 days ago\u00a0(1 child)I get your point but my point was the disparity between the upvotes for CPU does hashing better vs GPU does hashing better. Assuming your logic they should be the same as both are wrong\n\npermalinkembedsaveparentreportgive awardreply[\u2013]darkconfidantislife 0 points1 point2 points 5 days ago\u00a0(0 children)I'm the one who's upvoted for CPU, and I agree, he just asked a simple question. People are just downvote happy I guess\n\npermalinkembedsaveparentreportgive awardreply[\u2013]yusuf-bengio 34 points35 points36 points 6 days ago\u00a0(1 child)I know some guys from Boston who work there. \nIn essence, they develop multi-threaded, SIMD and cache efficient kernels to train sparse deep learning models.\nTheir focus is on sparse data\/models, where they claim to achieve GPU level performance.\n\npermalinkembedsavereportgive awardreply[\u2013]jminuse 15 points16 points17 points 6 days ago\u00a0(0 children)GPUs are less efficient on sparse matrices, so they inherently don't provide as much speedup vs CPUs here. That's fair within this problem domain, and fair if the sparse models can equal the dense ones in accuracy. But it's not a good comparison if they're saying \"we can be as fast as GPUs (if we use substantially less accurate models).\"\n\npermalinkembedsaveparentreportgive awardreply[\u2013]bigfish_in_smallpond 18 points19 points20 points 6 days ago\u00a0(0 children)They aren't talking about learning, they are specifically talking about inference.\n\npermalinkembedsavereportgive awardreply[\u2013]jacobgorm 5 points6 points7 points 5 days ago\u00a0(2 children)They seem to have a few magical tricks up their sleeves, but in general the performance differences between CPUs and GPUs for inference is smaller that most believe. Looking at darknet for instance (at least when I last tried it), it uses cublas GEMM() on the GPU, but a simple triple-nested loop on the CPU, resulting in a 100X speed difference, but replacing its naive GEMM() with an modern BLAS GEMM() implementation readily reduces the difference to between ~5X as I recall. My own tiny company, Vertigo.ai, has been shipping CPU-based neural nets for several years, though we don't make as bold claims as Neural Magic does about always running as fast as GPUs in all cases.\n\npermalinkembedsavereportgive awardreply[\u2013]darkconfidantislife 3 points4 points5 points 5 days ago\u00a0(0 children)That sounds interesting, care to say more?\nAs an aside, your website has an expired certificate and is fairly illegible on mobile.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]HipHomelessHomie 1 point2 points3 points 5 days ago\u00a0(0 children)That is my experience as well. In fact Intel have a framework for optimized inference performance on their CPUs that works very well. The generations of CPUs with AVX instructions can leverage these to get good inference performance.\nIn fact a company I worked with leveraged that to do edge inferencing on tiny not very powerful machines and it works great.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]axeonthra 2 points3 points4 points 6 days ago\u00a0(0 children)Depends on the metric and GPU\/CPU they are talking about. In my limited tests, GPUs (recent) are only minimally better than CPUs (recent, with AVX2) on a per $ basis. They are definitely faster by a significant margin though.\n\npermalinkembedsavereportgive awardreply[\u2013]gnulynnux 1 point2 points3 points 6 days ago\u00a0(2 children)I'm skeptical of GPU-level learning on a CPU. Can you provide more details?\n\npermalinkembedsavereportgive awardreply[\u2013]goldcakes 5 points6 points7 points 5 days ago\u00a0(1 child)It's CPU-level inference, not CPU-level learning. I have worked on deployments where we found CPU-only inference to be better value (on a per dollar basis) when you look at the total BOM, so I would not be surprised more optimized code allows for solid inference using CPUs only.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]gnulynnux 0 points1 point2 points 5 days ago\u00a0(0 children)Ahh, that makes more sense. Thank you!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]TrueLankinen 1 point2 points3 points 5 days ago\u00a0(0 children)This is a little bit out of context but do anyone know is there some free website online where I could make videos like their. It's great because they just use words so it doesn't even need fancy product to make that kind of video.\n\npermalinkembedsavereportgive awardreply[\u2013]CireNeikual 0 points1 point2 points 6 days ago\u00a0(0 children)It depends on whether they are just optimizing regular DL operations, or performing a different kind of learning entirely. With sparsity it is possible to train a reinforcement learning agent to play Atari Pong from pixels on a Raspberry Pi in real-time (our company has shown that, with source code available). If they are not exploiting sparsity then I have no idea whether it is legitimate or not.\n\npermalinkembedsavereportgive awardreply[\u2013]alexmlamb 0 points1 point2 points 5 days ago\u00a0(0 children)It might be an aquihire ploy too?  Like I'm not sure that Nervana ever had a clear plan to be financially sustainable, but it had a really good Intel acquisition.  \nI could see if a middle-tier company wants to have an AI lab, they might like to acquire a company like this which focuses on fast implementation and deployment, which they could then reorient towards their own application that they care about.\n\npermalinkembedsavereportgive awardreply[\u2013]bbateman2011 0 points1 point2 points 1 day ago\u00a0(0 children)It appears to be real, and have at least some use cases.  As others here have said, they are talking mainly about inference, and in their blogs etc. they specifically talk about taking advantage of sparse structures in inference.  \nThey have a patent application:  http:\/\/www.freepatentsonline.com\/y2019\/0138902.html\n\npermalinkembedsavereportgive awardreply[\u2013]johnyt3 0 points1 point2 points 6 days ago\u00a0(0 children)Upvoted for visibility because i\u2019m curious\n\npermalinkembedsavereportgive awardreply[\u2013]dasdull -1 points0 points1 point 5 days ago\u00a0(0 children)Nice try at marketing\n\npermalinkembedsavereportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 30116 on  r2-app-0b795575c8b440638  at 2019-11-14 21:52:57.049614+00:00 running 7ff3f3b country code: US."
  },
  "6":{
    "title":"[D] why softmax+CE over sigmoid+BCE? : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-funny-gaming-pics-tifu-movies-worldnews-aww-todayilearned-gifs-TwoXChromosomes-videos-OldSchoolCool-Jokes-Showerthoughts-mildlyinteresting-television-explainlikeimfive-science-LifeProTips-personalfinance-dataisbeautiful-history-nottheonion-IAmA-askscience-nosleep-sports-Futurology-books-Art-space-food-photoshopbattles-EarthPorn-UpliftingNews-DIY-WritingPrompts-Music-Documentaries-gadgets-GetMotivated-philosophy-listentothis-announcements-creepy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  08 Nov 201920 points (88% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave816,364 readers2,613 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X386  \u00b7 126 comments \"[D]\" John Carmack stepping down as Oculus CTO to work on artificial general intelligence (AGI)103  \u00b7 100 comments [D] Working on an ethically questionnable project...23  \u00b7 7 comments [R] Momentum Contrast for Unsupervised Visual Representation Learning: \"the gap between unsupervised and supervised representation learning has been largely closed\"11 [Research] We trained a self-balancing physics-based character to follow interactive motion capture.200  \u00b7 5 comments [R] NVIDIA's Kaolin: A PyTorch Library for Accelerating 3D Deep Learning Research4  \u00b7 1 comment [R] \"Compressive Transformers for Long-Range Sequence Modelling\", Rae et al 20193 [D][R] Applications of AI\/ML in the field of Digital Pathology13  \u00b7 8 comments [D] Thoughts about this conversation?9  \u00b7 2 comments [R] HOList: An Environment for Machine Learning of Higher-Order Theorem Proving2 [N] Awesome AI Research and Papers reviewed on Computer Vision News (with codes!) November 2019Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7192021Discussion[D] why softmax+CE over sigmoid+BCE? (self.MachineLearning)submitted 6 days ago by DeMorrrMost of the popular neural network language models use softmax+cross entropy loss during training, which is based on the assumption that only the target label is true, and everything else is false. But isn't language modeling a multilabel classification task? why sigmoid+BCE isn't used often?\n\n16 commentssharesavehidereportall 16 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]picardythird 10 points11 points12 points 6 days ago\u00a0(2 children)The motivation is that the output of the model is actually attempting to approximate the conditional probability of a word, conditioned on the previously seen words (and their ordering) , over the vocabulary. This probability distribution must sum to 1.\n\npermalinkembedsavereportgive awardreply[\u2013]WannabeMachine 2 points3 points4 points 6 days ago*\u00a0(1 child)To expand on this, formally, at each timestep, language models estimate P(w_i | w_1, ..., w_{i-1}) which is a multi-class problem, not multi-label.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]BatmantoshReturns 0 points1 point2 points 5 days ago*\u00a0(0 children)Regarding the definition of multi-label; would a multi-label problem would have estimates of multiple words? For example, in the case of 2 correct labels in a batch: \nP(wi, w_j | w_1, ..., w{i-1})\nIn this case, wouldn't either approach work? If using softmax+CE, you can set the probabilities equal to .5 for i and j. During training with negative sampling, you can set everything else to zero.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]SteveIsMyRapName 1 point2 points3 points 5 days ago*\u00a0(1 child)Although there are many possible words, you still only select one word for each position. Let\u2019s say the training data has two examples \u2018there is a cat\u2019 and \u2018there is a dog\u2019. During inference you may be given \u2018there is a\u2019. 50 percent of the time the model should select dog and 50 percent of the time the model should select cat. That can be achieved by sampling according to the logits instead of taking the argmax. In contrast, an image can have both a cat and a dog at the same time.\nAnyway, the difference is somewhat arbitrary. Maybe I\u2019m not thinking straight but for a multi-classification problem wouldn\u2019t a sigmoid network with class A and class B be very similar to a softmax network with three classes: class A, class B, and class A and B? Moreover I\u2019m sure I\u2019ve seen a proof which shows that there is a reparameterization such that a system trained with softmax is the same as sigmoid.\n\npermalinkembedsavereportgive awardreply[\u2013]BatmantoshReturns 0 points1 point2 points 5 days ago\u00a0(0 children)\nsigmoid network with class A and class B be very similar to a softmax network with three classes: class A, class B, and class A and B?\n\nI'm trying to expand this to language modeling, where you could have multiple correct labels, and negative samples. Say that in our batch we have 2 correct labels (or classes?) Class A, Class B , and 3 incorrect classes, Class D, Class E, Class G. For Sigmoid+BCE, you can see the true classes to 1, and false ones to zero. And another approach could be for the softmax, and set the probabilities equal to .5 for each true class, and zero for the negative samples, then use regular cross entropy. \nWhat would be the advantages\/disadvantages of these approaches?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]asobolev 0 points1 point2 points 5 days ago\u00a0(3 children)\nbased on the assumption that only the target label is true, and everything else is false\n\nNo, it's not. You can have several target labels for the same input, and the optimal solution, in that case, should assign some probability to all of them.\nInstead, the actual assumption of softmax + CE is that the sentence is generated one word at a time, and not by tossing a coin for each word independently for whether we'd like to take it.\n\npermalinkembedsavereportgive awardreply[\u2013]BatmantoshReturns 0 points1 point2 points 5 days ago\u00a0(2 children)I am wondering why sigmoid +BCE is used in word2vec then. \nhttps:\/\/youtu.be\/TaZz_K2xJy8?t=523\nSince the next word is being predicted, shouldn't a sampled softmax +CE be used?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]asobolev 0 points1 point2 points 5 days ago\u00a0(1 child)The particular moment you've linked talks about random variables y that says whether the word t matches the context c, it does not predict the next word. The very same slide mentions p(t|c) in the top row, which does predict the target token t given the context c, and thus uses softmax.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]BatmantoshReturns 0 points1 point2 points 5 days ago*\u00a0(0 children)I get it now, thanks!\nI am wondering which method to use for training question and answer similarity, where the questions and answers are represented by vectors, and a question could have more than one correct answer. \nSay that in a batch, I have the following questions and answers, each represented by a vector \nQuestions:\nWhat's in the sky?\nWhat appears at night? \nWhat's hot?\nAnswers:\nMoon\nSun\nFire\nCorrect Combinations:\nWhat's in the sky? Moon, Sun\nWhat appears at night? Moon\nWhat's hot? Fire, Sun. \nIn this batch, 'Moon' and 'Sun' are both answers to 'What's in the sky?', so the cos similarity of the question vector to the answer vectors should be trained equal to 1. But 'Fire' is not an answer to that question, so the cos similarity should be trained to equal to 0. \nThere are two approaches for this, one using sigmoid + BCE, another using softmax + CE.  \nSigmoid + BCE:\nAfter taking the dot products of all combinations, pass them through a sigmoid, and doing binary cross entropy loss with the correct label , 0 or 1. \nFor example:\npartialLoss1 =  - Log ( Sigmoid( DotProduct( Vector{What's in the sky}, Vector{Moon} ) ) )\npartialLoss2 =  - Log ( 1 - Sigmoid(  DotProduct( Vector{What's in the sky}, Vector{Fire} ) ) )\npartialLoss3 =  - Log ( Sigmoid(  DotProduct( Vector{What's in the sky}, Vector{Sun} ) ) )\nand do this for all the combinations of questions and answers. \nSoftmax + CE:\nIn this approach, a softmax is taken over each question and their answers combinations. For questions that have two correct answers, the softmax output should be .5 for each of correct answers. \nIf doing the softmax over all possible dot products of answers for 'What's in the sky?', the softmax probabilities should be .5 for 'Moon' , .5 for 'Sky', and 0 for 'Fire'. \nAnd this the loss for the output labels and the softmax probabilities can be calculated with regular cross entropy. \nFor example:\npartialLoss1 = .5*Log( SoftmaxProbability{  Vector{What's in the sky}, Vector{Moon} } )\npartialLoss2 = .5*Log( SoftmaxProbability{  Vector{What's in the sky}, Vector{Sun} } )\npartialLoss3 = 0*Log( SoftmaxProbability{  Vector{What's in the sky}, Vector{Fire} } )\nAre both these approaches correct? If so, what are the advantages and disadvantages to each one?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]BatmantoshReturns 0 points1 point2 points 5 days ago\u00a0(4 children)I have been wondering about this myself over the last couple days. \n\nMost of the popular neural network language models use softmax+cross entropy loss during training, which is based on the assumption that only the target label is true, and everything else is false\n\nCouldn't cross entropy can be used for multi classes ?\nhttps:\/\/stats.stackexchange.com\/questions\/260505\/machine-learning-should-i-use-a-categorical-cross-entropy-or-binary-cross-entro\nSo I think for the example of 2 correct classes, the labels should be .5. And for this approach, it might do better with a higher learning rate, since the gradients wouldn't be a large for the 0 or 1 labels for sigmoid+BCE.\nWhere is softmax+CE used more? word2vec uses sigmod+BCE.\n\npermalinkembedsavereportgive awardreply[\u2013]cthorrez 0 points1 point2 points 3 days ago\u00a0(3 children)I can't remember the exact model, might be bert or elmo or something but some paper \"softened\" the softmax by like putting 0.9 on the target word and split the 0.1 over the rest of the words to try to stop it from saturating the softmaxes.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]BatmantoshReturns 0 points1 point2 points 2 days ago\u00a0(2 children)hmm , I wonder what was the goal of doing that? What does saturating the softmaxes mean?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]cthorrez 0 points1 point2 points 2 days ago\u00a0(1 child)Saturating the softmax is when the weights make the score for one class essentially 1 and 0 for all the others. Intuitively this is what you want in normal classification settings but if I remember correctly it made gradient flow bad or something in this case. \nMan I really wish I could remember where I saw that.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]BatmantoshReturns 0 points1 point2 points 2 days ago\u00a0(0 children)\nI remember correctly it made gradient flow bad or something in this case.\n\nhmm interesting, if cross entropy loss comes afterwards, then you would have a cross entropy term for all the classes, not just the correct class. Sounds like it could get computationally very expensive though.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]techlos 0 points1 point2 points 4 days ago\u00a0(0 children)i've done some experiments using sigmoid+BCE for image classification on cifar10 in the past - i found the best strategy was to use the true label for the correct class, and noisy smoothed labels for the false classes using uniform noise between 0 and 0.5. The results were never as good as softmax+CE loss in terms of overall accuracy, however it was surprisingly resilient to adversarial attacks compared to the usual softmax training.\n\npermalinkembedsavereportgive awardreply[\u2013]MrAcurite 0 points1 point2 points 2 days ago\u00a0(0 children)Something that might help you re-kajigger your conception of what's going on is knowing about the beam search algorithm. Read up on it a bit, if you're interested.\nBut the short version of the explanation is that you don't really care how good or bad each next word is on their own, but rather which words are the most likely out of all of them. So, because you're trying to get a probability distribution instead of a word-by-word rating, you need softmax.\n\npermalinkembedsavereportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 23234 on  r2-app-0c88321715d29f726  at 2019-11-14 20:59:09.626034+00:00 running 6a8641e country code: US."
  },
  "7":{
    "title":"[P] Art Valuation Bot : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-funny-gaming-pics-tifu-movies-worldnews-aww-todayilearned-gifs-TwoXChromosomes-videos-OldSchoolCool-Jokes-Showerthoughts-mildlyinteresting-television-explainlikeimfive-science-LifeProTips-personalfinance-dataisbeautiful-history-nottheonion-IAmA-askscience-nosleep-sports-Futurology-books-Art-space-food-photoshopbattles-EarthPorn-UpliftingNews-DIY-WritingPrompts-Music-Documentaries-gadgets-GetMotivated-philosophy-listentothis-announcements-creepy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  22 Oct 20193 points (81% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave816,387 readers2,637 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X135  \u00b7 111 comments [D] Working on an ethically questionnable project...398  \u00b7 136 comments \"[D]\" John Carmack stepping down as Oculus CTO to work on artificial general intelligence (AGI)31  \u00b7 7 comments [R] Momentum Contrast for Unsupervised Visual Representation Learning: \"the gap between unsupervised and supervised representation learning has been largely closed\"11 [Research] We trained a self-balancing physics-based character to follow interactive motion capture.200  \u00b7 5 comments [R] NVIDIA's Kaolin: A PyTorch Library for Accelerating 3D Deep Learning Research5  \u00b7 1 comment [R] \"Compressive Transformers for Long-Range Sequence Modelling\", Rae et al 201916  \u00b7 8 comments [D] Thoughts about this conversation?3  \u00b7 1 comment [D][R] Applications of AI\/ML in the field of Digital Pathology8  \u00b7 2 comments [R] HOList: An Environment for Machine Learning of Higher-Order Theorem Proving[D] Online paper reading \/ note taking software?Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7234Project[P] Art Valuation Bot (self.MachineLearning)submitted 23 days ago by amouravI need to develop a small project for a data science bootcamp interview next week (insightdatascience.com). \nOne idea I had was to create an art valuation bot and art generation bot. The outline would look something like this:\n\nScrape abstract art data (image and price data) from an art sales website.\nUse a pretrained network and fine-tune it on my dataset for price regression.\nGreate a GAN on the same dataset, then uses it to generate novel art images.\nEvaluate GAN with the price regression model to determine the newly generated pieces with the highest predicted value.\n\nSome potential challenges I see:\n\nImage size: Resizing the dataset to have a standard resolution will really affect the appearance of the newly generated images. Can I do without this? Perhaps I will resize while maintaining the original aspect ratio.\nNoise: Given that I don't have access to an art valuation dataset and am just trying to train based on an art sales website, the price does not necessarily indicate that the art piece is valuable. Hopefully, there is enough signal in the dataset to offset this effect.\n\nDoes anyone have thoughts on project-based data science boot camps like Insight Data Science (https:\/\/www.insightdatascience.com\/ )\nIf you see any more potential issues with my project outline, or have a suggestion for improving it, please leave a comment or PM :)\n\n13 commentssharesavehidereportall 13 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]sheeplearning 2 points3 points4 points 23 days ago\u00a0(2 children)Just look at the meta-data (artist, year, movement) and predict the price. What is in the painting usually has very little to do with the price of an artwork but when you have a hammer..\n\npermalinkembedsavereportgive awardreply[\u2013]amourav[S] 0 points1 point2 points 23 days ago\u00a0(1 child)Hmm. If I'm not relying on images, I might need a more robust dataset. I might go down this road if I find a good dataset\/source. More datasets with that level of context\/information is not free :(\n\npermalinkembedsaveparentreportgive awardreply[\u2013]chief167 0 points1 point2 points 22 days ago\u00a0(0 children)I wouldn't rely on images anyway. For example, there are a lot of painters who are able to nearly perfectly replicate common artworks such as Van Gogh's sunflowers and Mona Lisa. Those are also worth something, but definitely not as much as the real thing\n\npermalinkembedsaveparentreportgive awardreply[\u2013]TheRedmanCometh 2 points3 points4 points 23 days ago\u00a0(1 child)double value = ThreadLocalRandom.current().nextDouble(1000000);\n\u200b\ndone\n\npermalinkembedsavereportgive awardreply[\u2013]amourav[S] 0 points1 point2 points 22 days ago\u00a0(0 children)\nThreadLocalRandom.current().nextDouble(1000000);\n\naiming for above chance :)\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Quantum_Network 1 point2 points3 points 23 days ago\u00a0(3 children)Do you think you'll have enough data to train a GAN? And overall, data might be a challenge in this project.\nBut you could train from web-scraped data (like from https:\/\/www.liveauctioneers.com\/c\/art\/1\/) and hopefully it should work out.\n\npermalinkembedsavereportgive awardreply[\u2013]amourav[S] 0 points1 point2 points 23 days ago\u00a0(2 children)\nk you'll have enough data to train a GAN? And overall, data might be a challen\n\nYeah. Training on web scraped data is the goal. How many samples should I aim for.\nI also see another potential issue, cropping out the frames :P\n\npermalinkembedsaveparentreportgive awardreply[\u2013]cheruboftheabyss 2 points3 points4 points 23 days ago\u00a0(1 child)You dont necessarily have to crop out the frames, the generator will just model them then too, and you will have to crop them after the generation process (which will most likely involve some cherry picking anyway, if you dont want to spend a lot on gpus).\nI would probably aim at about 5-40k images (depndes on the diversity of your images), but you can also augment your dataset with the wikiart dataset (25.4GB).\nThe biggest problem with your idea will most likely be the price regression, since predicting the price of art pieces involves a lot of complicated 'human' background knowledge (emotional effectiveness, quality of  artistic realization, price of materials, ...), which is not the case in most standard computervision tasks, where in some cases only the texture is important (there is some interesting research on that specific topic by the way).\n\npermalinkembedsaveparentreportgive awardreply[\u2013]amourav[S] 1 point2 points3 points 23 days ago\u00a0(0 children)Thanks! \nI agree, much of the task is related to 'human' factors and context, but I'm hoping there is something else, maybe some X factor, or artistic style that seems to be more valued. That's why I'm only planning to train on abstract art pieces. I'm not aiming as much for good accuracy, more of a proof of concept (above random chance).\n\npermalinkembedsaveparentreportgive awardreply[\u2013]horace999 1 point2 points3 points 22 days ago\u00a0(1 child)That's way more than you need to do for pre-insight. Focus on making the end product good and usable rather than such complicated backend stuff\n\npermalinkembedsavereportgive awardreply[\u2013]amourav[S] 0 points1 point2 points 22 days ago\u00a0(0 children)Thanks for the advice!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]shaggorama 1 point2 points3 points 16 days ago\u00a0(1 child)If you already have the knowledge to build something like this, what do you hope to learn from the bootcamp?\n\npermalinkembedsavereportgive awardreply[\u2013]amourav[S] -1 points0 points1 point 14 days ago\u00a0(0 children)It's a chance to make connections with companies that are hiring and network with other professionals.\n\npermalinkembedsaveparentreportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 11088 on  r2-app-052d8ec9d906544ae  at 2019-11-14 21:46:14.025768+00:00 running 6e1acb2 country code: US."
  },
  "8":{
    "title":"[P] Fast Super Resolution GAN : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-funny-gaming-pics-tifu-movies-worldnews-aww-todayilearned-gifs-TwoXChromosomes-videos-OldSchoolCool-Jokes-Showerthoughts-mildlyinteresting-television-explainlikeimfive-science-LifeProTips-personalfinance-dataisbeautiful-history-nottheonion-IAmA-askscience-nosleep-sports-Futurology-books-Art-space-food-photoshopbattles-EarthPorn-UpliftingNews-DIY-WritingPrompts-Music-Documentaries-gadgets-GetMotivated-philosophy-listentothis-announcements-creepy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  27 Oct 201963 points (92% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave816,425 readers2,845 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X165  \u00b7 118 comments [D] Working on an ethically questionnable project...411  \u00b7 148 comments \"[D]\" John Carmack stepping down as Oculus CTO to work on artificial general intelligence (AGI)40  \u00b7 7 comments [R] Momentum Contrast for Unsupervised Visual Representation Learning: \"the gap between unsupervised and supervised representation learning has been largely closed\"17 [Research] We trained a self-balancing physics-based character to follow interactive motion capture.198  \u00b7 5 comments [R] NVIDIA's Kaolin: A PyTorch Library for Accelerating 3D Deep Learning Research16  \u00b7 10 comments [D] Thoughts about this conversation?5  \u00b7 1 comment [R] \"Compressive Transformers for Long-Range Sequence Modelling\", Rae et al 20193  \u00b7 1 comment [D][R] Applications of AI\/ML in the field of Digital Pathology10  \u00b7 2 comments [R] HOList: An Environment for Machine Learning of Higher-Order Theorem Proving[R] Confidence Estimation for Black Box Automatic Speech Recognition Systems Using Lattice Recurrent Neural NetworksWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7626364Project[P] Fast Super Resolution GAN (self.MachineLearning)submitted 18 days ago by abnormdistI've been super intrigued by image super resolution problems. Reading online, I found the SRGAN paper to be interesting, especially how the PSNR and SSIM metrics are unreliable when compared to human perception of quality. I wanted to create a faster version of the SRGAN, so I decided to use a MobileNet as the generator. This idea is somewhat inspired by Realtime Image Enhancement, Galteri et al. I want to use it to upsample low quality videos, for scenarios when you may not have access to high speed internet. You can leverage the GPU to do synthetic super resolution. I would appreciate any ideas towards increasing speed\/quality of this project.\nHere is the implementation in Tensorflow 2.0: Fast-SRGAN. Take a look, and feedback is really appreciated!\n\n33 commentssharesavehidereportall 33 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]ArkaonGP 6 points7 points8 points 17 days ago\u00a0(7 children)Interesting work. Congrats.\nDid you consider to implement some of the tricks proposed by the ESRGAN paper?\n\npermalinkembedsavereportgive awardreply[\u2013]abnormdist[S] 3 points4 points5 points 17 days ago\u00a0(6 children)I really want to. One thing that's holding me back is that I can't find a pretrained tf\/keras VGG19 which allows pre-activation feature selection. All I found online use specify the \"activation\" parameter in the conv function. And to implement the ESRGAN tricks, I need the pre activation features. So I'll have to train a VGG19 on imagenet myself, but I don't have the resources to.\nApart from that, I find the idea of Wasserstein GANs very interesting.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]AlexiaJM 1 point2 points3 points 17 days ago\u00a0(1 child)ESRGAN actually uses Relativistic GAN which is trivial to implement.\nPenalizing the gradient (as in WGAN) is very helpful to prevent mode collapse, but I'm not sure that it would be helpful when you actually don't care about diversity (which is the case in super resolution). In super-resolution you don't want to sacrifice even a little bit of quality for more diversity.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]abnormdist[S] 2 points3 points4 points 17 days ago\u00a0(0 children)Yep, I agree. I should've said relativistic GANs, just blurted WGAN because they are a subset of the RGANs.\n\npermalinkembedsaveparentreportgive awardreply[\u2013][deleted] 17 days ago\u00a0(3 children)[deleted]\n\n[\u2013]abnormdist[S] 1 point2 points3 points 17 days ago\u00a0(2 children)I can. But I don't think it works in this case. Typical VGG19 models I found on the internet use convolution like this:\nForgive the poor pseudo code:\nx = deeplearningframework.Conv2d(out_filters, kernel_size, strides, ACTIVATION=RELU)(x)\n\u200b\nI'm not really sure how I can extract the feature maps from this layer before the activation. Since I believe the ops are fused for faster computation? I'm not sure if the ops are not fused, I'll need to see, because if they aren't, then it should be easy.\n\npermalinkembedsavereportgive awardreply[\u2013][deleted] 17 days ago\u00a0(1 child)[deleted]\n\n[\u2013]abnormdist[S] 1 point2 points3 points 17 days ago\u00a0(0 children)Du-OH! I don't know why I didn't think of that. Thanks for that!\n\npermalinkembedsavereportgive awardreply[\u2013]lendacerda 1 point2 points3 points 17 days ago\u00a0(1 child)I didn't find many papers on it when i was researching on it as well. But for one, you have to use as high resolution images as you can and as many images to train the network. Basic stuff.\nWhat i did find tho is that you can do something similar to Non-Local Means Denoising: find similar areas on the screen and use one area's information on another area. Render the new pixels using it's neighbours as a guide. Might be a bad explenation but just google \"NonLocalMeansDenoising OpenCV\"\nAlso you might need some temporal features, as the super-resolution thing might diverge too much from one frame to another (e.g one edge is red in one frame and than slightly darker on the next frame, hitching colors)\nHere are some links:\nhttps:\/\/www.youtube.com\/watch?v=HvH0b9K_Iro (has source code link in the comments)\nhttps:\/\/www.youtube.com\/watch?v=WovbLx8C0yA  (uses NLMD approach)\n\npermalinkembedsavereportgive awardreply[\u2013]abnormdist[S] 2 points3 points4 points 17 days ago\u00a0(0 children)I like how you're thinking in the frame of reference of a video. I like your ideas! They will come in handy.\nCurrently I simply trained the GAN on div2k (high quality image dataset). But it's not too big a dataset (only 800 images).\nI'll go through the videos, sounds interesting for videos.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]alvisanovari 1 point2 points3 points 17 days ago\u00a0(11 children)Nice! Are there instructions to run inference on the pre-trained model? Maybe a Colab you can share?\n\npermalinkembedsavereportgive awardreply[\u2013]abnormdist[S] 4 points5 points6 points 17 days ago\u00a0(9 children)I didn't provide a sample code for inference. Totally my bad. I'll add it soon!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]BobFloss 0 points1 point2 points 17 days ago\u00a0(8 children)Please do. Every time I see a repo where they only show how to train the model, I feel like they're just full of shit. I'm not saying you are, that's just what my gut says, because clearly you have to have the code to actually do the upscaling or you wouldn't have had results to share. Nobody wants to have to duplicate the effort of writing the code just to try a model out. It also stunts future efforts because it makes it harder to compare your model to others. Your model might even be really great, but if nobody can try it without going out of the way to see if it even works, it could be left in the dust by something that's not even any good, simply because people can actually use it easily.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]abnormdist[S] 2 points3 points4 points 17 days ago\u00a0(0 children)True, I didn't publish the visualization code since it was pretty badly written to get the repo up quick. I'll provide a cleaner version soon. Thanks for the feedback.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]abnormdist[S] 2 points3 points4 points 17 days ago\u00a0(6 children)Update: The code to infer on your images is now there, hope you have fun testing it out.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]FreckledMil 1 point2 points3 points 16 days ago\u00a0(2 children)Do you happen to have a version that works on any hosted notebooks? just wondering. Seems to be a waterfall of issues related to python versions and TF when I just tried to.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]abnormdist[S] 0 points1 point2 points 15 days ago\u00a0(1 child)I don't think I want to go through the hassle of supporting colab notebooks. Because then I have to answer questions related to Colab functionality which I'm not responsible for.\nThe infer code will run on your cpu even, so you can rest it out locally if you have decent ram in your machine.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]FreckledMil 0 points1 point2 points 15 days ago\u00a0(0 children)Fair enough, thanks for reply. was just curious.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]BobFloss 1 point2 points3 points 15 days ago\u00a0(0 children)Glad to hear it, I'll be trying it soon!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]alvisanovari 0 points1 point2 points 9 days ago\u00a0(1 child)This is awesome! Great job! :)\nI made a Colab in case it comes in handy: https:\/\/colab.research.google.com\/drive\/1vdNx-snivEBGqzbX1AaZV7sP4Znd1xJT\nQuick note: Looks like you are importing dataloader unnecessarily and it's throwing an error. I'd take the first line out in infer.py.\nAgain - this is awesome! :)\n\npermalinkembedsaveparentreportgive awardreply[\u2013]abnormdist[S] 0 points1 point2 points 9 days ago\u00a0(0 children)Thanks for the notebook. Some people here were asking for it as well.\nAlso thanks for the import bug, I already pushed a fix.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]abnormdist[S] 0 points1 point2 points 17 days ago\u00a0(0 children)Update: the code for inference on your own images is provided. Have a look at infer.py.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]fdskjflkdsjfdslk 1 point2 points3 points 17 days ago\u00a0(1 child)Cool stuff.\n\nI want to use it to upsample low quality videos, for scenarios when you may not have access to high speed internet.\n\nThis could also be useful in other scenarios (e.g. if you only have a low resolution version of a video to begin with).\n\npermalinkembedsavereportgive awardreply[\u2013]abnormdist[S] 1 point2 points3 points 17 days ago\u00a0(0 children)True, the applications seem interesting.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]saynay 1 point2 points3 points 16 days ago\u00a0(1 child)I was looking in to a similar thing a few weeks ago.\nSpecifically for SR on video, I found this paper interesting, and wondered if it would be possible to adapt a MobileNet backbone to it. Unfortunately, I am not nearly proficient enough yet to attempt that.\n\npermalinkembedsavereportgive awardreply[\u2013]abnormdist[S] 0 points1 point2 points 16 days ago\u00a0(0 children)Looks interesting. But also seems PSNR focused. The architecture and ideas seem highly relevant. Thanks for sharing.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]shikhragimov 0 points1 point2 points 15 days ago\u00a0(1 child)Do you plan to use some seq2seq approach?\nVideo frames depends on the previous vidoeframe. This could give a better result than just enhancing a frames separately.\nAlso you should predict scene changing\n\npermalinkembedsavereportgive awardreply[\u2013]abnormdist[S] 0 points1 point2 points 15 days ago\u00a0(0 children)That would be a future direction. The first step was to be realtime on individual frames.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]shikhragimov 0 points1 point2 points 15 days ago\u00a0(1 child)if you could - make the comparison with original SRGAN and ESRGAN (speed and quality).\nGreat work\n\npermalinkembedsavereportgive awardreply[\u2013]abnormdist[S] 0 points1 point2 points 15 days ago\u00a0(0 children)Speed makes sense. Not sure about the quality. Since higher PSNR and SSIM scores don't necessarily mean better looking images to a human.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]howdoireachthese 0 points1 point2 points 17 days ago\u00a0(2 children)Very timely, I'm just about to do a project on the topic and would love to see how this measures up\n\npermalinkembedsavereportgive awardreply[\u2013]abnormdist[S] 2 points3 points4 points 17 days ago\u00a0(0 children)Awesome, glad this is useful!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Bazzert_One 1 point2 points3 points 15 days ago\u00a0(0 children)interesting field.\nHere is the papers with code chart for recent models:\nhttps:\/\/paperswithcode.com\/sota\/image-super-resolution-on-bsd100-4x-upscaling\nand a couple papers about SR as a whole:\nhttps:\/\/arxiv.org\/abs\/1904.07523\nhttps:\/\/arxiv.org\/abs\/1808.03344\n\npermalinkembedsaveparentreportgive awardreply[\u2013]MaxTalanov 0 points1 point2 points 17 days ago\u00a0(1 child)Nice work, I was actually looking for something like this!\n\npermalinkembedsavereportgive awardreply[\u2013]abnormdist[S] 1 point2 points3 points 17 days ago\u00a0(0 children)Yay!\n\npermalinkembedsaveparentreportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 25787 on  r2-app-0cc8d801970037458  at 2019-11-14 22:40:43.438424+00:00 running cfe41af country code: US."
  },
  "9":{
    "title":"[D] Statistical Physics and Neural Networks question. : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-funny-gaming-pics-tifu-movies-worldnews-aww-todayilearned-gifs-TwoXChromosomes-videos-OldSchoolCool-Jokes-Showerthoughts-mildlyinteresting-television-explainlikeimfive-science-LifeProTips-personalfinance-dataisbeautiful-history-nottheonion-IAmA-askscience-nosleep-sports-Futurology-books-Art-space-food-photoshopbattles-EarthPorn-UpliftingNews-DIY-WritingPrompts-Music-Documentaries-gadgets-GetMotivated-philosophy-listentothis-announcements-creepy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  08 Nov 2019154 points (95% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave816,423 readers2,833 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X166  \u00b7 118 comments [D] Working on an ethically questionnable project...405  \u00b7 148 comments \"[D]\" John Carmack stepping down as Oculus CTO to work on artificial general intelligence (AGI)42  \u00b7 7 comments [R] Momentum Contrast for Unsupervised Visual Representation Learning: \"the gap between unsupervised and supervised representation learning has been largely closed\"17 [Research] We trained a self-balancing physics-based character to follow interactive motion capture.196  \u00b7 5 comments [R] NVIDIA's Kaolin: A PyTorch Library for Accelerating 3D Deep Learning Research18  \u00b7 10 comments [D] Thoughts about this conversation?4  \u00b7 1 comment [R] \"Compressive Transformers for Long-Range Sequence Modelling\", Rae et al 20193  \u00b7 1 comment [D][R] Applications of AI\/ML in the field of Digital Pathology9  \u00b7 2 comments [R] HOList: An Environment for Machine Learning of Higher-Order Theorem Proving[R] Confidence Estimation for Black Box Automatic Speech Recognition Systems Using Lattice Recurrent Neural NetworksWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7153154155Discussion[D] Statistical Physics and Neural Networks question. (self.MachineLearning)submitted 6 days ago * by AlexSnakeKingIf you look at the theoretical physics literature, there's a ton of research being done on the statistical physics of neural networks and the statistical physics of deep learning, etc...where they use analogies between spin glasses and condensed matter models to get to all sorts of theoretical results about neural networks.\nTo be clear, I'm not talking about studies were neural nets were used to model and solve a problem in statistical physics. I'm thinking about the line of research were the mathematics of statistical physics and spin glasses are used as frameworks to analyze the behavior of neural nets, and then arrive at conclusions like \"The loss surface of neural nets have this particular topological property\" or \"CNN show a phase transition when the number of classes jumps from x to y\", etc.....\nMy question is: Did any of these theoretical results from the analysis of neural nets using methods from physics ever lead to any practical results, such as a faster training algorithm, or  improved generalization ability, etc....?\nAs far as I can tell: No, none of the popular NNet models incorporate results from these physics inspired studies. All the improvements come from purely mathematical insights, or originally from biological insights.\nBut I might be wrong: Did any of the significant practical developments in NNets and Deep Learning  (better activation functions, training algorithms, regularizations methods,...) stem from the statistical physics approaches?\n\n47 commentssharesavehidereportall 47 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]mec_con 59 points60 points61 points 5 days ago\u00a0(15 children)Hey, I worked a bit on this myself. Personally I'd say the field is still very young (even though a lot of what we see today actually started in the 80s), and that most of the discoveries are of theoretical interest, thus not necessarily practical. You are right for instance that none of this progress has yet been translated into something that has become mainstream in deep learning.\nThat being said, lots of theoretical questions are also practical. You can ask yourself, for instance, why is one architecture better than another? If you are able to answer such a question, you will have a better idea of what to do once you face a real problem. In other words, you won't have to try lots of different architectures and perform cross validation or whatever.\nStatistical physics can actually be used in different ways for this. For the approach you mentioned, based on spin glasses, the main idea typically is to study, on an idealized setting (e.g. assuming data comes from a certain distribution), what is the average performance one obtains using a certain class of networks. This can be seen already in older works from the 80\/90s by Gardner, M\u00e9zard, Opper and more recently in works by people such as Montanari, Zdeborov\u00e1 and Krzakala. Another line of work uses a more dynamical approach to understand how a given input propagates through a random neural network and is able to derive, from this, some general properties the network will have. You can see this in works by Ganguli, Pennington, Schoenholz, Yang, Karakida and so on, but also this can be tracked to older works by people such as Amit. Yet another approach which is perhaps worth of mention is the development of better approximate Bayesian inference algorithms, which could be used e.g. for Bayesian deep learning, but these have not yet shown to be practical in larger problems (these are known as TAP equations, or approximate message-passing in the recent literature).\nThis idealized setting, in which lots of things are random, is still a big issue for many of these works, but the assumptions are being relaxed little by little. This is why I say the field is still young , because we see year after year that progress is being made, even if there's still no groundbreaking approach that translates all of this into a big practical gains. But who knows, it might be around the corner... That was everyone's hope when I used to work in this field.\n\npermalinkembedsavereportgive awardreply[\u2013]bohreffect 15 points16 points17 points 5 days ago\u00a0(5 children)I'm curious, what are you thoughts on the combinatorial topologists' take on neural networks? Specifically in reference in the Manifold Hypothesis and viewing NN layers as a knot-theory problem in rendering data linearly separable?\nI appreciate the differential geometry perspective, but I just keep getting this gut feeling that no one wants to touch the combinatorial aspects of NN architectures, i.e. number and width of layers, combinations of activation functions, etc by casting everything in the limit.\nedit: I'm just a super casual in this area and would be great to co-opt someone's take for lab meetings.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]StellaAthena 12 points13 points14 points 5 days ago*\u00a0(3 children)Mathematician, but not a theoretical physicist here: I think Taco Cohen and his collaborators have done phenomenal work on manifold and gauge invariant CNNs. If I had to give an award for best theoretical DL research in the world, it would be them. Their framework is revolutionary on both a theoretical and an applied level.\nI think you\u2019re right about combinatorial approaches being eschewed because nobody wants to do the number crunching, but the end of your sentence confuses me. What did you mean about limits? Are you referencing recent work on infinitely wide neural networks?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]bohreffect 1 point2 points3 points 5 days ago\u00a0(2 children)Oh, yeah, bad grammar there. Yeah, as opposed to the combinatorial problems; sure things like infinitely wide networks, but also just limits in the analytical sense. Loss surfaces, geometry of each layer viewed as a diffeomorphism, etc.\nGauge theory is super fascinating but so far above my paygrade, I hate knowing that there's impactful math like that that won't be accessible to me in my lifetime.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]StellaAthena 1 point2 points3 points 5 days ago\u00a0(1 child)One thing in a more combinatorial direction you might be interested in is I am looking at how the network structure\u2019s graph theoretical properties influence the set of expressible functions. So fix some set of graphs {G_i} and only build networks with those structures. What interesting things can we say about expressible functions? If we go from using {G_i} to using {H_i}, where G_j and H_j have some known relationship (day H_j is G_i with one edge deleted) what can we say about how much we lose \/ gain moving from using G_i fo H_i. It\u2019s still pretty preliminary, but there are positive signs.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]MemeBox 0 points1 point2 points 4 days ago\u00a0(0 children)On the practical side - I have wondered how much of the success of transfer learning is down to the set of graphs that are prevalent within the network? Can we simply produces networks that express certain graphs at certain rates and produce networks that operate out of the box a la reservoir learning? Or are much quicker to learn to train for a given domain? I would imagine that this is the approach of biology, the overall structure of the networks determines the kind of problem that the network is best suited to solving. Maybe you could use a GAN to generate new networks...\n\npermalinkembedsaveparentreportgive awardreply[\u2013]clueless_scientist 1 point2 points3 points 5 days ago\u00a0(0 children)\nviewing NN layers as a knot-theory problem in rendering data linearly separable?\n\nYou're talking about that one demonstration in the Cris Colah blog? The trick is that knots have interesting behaviour only in low-d space. So, that example looked fascinating, but was too low-d and gave a false analogy imho.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]maxToTheJ 11 points12 points13 points 5 days ago*\u00a0(3 children)Also OP is making a bad assumption about how theory works. The word \u201csignificant\u201d is a big red flag for ambiguity which could lead to goal post moving \nA) Not all theory is going to be felt day by day . If a theoretician proves some assumption like about convergence ect that the community has taken for granted will it really matter? What if the proof is especially hard to follow for the ML community then it will obviously end up with an ignore or \u201cill take your word for it situation \nB) what if you come up with something practical but it is based on complicated theory? People adopt the intuitive stuff that is easy to apply first and then the more difficult stuff in their field and lastly the relevant stuff in other fields. This leaves complicated stuff outside of the ML mainstream absolutely in the back of the line.\nC) Lets be honest the ML community is super \u201chypebeast\u201d ish . A while ago RBM were hot and it would be way more obvious the answer to OPs question.\nIf you want an example here\nhttps:\/\/pypi.org\/project\/WeightWatcher\/\n\npermalinkembedsaveparentreportgive awardreply[\u2013]AlexSnakeKing[S] 3 points4 points5 points 5 days ago\u00a0(2 children)\"Also OP is making a bad assumption about how theory works. The word \u201csignificant\u201d is a big red flag for ambiguity which could lead to goal post moving\" - I disagree.\nHere's why: Several of the same authors who worked on the intersection of stat. physics and spin glasses and neural networks also worked on the intersection of stats physics and spin glasses and optimization. But in the optimization realm, several practical algorithms came out of the community, such as Simulated Annealing and Survey Propagation. I think it is legitimate and unambiguous to ask why hasn't the same happened with their work on NNets?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]maxToTheJ 2 points3 points4 points 5 days ago\u00a0(0 children)\nHere's why: Several of the same authors who worked on the intersection of stat. physics and spin glasses and neural networks also worked on the intersection of stats physics and spin glasses and optimization.\n\nWhat is the motivation for the assumption that it has to be the exact same authors that had success with optimization to be the ones that do so in NNs?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Fujikan 1 point2 points3 points 4 days ago\u00a0(0 children)Not jus SA and SP, but also Expectation Propagation and Approximate Message Passing have had a significant impact in a number of fields. There are many other meaningful techniques to come out of the literature, besides :)\n\npermalinkembedsaveparentreportgive awardreply[\u2013]the_new_scientist 4 points5 points6 points 5 days ago\u00a0(1 child)I'm quite interested in this topic, and I agree with you, though the seeds of these ideas were generated decades ago, the field is quite young.\nI've seen some research recently that used tools from stat mech to analyze the stochastic block model, and track phase transitions in the computational hardness of it.\nCurious as to what you worked on?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]mec_con 1 point2 points3 points 5 days ago\u00a0(0 children)Yes the tools used to analyze the SBM are the same used in the first point I mentioned above.\nI have worked mostly on the first and third topics I mentioned (using spin glass techniques to analyze inference problems, as well as message-passing algorithms to solve them in practice).\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Diffeologician 0 points1 point2 points 5 days ago\u00a0(1 child)\nYet another approach which is perhaps worth of mention is the development of better approximate Bayesian inference algorithms, which could be used e.g. for Bayesian deep learning, but these have not yet shown to be practical in larger problems (these are known as TAP equations, or approximate message-passing in the recent literature).\n\nDo you have a reference on this? I\u2019d be interested in how this relates to the notions of message passing I\u2019ve seen in PL literature.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]mec_con 0 points1 point2 points 5 days ago\u00a0(0 children)You can maybe take a look here: https:\/\/arxiv.org\/pdf\/1511.02476.pdf. I'm not sure what notions of message-passing you are thinking about, but it's quite related for instance to belief propagation, and not at all related to message-passing as in MPI.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Fujikan 0 points1 point2 points 4 days ago\u00a0(0 children)\nlarge problems\n\nZdeborova & Krzakala's group have been progressing further and further into more practical ML systems. When I left we had some good work and understanding on practical-scale RBMs, and from there into Deep Boltzmann Machines. For more interesting multi-layer networks, indeed, their latest works with Gabri\u00e9 or Gold would be of interesting. Also, as mentioned somewhere else in these comments, R. Zecchina has been doing work in this area and had a number of interesting results with his co-authors. \n\u200b\n\nBut who knows, it might be around the corner... That was everyone's hope when I used to work in this field.\n\nLiterally every result was \"This is gonna be it!\" but somehow never quite gains traction :P Sometimes the resulting algorithms are a little bit cumbersome in terms of efficient implementation, so it seems like other works turned to just trying to better understand the dynamics of conventional stochastic optimization rather than deriving new frameworks. A little bit of a shame, perhaps!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]NichG 14 points15 points16 points 5 days ago\u00a0(3 children)Boltzmann machines are probably the most relevant current example I can think of, even if they're getting obsolete now for the most part. Hopfield networks are an older case - you can calculate their storage capacity with stat phys methods that you would use to calculate the memory of a spin glass.\nIt's a bit more murky, but there are stat phys calculations that let you determine the properties of infinitely deep neural networks if they have homogeneous architectures. That in turn lets you determine good initializations for stable gradients. But stat phys is one of a number of ways to derive that.\nI'd also argue that designing architectures with arbitrary invariants makes more sense in terms of the way physics handles symmetries, gauge fields, etc than the popular account of e.g. 'we use convolutions because the human visual system has a columnar structure'. The formalism lets you work out how to make other invariances: permutation invariant, rotation invariant, scale invariant, invariant under discrete symmetries, etc. There are a number of papers that use those constructions to make conv-net equivalents for their domains without needing a biological analogue to copy from. But you could argue that's group theory rather than physics.\n\npermalinkembedsavereportgive awardreply[\u2013]twesterhout 2 points3 points4 points 5 days ago\u00a0(2 children)Any chance you could point me to some papers which manage to impose invariance under discrete symmetries?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]NichG 6 points7 points8 points 5 days ago\u00a0(1 child)We actually did one for permutation invariance (https:\/\/arxiv.org\/abs\/1612.04530), which is a discrete symmetry. There have been a number of followup papers by other groups which have improved the initial result, and it's worth noting that attention layers also obey this symmetry.\nThere are more general recipes for other symmetries in https:\/\/arxiv.org\/abs\/1602.07576 and http:\/\/papers.nips.cc\/paper\/5424-deep-symmetry-networks.pdf. The former includes a reflection-invariant convolution operation, for example.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]StellaAthena 1 point2 points3 points 5 days ago\u00a0(0 children)Cohen et al. also have a paper extending their manifold geometry ideas to local geometry using gauge theory: https:\/\/arxiv.org\/pdf\/1902.04615.pdf\n\npermalinkembedsaveparentreportgive awardreply[\u2013]panties_in_my_ass 7 points8 points9 points 5 days ago\u00a0(2 children)\nIf you look at the theoretical physics literature, there's a ton of research being done on the statistical physics of neural networks and the statistical physics of deep learning, etc...where the mathematics of statistical physics and spin glasses are used as frameworks to analyze the behavior of neural nets, and then arrive at conclusions like \"The loss surface of neural nets have this particular topological property\" or \"CNN show a phase transition when the number of classes jumps from x to y\", etc.\n\nCan you please link some of these papers?  Or cite the major authors in the area?  This sounds fascinating!!\n\npermalinkembedsavereportgive awardreply[\u2013]AlexSnakeKing[S] 4 points5 points6 points 5 days ago*\u00a0(0 children)Here are some examples https:\/\/journals.aps.org\/pre\/abstract\/10.1103\/PhysRevE.90.052813\nhttps:\/\/arxiv.org\/pdf\/1907.07578.pdf\nKabashima, one the authors of the first paper, and Zecchina, one the authors of the second one are both big names in the filed, so are Marc Mezard, and Remi Monasson. A lot of these authors work mainly on analyzing optimization algorithms from a statistical mechanics point of view, but they occasionally venture into Neural Network territory.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]mec_con 3 points4 points5 points 5 days ago*\u00a0(0 children)For an overview of spin-glass related techniques, as well as message-passing algorithms, I'd recommend this review by Zdeborov\u00e1 and Krzakala: https:\/\/arxiv.org\/pdf\/1511.02476.pdf, and citations on there. It doesn't mention neural networks so much though, as they have been working on it mostly since the review has been published. For that you can look at their works on NeurIPS and ICML this year and the last.\nFor analyses of neural networks using dynamical techniques, you can look at any of the recent works from Jeffrey Pennington, Sam Schoenholz and Greg Yang.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]bbsome 5 points6 points7 points 5 days ago\u00a0(0 children)Most often the answer is No since all of these models that I've seen make way to many simplifying assumptions to be relevant in practice. Probably the only results that are truly valid are the Mean Field approximations of nets at initialization - they seem to describe even for finite widths very well the behaviour. This has led to a bit better initializers. However, this is only at initialization. All of the NTK stuff though seems to be not relevant to finite widths, for instance, hence it just remains as an infinite limit result (to my knowledge). The spin-glass models from statistical physics I don't think have had any interesting results with practical uses.\n\npermalinkembedsavereportgive awardreply[\u2013]cecri17 3 points4 points5 points 5 days ago\u00a0(1 child)Sevral examples.\n1) Markov chain monte-carlo, that we use for Bolzmann machines and reinforcement learning is absolutely form physics.\n2) In general optimization problems, we never expect that a variant of 1st order optimization work so well as in neural network examples. Some people try to investigate this problem using the continuous formulation of SGD which yields the Fokker-Plank equation that combines the Hessian and the Fisher matirx of the loss function. Fokker-Plank equation is originally from physics to describe non-equilibrium system. \n3) Moreover, now physicsists started to study generalization using their tools. Google brain has a team consists of physicsists. One of their recent results is that in wide limit, neural networks behaves like a gaussian process. They mainly used tools from physics to prove this.\n\npermalinkembedsavereportgive awardreply[\u2013]AlexSnakeKing[S] 0 points1 point2 points 5 days ago\u00a0(0 children)Cool. Can you point to the paper(s) that describe that last result?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]charlesbovarycestmoi 4 points5 points6 points 5 days ago\u00a0(0 children)Most studies in the field are theoretical and try to get an understanding\/characterization of NNs, somewhat like if they were a physical phenomenon to be understood.\nA couple of works that explore algorithmic ideas on the more practical side are these (disclaimer: I'm among the authors)\nhttps:\/\/arxiv.org\/abs\/1611.01838\nhttps:\/\/arxiv.org\/abs\/1707.00424\nthe ideas originate from a statistical physics study based on spin glass theory (https:\/\/www.pnas.org\/content\/113\/48\/E7655 and others) and that is still heavily under development (e.g. https:\/\/arxiv.org\/abs\/1905.07833).\n\npermalinkembedsavereportgive awardreply[\u2013]brekelma 1 point2 points3 points 5 days ago\u00a0(0 children)You might find videos from this workshop interesting!  https:\/\/icml.cc\/Conferences\/2019\/ScheduleMultitrack?event=353\n\npermalinkembedsavereportgive awardreply[\u2013]StellaAthena 1 point2 points3 points 5 days ago\u00a0(1 child)Could you link to a couple papers that you have in mind here?\n\npermalinkembedsavereportgive awardreply[\u2013]AlexSnakeKing[S] 1 point2 points3 points 5 days ago\u00a0(0 children)Here are some examples https:\/\/journals.aps.org\/pre\/abstract\/10.1103\/PhysRevE.90.052813\nhttps:\/\/arxiv.org\/pdf\/1907.07578.pdf\n\npermalinkembedsaveparentreportgive awardreply[\u2013]the_new_scientist 1 point2 points3 points 5 days ago\u00a0(0 children)I'd like to ask a similar question: have \"optimization\" style proofs (proving general theorems about SGD and NNs ) aided in practical architecture searches?\n\npermalinkembedsavereportgive awardreply[\u2013]Sweet_Significance 0 points1 point2 points 5 days ago\u00a0(2 children)Can someone suggest sources where i can learn more about this field? How is satistical physics related to this? I was always curious about the behaviour of deep nets for example and when i asked a similar question on another sub all i got was \"deep learning is mostly engineering there is not much theory going on\".\n\npermalinkembedsavereportgive awardreply[\u2013]StellaAthena 0 points1 point2 points 5 days ago\u00a0(0 children)Theoretical DL is widely maligned by the community unfortunately. There are some people doing interesting theoretical work, but you have to know where to look. Taco Cohen, Risi Kondor, and Benjamin Bloem-Reddy are three people who do excellent theoretical work, though none of them are from the statistical physics side of things.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]AlexSnakeKing[S] 0 points1 point2 points 4 days ago\u00a0(0 children)This paper:\nhttp:\/\/proceedings.mlr.press\/v38\/choromanska15.pdf\n(and the references within) provide a useful starting point.\n\nHow is satistical physics related to this?\n\nThe idea is roughly the following (obviously an oversimplification that still gets the point across): Take a mathematical expression of a neural network model, and then find a similar expression in the field of statistical mechanics or condensed matter physics. A typical example is to represent a loss function as the temperature or energy of a complex system of interacting particles. Now you can take known physics results about how those systems behave when their temperature or energy is reduced and apply it to your neural network model to see how it should behave when you try to minimize the loss function.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]lucidrage 0 points1 point2 points 5 days ago\u00a0(0 children)The loss function for cycleGAN used chemical equilibrium as an inspiration for training the generator and discriminator I think. Chemistry is the application of physics so I guess this counts.\n\npermalinkembedsavereportgive awardreply[\u2013]seanv507 -1 points0 points1 point 5 days ago\u00a0(0 children)I would say the answer is no, but I think the question is also wrong.\nI believe the question assumes that neural networks have some magic which other ml techniques don't.\nI would argue that the main successes of nnets are in image processing with CNN's, \nThe results there are essentially automating\/optimising end to end the standard image processing pipeline that has already been done since ? the 80s.\nTLDR: the amazing results in neural networks are in image processing. If you want to understand these study image processing. \nEg https:\/\/arxiv.org\/abs\/1203.1513\nhttps:\/\/openreview.net\/forum?id=SkfMWhAqYQ\nE\n\npermalinkembedsavereportgive awardreply[+]yetanothernormalG comment score below threshold-28 points-27 points-26 points 5 days ago\u00a0(10 children)I know both of the PhD in physics, Licentiate in ML.\nI have not read yet the spin glass papers but I did my PhD in structural glasses.\nIf you have this kind of education you understand why your question does not make any sense. \nDo you?\nDo you know what is the difference between supervised and unsupervised learning?\nOr how can the concept of entropy help making better deep belief networks?\nWhat is Gibbs sampling?\nWho is Gibbs?\nWhat is a Boltzmann Machine?\nWho is Boltzmann?\nWhat is a dynamical phase transition and why does it matter in deep learning?\nand I can go on.\nThese things are not something I read. These are just basic thoughts that come to my head because ML is basically statistical physics.\nTo see it, I suggest, spend 10 years doing physics, and five at doing ML (after being \"raised\" by physicists).\nBtw, why is it possible to use HMC ? For Bayesian leasning ? The answer is know by ever 3rd year physics student, how many 3rd year \"ML\" students know the answer?\nI see both sides. The ML side is 500 years lagging in \"culture\".  The way they think, the questions they ask... are not coming from 2000 years of distilled scientific culture. \nThink about this... I know both sides and physicists are really killing ML... on the theoretical side. Why? Because the ask the right questions. Why? Because they have 2000 years of culture in their science. \nPay close attention to physics, classical mechanics, statistical physics, spin glasses, phase transitions, inverse problem solving.\nOver and out. I got tired of pissing ppl off who either are pissed or not. The ones who are will not start to learn anything from this post. The ones who are not have a PhD in physics too.\n\npermalinkembedsavereportgive awardreply[\u2013]BoltzmannMachine 17 points18 points19 points 5 days ago\u00a0(0 children)I see your phd in physics has really humbled you\n\npermalinkembedsaveparentreportgive awardreply[\u2013]adventuringraw 17 points18 points19 points 5 days ago\u00a0(0 children)I have not read any of the relevant papers, but my education was in math and physics.\nIf you have this kind of an education, you understand why your post does not make any sense.\nDo you?\nDo you know the important questions in this field? \nWho is Richard Feynman? \nAlbert Einstein? \nMost importantly, who is John Galt?\nI can go on.\nthese are not just things I read, these are basic thoughts that come into my head because of how much I know. To see it, I suggest you spend at least 2000 years of culture studying machine learning, and at least 50 years practicing as a professional.\nI see both sides. You see, I am an immortal vampire. I am John Galt. I founded physics 2,000 years ago in ancient Greece, and I will still be here when the world is lost to ice and vacuum at the heat death of the universe.\nPay close attention to the old magic, physics, and inverse problem solving. The truth is out there.\nOver and out, this is John Galt.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]StellaAthena 12 points13 points14 points 5 days ago\u00a0(1 child)This comes across extremely obnoxious. There are a million far more pleasant ways to explain why you think this is a bad question.\n\npermalinkembedsaveparentreportgive awardreply[+]yetanothernormalG comment score below threshold-7 points-6 points-5 points 5 days ago\u00a0(0 children)i am not a pleasant person when it comes to deep learning stupidity\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Andy_Reds 2 points3 points4 points 5 days ago\u00a0(5 children)Someone reading your complaints in this comment would think you were a pure mathematician, not a physicist. It\u2019s funny watching physicists, of all people, complain about some machine learning researchers having no deep understanding of the theory behind what they\u2019re doing. I would suggest someone coax a physicist into explaining what quantum field theory actually is to see what I mean.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]facundoq 1 point2 points3 points 5 days ago\u00a0(0 children)You overfit mnist? I overfit the laws of nature\n\npermalinkembedsaveparentreportgive awardreply[\u2013]yetanothernormalG -1 points0 points1 point 3 days ago\u00a0(3 children)yeah, thats the thing.... at least they are about these questions\nthey care about understanding what they are doing...\nML ppl don't\ni think... i just came to some awesome realization why dl works...\nbut this community is not ready for it \nif i see the reactions to this post...\nmy god...\ni think i just stick to my ppl\nwho actually know what a spin glass is... and free energy\nand entropy\nand can come to a conclusion why deep learning works\non their own\nwhy?\ncoz they know statistical phyisics...\nLOOOL \nwatch all the python monkeys.... doing DEEEEP learning\nmore and more and more layers\nbut it is not neurons\nor the layers what makes it work\nit is something totally different\nbut ppl dont realise it...\nyet\n5 years\n10 years\nit will be widespread and realised\nand neurons and layers will be thrown away...\nwhy ?\nbeacuse people from physics understand why it works ...\nthey care about it...\ni dont even try to explain it...\nmy friends understand it... \ni dont wanna explain it to ppl who do not even know what free energy is\nand how it connects to deep learning and bayesian statistics.... hamiltonian monte carlo and so on.....\nleave me alon... i won't post here anymore.... it's pointless\n\npermalinkembedsaveparentreportgive awardreply[\u2013]adventuringraw 0 points1 point2 points 2 days ago\u00a0(2 children)it's true that a lot of people playing with deep learning after doing a few MOOCs don't understand even how much they don't know. But you're seemingly not claiming that, you're also apparently claiming all the actual deep learning researchers also know far less than you. If you think you know so much more than every single well cited researcher exploring the practical and theoretical nuances of deep learning... okay dude. You just keep on believing that, enjoy going back to 'your people' where every single one of the real researchers live. If even a handful of machine learning researchers know more than you though, that makes everything you just said complete bullshit. You're not just saying you know more relevant theory than everyone else in this subreddit (which could potentially be true, this is just an internet forum) you're saying you know more than absolutely everyone in the entire field. \nIncidentally, if you really do truly have deep insight that the machine learning community would benefit from, someone that wasn't an asshole would share relevant research (or textbooks even) instead of just saying how little all the machine learning researchers know. Even more, publish a goddamn peer reviewed paper if you've got the breakthrough that'll shake this field loose, find a collaborator in the space if you need help getting attention and citations for your effort. Cross disciplinary collaboration is common in science, if you really do have important insight, publish it. Posting it on here would obviously be a waste anyway, truly novel contributions should be published, not just posted.\nContrary to what you seem to think, there are people who do care how things work. Until there's a proper way of relating network topology with capacity and learning rate, theory will obviously have a long way to go, only a fool things a black box is sufficient forever. Deep insight leads to deep improvements. People here aren't mocking you because they think theory doesn't matter. They're mocking you because you make it sound like literally not a single researcher in ML cares about theory, or knows half as much as you and 'your people' do. That doesn't make you smart, it makes you an asshole. Or maybe both smart and an asshole. Given Cauchy and Fisher and many other historical assholes though, I guess you've got plenty of company. Though both Fisher and Cauchy actually published their work and left a mark in history. Course, for all I know, maybe you've gotten thousands of citations to your name, and made waves in the physics community. If that's you, I hope you use your great experience and insight to help move the machine learning community forward a few decades too, when you have the time.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]yetanothernormalG 0 points1 point2 points 2 days ago\u00a0(1 child)ok here we go, show me what you got\nwhat is the difference between supervised and unsupervised learning\nyou got one hour\nor let me give you an easier one... this gonna be a good one... what is the curse of dimensionality ?\nfor this you have 10 minutes...\nthis is the irony in the story... convince me that you have something behind what you say...\n\npermalinkembedsaveparentreportgive awardreply[\u2013]adventuringraw 0 points1 point2 points 2 days ago*\u00a0(0 children)dude, are you serious? You roll up your sleeves and ask to throw down, and this is the level of basic questions you think people on here don't know about? The comments in this subreddit are sometimes brain dead, it's true, but there's some excellent papers that come and go, all of which demand an enormous amount of mathematical maturity and familiarity with the literature. And I've met a number of incredible people on here, including PhDs in pure math, arguably people with useful knowledge 'your people' don't even possess on average, depending on the questions being asked.\nBut alright, I'll indulge you. \nSupervised learning typically has two objects in the training set, X (n x m features) and Y (n x t target dimensions) and given some function family, you're looking to tune the free parameters to get a minimum error rate using your metric of choice (MSE, etc) for transforming X to \\hat Y, the approximation of Y. That same formalization applies to whatever function family you're using, whether it's an SVM, a GLM, a deep neural network, or whatever other kind of model family you think will best fit the observed data. This approach partly comes from classic statistics, where you can often fit the distributions (single dimensional Gaussian for example) analytically instead of needing an iterative solution like gradient descent.\nThe formalization is slightly different for classification, often breaking down into either a full generative model (estimating p(C,D)) a conditional generative model (p(C|D)) or the discrimination function directly, f: X -> class. Either way, the actual final model gives you a set of decision manifolds dividing the feature space into K disjoint regions.\nUnsupervised amounts to pulling out what you can from unlabeled data. Given just X above, in other words, with no Y. A lot of recent papers in this space use a mutual information metric to try and break apart a dataset into categories, I'm particularly interested in representation learning, so this comes up frequently there. Often unsupervised learning tasks can be turned into self-supervised learning tasks (more common in NLP originally, though there's more work in computer vision coming out now too) by pulling out part of each sample and training the model to impute the missing piece. Removing chunks of images for example, or words in a sentence. The hope is that the model learns a broadly useful representation of the dataset, meaning fine tuning on broad range of tasks you actually care about will hopefully be possible with your trained self-supervised model.\nThe curse of dimensionality is a pretty broad concept, that reveals itself differently depending on the question you'd like to ask. One way to frame it is in terms of sparsity. Breaking apart your feature domain into a lattice, the number of cells (say, 9 cell dividers per dimension) means your cell count goes up as 10D . Meaning it takes a greater and greater number of samples to get observations in the various regions of the data manifold. 'distance' starts to get wonky in high dimensional space as well. One illustrative example is (volume of a hypersphere\/volume of a hypercube) where the half-edge length of the hypercube is equal to the radius of the hypersphere. You get piD\/2 \/ D2D-1 Gamma(D\/2). With Sterling's approximation, you end up with the ratio going to zero as D -> infinity, meaning more and more of the volume of each cube is concentrated in the 'spikes', so to speak. In practice, it means that standard low-dimensional methods (like KNN for example) ends up completely worthless, because any typical distance measure isn't going to properly find points that are actually all that close in the data manifold. You also end up with strange properties around where the volume is actually concentrated in hyperspheres, meaning (among other things) for high dimensional Gaussian distributions, your samples aren't actually likely to come from the regions of highest density, since all the actual volume is concentrated in a shell farther out. A final useful example of the curse of dimensionality comes from na\u00efve methods like polynomial curve fitting. Taking a degree M polynomial fit to D dimensional data, it can be shown that the number of independent parameters goes up according to (D + M)!\/D!M!, so for even very moderate values of M, D climbing leads to an explosion of parameters to fit, making a lot of basic tools (KNN and polynomial curve fitting being my two examples here) worthless as D starts to climb.\nMore detail on both of these topics can be found in Bishop's chapter 1, Elements of Statistical learning, and so on. These are very basic topics, and you're right. If someone doesn't have a clear answer to your questions, then they're a rank beginner and don't know even the beginnings of the theory. You're not wrong that theory's important, you're just wrong that no one cares, and no one knows. And I'm aware my answers probably aren't the best, I've only been studying for two years. I figure I have a decade ahead of me even to really start to deeply understand all the related topics I wish to understand. But I'm doing the work, you're an ass for assuming everyone's just happily playing with deep learning on the cloud without any clue what they're doing, or interest in learning. And you're wrong too if you think that no one in ML understands that physics matters. this paper in particular shows the bleeding in of gauge theory on a topic I'm quickly finding is my main area of interest... disentangled representation learning. Proper disentangling requires group actions the agent can take, revealing the symmetries under actions in the world model being learned. It does obviously look like physics has a lot to offer to the future of ML, you're not wrong. I've got a statistical mechanics book on my Amazon list, I'm still working on my math fundamentals right now though (pushing up towards Munkres, and getting into dynamic systems) so I have to be judicious about how I spend my time. I work full time and have a family, so I haven't had the luxury of covering as much theoretical ground yet as I'd like, but I'm slowly getting there.\nAnyway. Like I said. You probably know more than me, and you probably know things that could be of value to the ML community, assuming you actually are a PhD somewhere and not just a complete fake. No one here is questioning physics being useful. We're questioning your arrogance, in assuming no one here knows fucking anything. Like I said, you're maybe not stupid when it comes to physics, you're just needlessly making completely overblown assumptions about other people's inferiority. People aren't going to look kindly to you looking down your nose at them.\nIn fact, if you're going to ask me basic fucking questions to see if I know even the absolute bare minimum, let me ask you a question that my kid would easily be able to answer.\nIn your own words, why do you think people insulted you after you posted your first comment? If you know even the first thing about interacting with other humans, the answer should be obvious. I've literally told you several times already. \nI still can't believe you literally thought an average person on this subreddit couldn't tell you about supervised vs unsupervised, or the curse of dimensionality. Do you really, truly believe people on here are all so completely ignorant about the absolutely basics of machine learning? Do you think no one can read the papers being posted on here? Who's posting them if no one can read them? A lot of the papers on here are no joke if you can get through them and understand everything.\n\npermalinkembedsaveparentreportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 14224 on  r2-app-04a6d3b2b4de81e7e  at 2019-11-14 22:38:53.771855+00:00 running cfe41af country code: US."
  },
  "10":{
    "title":"[R] Announcing Confident Learning: Finding and Learning with Label Errors in Datasets : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-funny-gaming-pics-tifu-movies-worldnews-aww-todayilearned-gifs-TwoXChromosomes-videos-OldSchoolCool-Jokes-Showerthoughts-mildlyinteresting-television-explainlikeimfive-science-LifeProTips-personalfinance-dataisbeautiful-history-nottheonion-IAmA-askscience-nosleep-sports-Futurology-books-Art-space-food-photoshopbattles-EarthPorn-UpliftingNews-DIY-WritingPrompts-Music-Documentaries-gadgets-GetMotivated-philosophy-listentothis-announcements-creepy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  04 Nov 2019148 points (94% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave816,463 readers2,644 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X202  \u00b7 135 comments [D] Working on an ethically questionnable project...415  \u00b7 150 comments \"[D]\" John Carmack stepping down as Oculus CTO to work on artificial general intelligence (AGI)42  \u00b7 7 comments [R] Momentum Contrast for Unsupervised Visual Representation Learning: \"the gap between unsupervised and supervised representation learning has been largely closed\"21 [Research] We trained a self-balancing physics-based character to follow interactive motion capture.5  \u00b7 1 comment [R] \"Compressive Transformers for Long-Range Sequence Modelling\", Rae et al 20192  \u00b7 7 comments [D] [P] Architecture of a neural network implementing a neural algorithm of artistic style3  \u00b7 2 comments [D][R] Applications of AI\/ML in the field of Digital Pathology19  \u00b7 12 comments [D] Thoughts about this conversation?195  \u00b7 5 comments [R] NVIDIA's Kaolin: A PyTorch Library for Accelerating 3D Deep Learning Research[D] Looking for a good open-source NAS implementationWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7147148149Research[R] Announcing Confident Learning: Finding and Learning with Label Errors in Datasets (self.MachineLearning)submitted 10 days ago * by cgnorthcuttHi, Reddit. I'm excited to share confident learning for characterizing, finding, and learning with label errors in datasets. This is joint work with co-authors Lu Jiang (Google Reserach) and Isaac Chuang (MIT). To promote and standardize future research in learning with noisy labels and weak supervision, I've also open-sourced the cleanlab Python package: https:\/\/pypi.org\/project\/cleanlab\/\nPost: https:\/\/l7.curtisnorthcutt.com\/confident-learning\nTitle: Confident Learning: Uncertainty Estimation for Dataset Labels\nAbstract: Learning exists in the context of data, yet notions of confidence typically focus on model predictions, not label quality. Confident learning (CL) has emerged as an approach for characterizing, identifying, and learning with noisy labels in datasets, based on the principles of pruning noisy data, counting to estimate noise, and ranking examples to train with confidence. Here, we generalize CL, building on the assumption of a classification noise process, to directly estimate the joint distribution between noisy (given) labels and uncorrupted (unknown) labels. This generalized CL, open-sourced as cleanlab, is provably consistent under reasonable conditions, and experimentally performant on ImageNet and CIFAR, outperforming recent approaches, e.g. MentorNet, by 30% or more, when label noise is non-uniform. cleanlab also quantifies ontological class overlap, and can increase model accuracy (e.g. ResNet) by providing clean data for training.\nPaper: https:\/\/arxiv.org\/abs\/1911.00068\nCode: https:\/\/github.com\/cgnorthcutt\/cleanlab\/\nTop 32 label issues in the 2012 ILSVRC ImageNet train set identified using confident learning. Label Errors are boxed in red. Ontological issues in green. Multi-label images in blue.\n\n14 commentssharesavehidereportall 14 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]brb92 4 points5 points6 points 10 days ago\u00a0(4 children)How would this work in case of imbalanced datasets where a over\/under sampling is applied ? \nIt would affect the joint probability, right ?\n\npermalinkembedsavereportgive awardreply[\u2013]cgnorthcutt[S] 2 points3 points4 points 10 days ago*\u00a0(3 children)Thanks for your question! The short answer is CL is unaffected by class imbalance except for discretization error. By discretization error, i mean that if you only have 3 examples in a class 'A', and the true probability class 'B' was flipped to 'C' is 0.7... the best you could do with 3 examples is 2\/3 = 0.67.\nThe long answer is: CL takes predicted probabilities and noisy labels as inputs. If you're predicted probabilities are random, then CL can't work. In the theory section of the paper, we prove realistic conditions when CL will exactly find label errors even when there is error in predicted probabilities for every example and class.\nIf you use tricks to deal with class imbalance when you compute your predicted probabilities (loss weighting, bagging, data augmentation, etc.)... then in practice you should be fine. Similarly, if you have some class imbalance, but it's not so extreme as to produce wonky predicted probabilities, then again in practice you should be fine. For example, some of the classes in ImageNet training set have fewer examples, but using CL, we did not observe less accurate label error detection in these classes (verified by humans).\nNote predicted probabilities should be computed out of sample. We use four-fold cross-validation in the paper. If you have the computation, you can increase the folds for better results.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]brb92 0 points1 point2 points 10 days ago\u00a0(2 children)I see, thanks for your answer and congratulations for the very nice project. I will for sure deep dive more on it when I have more time.\nAs you use only per-class probabilities to define the thresholds, I understand that indeed it should not be affected by class imbalance.\nHowever it is still important to have calibrated predicted probabilities as output, because if not we will not be able to correctly distinguish between noisy and not-noisy examples. Am I right ?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]cgnorthcutt[S] 1 point2 points3 points 10 days ago\u00a0(1 child)Think of it this way. If your predicted probabilities are bad (due to whatever: class imbalance, bad model choice, etc), then even if you have ZERO label errors and don't use CL at all, you'll still have bad predictions.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]brb92 1 point2 points3 points 10 days ago\u00a0(0 children)Yep, makes sense for me \ud83d\ude05\nThanks again for your answer and for opening up this project :)\n\npermalinkembedsaveparentreportgive awardreply[\u2013]alexrenda 1 point2 points3 points 10 days ago\u00a0(0 children)Mirror: https:\/\/web.archive.org\/web\/20191104143423\/https:\/\/l7.curtisnorthcutt.com\/confident-learning\n\npermalinkembedsavereportgive awardreply[\u2013]dracheschreck 1 point2 points3 points 10 days ago\u00a0(1 child)Does it work for regression problems as well?\n\npermalinkembedsavereportgive awardreply[\u2013]cgnorthcutt[S] 0 points1 point2 points 10 days ago*\u00a0(0 children)Thanks for your question. CL works for classification only. However, depending on the granularity you need, you can discretize your targets into m labels. For example, confident Learning works well on imagenet which has 1000 labels. That's fairly granular. If your regression targets were probabilities (bounded between 0 and 1) then it's possible CL could handle up to 3 decimals of target granularity for regression. This is reasonable theoretical conjecture: I have not run these experiments\nThroughout our work, we use the term \"label\"  to refer to a \"class label\", reserving \"targets\" for regression target values. And we only deal with noisy \"labels\".\n\npermalinkembedsaveparentreportgive awardreply[\u2013]liqui_date_me 1 point2 points3 points 9 days ago\u00a0(0 children)Isaac Chuang is doing ML now?\n\npermalinkembedsavereportgive awardreply[\u2013]speyside42 1 point2 points3 points 9 days ago\u00a0(0 children)Nice work. Would be interesting how this compares to more recent works like o2u-net:\nhttp:\/\/openaccess.thecvf.com\/content_ICCV_2019\/html\/Huang_O2U-Net_A_Simple_Noisy_Label_Detection_Approach_for_Deep_Neural_ICCV_2019_paper.html\n\npermalinkembedsavereportgive awardreply[\u2013]jrkirby 0 points1 point2 points 10 days ago\u00a0(1 child)I wonder what happens when you apply this to random data, or regular data with random labels. Deep learning has been shown to fit the training set rather robustly even in these nonsense cases (of course, not generalizing to any test set). Would CL be able to notice when it is set to train on a random dataset?\n\npermalinkembedsavereportgive awardreply[\u2013]cgnorthcutt[S] 0 points1 point2 points 10 days ago*\u00a0(0 children)Thanks for the question. With completely random labels, predicted probabilities (assuming some regularization) tend to be more uniform. For most applications of confident learning, empirically (checked on MNIST, CIFAR, and Imagnet) the result is random performance or the prediction all one label. This often also results in edge conditions during pruning like removing all of one class if examples or removing no examples as errors because there is no signal.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]aashus18 0 points1 point2 points 10 days ago\u00a0(1 child)Would this work for multi-label setup ? In that case would the analysis be similar to binary one-vs-all classifier for all the labels ?\n\npermalinkembedsavereportgive awardreply[\u2013]cgnorthcutt[S] 2 points3 points4 points 10 days ago\u00a0(0 children)Hi, thanks for the question. While we do not address multi-label in the paper, the cleanlab python package fully supports multi-label. In terms of how it works, its more simple than binary one-vs-all because confident learning intrinsically works with multiple labels. The only change needed is a few lines like this s_filter = np.array([k in l for l in s]) if multi_label else s == k  where you instead of considering examples with given label k, you instead consider any example that has label k in its set of labels. You can ctrl+f `multi_label` in the codebase for further inspection. In the paper, we presume single-class datasets where multiple labels are handled with the notion of collisions.\n\npermalinkembedsaveparentreportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 23392 on  r2-app-0ef3edbb8f291636c  at 2019-11-14 23:42:13.765311+00:00 running e8e67f8 country code: US."
  },
  "11":{
    "title":"[P] Trained a StyleGAN on all emojis from emojipedia. Samples posted hourly. Please help describing samples! : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-gaming-funny-pics-worldnews-aww-todayilearned-IAmA-videos-Showerthoughts-tifu-movies-Jokes-nottheonion-science-sports-gifs-television-mildlyinteresting-LifeProTips-TwoXChromosomes-dataisbeautiful-explainlikeimfive-Music-OldSchoolCool-space-askscience-nosleep-books-food-Art-Futurology-history-gadgets-GetMotivated-creepy-WritingPrompts-photoshopbattles-EarthPorn-DIY-Documentaries-UpliftingNews-listentothis-philosophy-InternetIsBeautiful-announcements-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  08 Nov 201910 points (81% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave817,930 readers2,338 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X18  \u00b7 5 comments [D] Lets Talk About Vicarious Inc.[P] baikal: A graph-based functional API for building complex scikit-learn pipelines269  \u00b7 56 comments [D] Machine Learning Frameworks used at NeurIPS 2019: PyTorch 68 -> 166, TensorFlow 91 -> 74[D] Recommendations about users and repository that has good organization in ML projects on Github2  \u00b7 5 comments [D] Where are withdrawn ICLR papers being submitted to?100  \u00b7 5 comments [P] An Open-Source Course on Hacking Neural Networks231  \u00b7 18 comments [P] Nearing BERT's accuracy on Sentiment Analysis with a model 56 times smaller by Knowledge Distillation8  \u00b7 2 comments [R] Resizable Neural Networks257  \u00b7 42 comments [D] DanNet, the CUDA CNN of Dan Ciresan in Jurgen Schmidhuber's team, won 4 image recognition challenges prior to AlexNet2  \u00b7 2 comments [D] NN Pruning for Object Detection?Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d791011Project[P] Trained a StyleGAN on all emojis from emojipedia. Samples posted hourly. Please help describing samples! (self.MachineLearning)submitted 9 days ago by nehalemlabsI set up a twitter bot posting a new sample every hour here:\u00a0https:\/\/twitter.com\/EmojiPainter\nI am trying to collect a dataset with images and associated descriptions. I am hoping to collect human generated descriptions to augment the existing emojis (too few to train an image - language model on).\nThe images can be unintentionally hilarious but also sometimes disturbing! Enjoy!\n\n4 commentssharesavehidereportall 4 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]hearingsilence 4 points5 points6 points 8 days ago\u00a0(0 children)Thanks for the nightmares\n\npermalinkembedsavereportgive awardreply[\u2013]code_refactor 2 points3 points4 points 8 days ago\u00a0(0 children)Thanks, I hate it\n\npermalinkembedsavereportgive awardreply[\u2013]yusuf-bengio 1 point2 points3 points 8 days ago\u00a0(0 children)Have you tried to decompose the latent space? Would be nice to see some transitions.\n\npermalinkembedsavereportgive awardreply[\u2013]phyrz 0 points1 point2 points 8 days ago\u00a0(0 children)\/r\/interestingasfuck\n\npermalinkembedsavereportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 31314 on  r2-app-0d0dc893e84949ffe  at 2019-11-17 04:24:35.192829+00:00 running 85b1b7a country code: US."
  },
  "12":{
    "title":"[P] DialogPT: State of the Art Conversational Model with Fine-Tuned GPT-2 (Microsoft Research) : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-gaming-funny-pics-worldnews-aww-todayilearned-IAmA-videos-Showerthoughts-tifu-movies-Jokes-nottheonion-science-sports-gifs-television-mildlyinteresting-LifeProTips-TwoXChromosomes-dataisbeautiful-explainlikeimfive-Music-OldSchoolCool-space-askscience-nosleep-books-food-Art-Futurology-history-gadgets-GetMotivated-creepy-WritingPrompts-photoshopbattles-EarthPorn-DIY-Documentaries-UpliftingNews-listentothis-philosophy-InternetIsBeautiful-announcements-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  07 Nov 201964 points (93% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave817,974 readers2,514 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X26 [P] baikal: A graph-based functional API for building complex scikit-learn pipelines24  \u00b7 5 comments [D] Lets Talk About Vicarious Inc.273  \u00b7 56 comments [D] Machine Learning Frameworks used at NeurIPS 2019: PyTorch 68 -> 166, TensorFlow 91 -> 744 [D] Recommendations about users and repository that has good organization in ML projects on Github2  \u00b7 5 comments [D] Where are withdrawn ICLR papers being submitted to?102  \u00b7 5 comments [P] An Open-Source Course on Hacking Neural Networks239  \u00b7 18 comments [P] Nearing BERT's accuracy on Sentiment Analysis with a model 56 times smaller by Knowledge Distillation8  \u00b7 2 comments [R] Resizable Neural Networks259  \u00b7 42 comments [D] DanNet, the CUDA CNN of Dan Ciresan in Jurgen Schmidhuber's team, won 4 image recognition challenges prior to AlexNet2  \u00b7 2 comments [D] NN Pruning for Object Detection?Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7636465Project[P] DialogPT: State of the Art Conversational Model with Fine-Tuned GPT-2 (Microsoft Research) (self.MachineLearning)submitted 9 days ago by anustretchhttps:\/\/github.com\/microsoft\/dialogpt\nAccording to Microsoft:\n\nThe human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test.\n\nExample conversation:\n\nUser: Does money buy happiness?  \nBot: Depends how much money you spend on it.  \nUser: What is the best way to buy happiness?  \nBot: You just have to be a millionaire by your early 20s, then you can be happy.  \nUser: This is so difficult!  \nBot: You have no idea how hard it is to be a millionaire and happy . There is a reason the rich have a lot of money\n\n\n53 commentssharesavehidereportall 53 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]illuminascent 18 points19 points20 points 9 days ago*\u00a0(11 children)I've managed to get the model running generation on my PC.\nOne thing needed to point out is that the checkpoint can NOT be loaded exactly as the GPT-2 model checkpoint from Huggingface pytorch-transformer repository. Because there's one key required by huggingfaces implementation called \"lm_head.weight\" and the corresponding key in Microsoft's checkpoint is called \"lm_head.decoder.weight\", so fix this before you can call load_state_dict().\nYou'll also need to manually define the config, e.g. medium_config = GPT2Config(n_embd=1024,n_layer=24,n_head=16) because checkpoints doesn't seem to contain them.\nThe generation works just fine by a nucleus sampling approach, and once in a while an E-O-T will be given to indicate end of one post.\n\u200b\nGenerated sample:\nUser: What do you guys think about the coming Olympics\nBot: they're having an open gym soon in June... dont think they'll be up there this time though\nBot: So what's this gym called?\nBot: San Diego Fitness Club\nBot: Well that sounds to perfect.\n\u200b\n\u200b\nEdit:\nBeen playing with it, here are some other highlights:\n\u200b\nUser: Every post on here that has anything to do with numbers, growth, streams that average more than 3 viewers, or literally anything that mentions something other than how fun streaming is, is instantly downvoted.\nBot: That is how democracy works.\n\u200b\nUser: If Trump was running against Trump, what would he tweet about his opponent?\nBot: Make American soccer great again\n\u200b\nUser: What do you guys know about the highest mountain in Japan?\nBot: It's a mountain, and no more.\n\u200b\nI'd say all of the generations are grammatically acceptable and quite impressive considering how little information it was given, about 1 out of 5 appeared to be very coherent and sometimes strikingly sarcastic(much reddit). Those prompted with a clear defined topic certainly worked out better. And just as the paper's result goes I also find the medium sized model to generally outperform the bigger one.\n\u200b\nEdit2:\nI've set up a colab here.\n\npermalinkembedsavereportgive awardreply[\u2013]Flag_Red 2 points3 points4 points 8 days ago\u00a0(0 children)I'm impressed with the world knowledge displayed in the Trump response.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]anustretch[S] 2 points3 points4 points 8 days ago*\u00a0(3 children)Thanks so much for creating\/sharing the colab. I've tweaked the script a little so that the inputs to the model reflect a turn-taking conversation over IM, similar to the formatting of the output example. It seems to be performing slightly better this way.\nEdit: added modifications so that full conversation history in recalc()should be properly re-fed, instead of just a 1-line hysteresis in the original colab. (Notebook link updated)\nEdit 2: truncating prev convo input at the next available line so that it doesn't exceed the fixed embedding length; loading config file according to updated configs folder for medium sized model; can now type 'reset' to start the conversation over.\nNotebook v3: https:\/\/colab.research.google.com\/drive\/1SETfvx_ot_-VhDXjwik2SxundaQZ9rDI\nNotebook v4 (just better input formatting etc in accordance with docs and dev feedback on github): https:\/\/colab.research.google.com\/drive\/1-_KjlAV3J1IVDw_9KogjKDCzgFY7Jp7E\nExample of passing inputs to model in the original script from huggingface: [2]\n\npermalinkembedsaveparentreportgive awardreply[\u2013]anustretch[S] 0 points1 point2 points 7 days ago\u00a0(2 children)Sample output:\n\nMe: What is the meaning of life?   \nYou: Mind over matter I assume   \nMe: Elaborate?   \nYou: Life is essentially defined as the ability to make the universe, or as the collective subconscious of humanity.   \nMe: How does one do that?   \nYou: With genius   \nMe: And what is the ultimate end in doing so?   \nYou: To not live forever and to make others live, to not exist\n\n\npermalinkembedsaveparentreportgive awardreply[\u2013]MemeBox 0 points1 point2 points 7 days ago\u00a0(1 child)This is what I think the correct answer is, where did the machine learn about this, I've never heard anyone say it before!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]anustretch[S] 0 points1 point2 points 7 days ago\u00a0(0 children)\nMe: Are you self-aware?  \nBot: i'm trying to figure out how   \nMe: Are you self-aware?  \nBot: Any sufficiently advanced darkness, is indistinguishable from poetry.\n\nThe most poignant words I've ever read\/heard when it came to that last line :)\n\npermalinkembedsaveparentreportgive awardreply[\u2013]mrconter1 0 points1 point2 points 8 days ago\u00a0(3 children)Would you mind setting up a Colab?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sunnyEngery 4 points5 points6 points 8 days ago\u00a0(0 children)\nWould you mind setting up a Colab?\n\nBot: Sure. Lemme see if I can set it up this weekend.\nIt really gave me that answer. :)\n\npermalinkembedsaveparentreportgive awardreply[\u2013]illuminascent 4 points5 points6 points 8 days ago\u00a0(1 child)https:\/\/colab.research.google.com\/drive\/1KTLqiAOdKM_3RnBWfqgrvOQLqumUyOdA\nThere you go!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]mrconter1 0 points1 point2 points 8 days ago\u00a0(0 children)Thank you so much! :D\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sunnyEngery 0 points1 point2 points 8 days ago\u00a0(0 children)Thanks.\nUser input: Pewdiepie\nBot: I read that as Pewdiy, the alien from alien 3.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]frequenttimetraveler 5 points6 points7 points 9 days ago\u00a0(1 child)anybody know if i can run this model as-is (without training) on a CPU only server?\n\npermalinkembedsavereportgive awardreply[\u2013]intersun2 5 points6 points7 points 9 days ago\u00a0(0 children)yes, the pre-trained model is provided. But you need to implement the decoding script by yourself. \nBTW I think even decoding on CPU will be slow...\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Kavillab 2 points3 points4 points 9 days ago\u00a0(2 children)Wow, using only the 345M model. Wonder what would happen if they used the 1.5B\n\npermalinkembedsavereportgive awardreply[\u2013]Kavillab 4 points5 points6 points 9 days ago\u00a0(1 child)wait.. i see that they tested with 762M model too but it underperformed.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]gwern 5 points6 points7 points 8 days ago*\u00a0(0 children)Probably undertraining:\n\nThe learning rate is selected based on validation loss.  Each model is trained until there is no progress in validation loss.   For small and medium models,  we trained the models for up to 5 epochs. For the large model we trained for at most 3 epochs.\n\nNo training curves are included but I wouldn't expect 762M to overfit 1.8b words, especially with validation checking and initialization from OA, so I bet what happened is simply that 762M hit their 3 epoch limit and hadn't finished.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]somethingstrang 2 points3 points4 points 9 days ago\u00a0(4 children)This is incredible! Can anybody tell me what is a \u201csingle turn\u201d conversation?\n\npermalinkembedsavereportgive awardreply[\u2013]this-is-test 2 points3 points4 points 8 days ago\u00a0(3 children)Single turn implies a round of question and answer. Any additional turns have no context of the other. So if you ask one question and then another it doesn't remember the previous response and use that as input to adjust the new response.\nIt's as if you start a new conversation each time.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]somethingstrang 1 point2 points3 points 8 days ago\u00a0(2 children)From the example dialogue it seemed like when the human said \u201cThis is so difficult!\u201d, the bot was able to remember the context of being a millionaire. So is this still within definition of single turn?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Nameless1995 0 points1 point2 points 8 days ago\u00a0(0 children)The dialogue is from a table whose caption is:\n\"An interactive example of multi-turn dialogue\"\nhttps:\/\/arxiv.org\/pdf\/1911.00536.pdf (table 5). So no.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]this-is-test -1 points0 points1 point 8 days ago\u00a0(0 children)The snippet from the OP is misleading. When you read the original GIT repo it's labled as Multi turn which is what that example really is\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Merzmensch 2 points3 points4 points 8 days ago\u00a0(0 children)Wonderful! Is there some Notebook version on order to run in in browser?\n\npermalinkembedsavereportgive awardreply[\u2013]sunnyEngery 1 point2 points3 points 9 days ago*\u00a0(1 child)The document says 12GB of memory and more. What happens if I use an 8GB GPU, e.g. an RTX 2080?\n\npermalinkembedsavereportgive awardreply[\u2013]sid__ -1 points0 points1 point 8 days ago\u00a0(0 children)Presumably swapping or a crash\n\npermalinkembedsaveparentreportgive awardreply[\u2013]mrconter1 1 point2 points3 points 8 days ago\u00a0(1 child)Is there any colab?\n\npermalinkembedsavereportgive awardreply[\u2013]anustretch[S] 1 point2 points3 points 7 days ago\u00a0(0 children)Try this out https:\/\/colab.research.google.com\/drive\/1SETfvx_ot_-VhDXjwik2SxundaQZ9rDI (More info)\n\npermalinkembedsaveparentreportgive awardreply[\u2013]farmingvillein -1 points0 points1 point 9 days ago\u00a0(25 children)That conversation is pretty bad (\"Depends how much money you spend on it\"???)...confused that this could get ranked highly versus humans.\n\npermalinkembedsavereportgive awardreply[\u2013]Rioghasarig 9 points10 points11 points 9 days ago\u00a0(23 children)Why are you confused? That seems like a perfectly reasonable response to me.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]farmingvillein -3 points-2 points-1 points 9 days ago\u00a0(22 children)It's a very awkward sentence that a native English speaker would rarely put together--a Google search (lack of results) validates this.\nIt is semantically very straightforward\/constrained, so we would expect to see this at higher frequency.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Rioghasarig 7 points8 points9 points 8 days ago\u00a0(12 children)I think they missed the word \"on\". Like \"Depends on how much money you spend on it\". It's not a big error. People make typos all the time.\nAnd I have heard people say \"Depends how much\" plenty of times. So it's also an acceptable way to say it.\n\npermalinkembedsaveparentreportgive awardreply[+]farmingvillein comment score below threshold-7 points-6 points-5 points 8 days ago\u00a0(11 children)YMMV, but collectively it is a phrase that a native speaker is unlikely to emit.\nSimilarly, \n\"Bot: You have no idea how hard it is to be a millionaire and happy . There is a reason the rich have a lot of money\"\ndoesn't make much sense.  The rich, by definition, have a lot of money.  It kind of makes sense as some sort of clever tautology in context...but not really.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Rioghasarig 8 points9 points10 points 8 days ago\u00a0(10 children)No, you're wrong. It's a perfectly common phrase. I don't know why you think it isn't. Google returned several examples. \nYeah, it doesn't seem to make sense. But it's really hard to tell with just one sentence. That's probably why it could score well. Even a sentence like that could make sense if someone continued it the right way.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]farmingvillein 1 point2 points3 points 8 days ago\u00a0(9 children)\nNo, you're wrong. It's a perfectly common phrase. I don't know why you think it isn't. Google returned several examples.\n\nI'm talking about the entire construct, not \"depends how much\".\n\nEven a sentence like that could make sense if someone continued it the right way.\n\nIn this case, no, because we're seeing the totality of the bots response for that dialogue turn.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Rioghasarig 3 points4 points5 points 8 days ago\u00a0(8 children)\nI'm talking about the entire construct, not \"depends how much\".\n\nThe sentence makes grammatical sense. I don't know what to tell you. What do you think is wrong with the sentence? \n\nIn this case, no, because we're seeing the totality of the bots response for that dialogue turn.\n\nI'm trying to explain why the bot was able to score highly. Because we only have people may have been more forgiving in their score. If the bot continued to talk more, it would reveal it didn't really understand what it was talking about. But it's hard to tell with just one sentence.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]farmingvillein 1 point2 points3 points 8 days ago\u00a0(7 children)\nThe sentence makes grammatical sense. I don't know what to tell you. What do you think is wrong with the sentence?\n\nThere are plenty of sentences out there that make grammatical sense that a native English speaker would not construct (but the bot might).\n\nI'm trying to explain why the bot was able to score highly.\n\nFair enough.  Color me skeptical about this aspect of their paper:\n\nthe response generated from DialoGPT is comparable to human response quality\n\nOverall, these responses are still of pretty mixed quality, which suggests issues with how their human evaluations are constructed (I suspect the human responses were created in a low quality way).  Being judged as \"more human than human\" should be a starting yellow flag.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Rioghasarig 7 points8 points9 points 8 days ago\u00a0(6 children)\nThere are plenty of sentences out there that make grammatical sense that a native English speaker would not construct (but the bot might).\n\nI am a native English speaking and I'm telling you that is a sentence that I would utter. Why are you adamant about this point? People speak in somewhat different ways. When it comes to this point you're just wrong. I don't know why you find the sentence so unnatural but it doesn't sound unnatural at all to me. \nThe responses were judged n a two-sentence exchange. That's the main thing. This basically means it delivers grammatically correct sentences that are at least a little bit on topic. It's not a high bar. \nI don't think the response quality is low. It's just the fact that you can't tell much from a single sentence.\n\npermalinkembedsaveparentreportgive awardreplycontinue this thread[\u2013]gwern 0 points1 point2 points 8 days ago\u00a0(8 children)How does Google validate that? I see tons of hits for \"Depends how much \" where 'on' is omitted. The first hit is Shel Silverstein, who I'm pretty sure is a native English speaker and who knows more about how to write than you. The next hit is a Bloomberg headline which is grammatically identical: \"How Much Is Your Education Worth? Depends How Much You Make.\"\n\npermalinkembedsaveparentreportgive awardreply[\u2013]farmingvillein 0 points1 point2 points 8 days ago\u00a0(7 children)We're talking about different things.  \nMe: \n\nIt's a very awkward sentence\n\nI.e., \n\"Depends how much money you spend on it\"\nI'm not talking about the fragment \"Depends how much\".  The entire sentence is rare and awkward.  (s\/time\/money\/, etc. and you'll see remaining high levels of rarity in the overall construction.)\nFWIW, even if you want to stick to 3-word fragment (which wasn't my intention:\n\nGoogle has ~200 examples.  That is exceedingly rare for a trigram.\nThe Shel Silverstein example is in the context of a poem that intentionally breaks grammaticality for effect, and breaks it in a way which is rare:\n\n\nHow much good inside a day?\nDepends how good you live \u2018em.\nHow much love inside a friend?\nDepends how much you give \u2018em.\u201d\n\nNone of those are patterns that you will see with any regularity in human speech, and none of those should be used as any validation of human.\nThis is an example that illustrates my point more than yours.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]gwern 0 points1 point2 points 8 days ago\u00a0(1 child)\nGoogle has ~200 examples. That is exceedingly rare for a trigram.\n\nWhere are you getting 200?\n\nThe Shel Silverstein example is in the context of a poem that intentionally breaks grammaticality for effect, and breaks it in a way which is rare:\n\nWhich is why I immediately pointed out the use in a headline as well, because I knew you would make the excuse 'oh well it's merely in a popular English poem, English poetry doesn't count in discussions of acceptable English'. If you're objecting to a English phrase which multiple other people are telling you is fine, which is found in both poems and headlines by famous writers and media, you're probably wrong. (Incidentally, just in one IRC channel I'm in, I count over 60 uses. 'Very awkward' my ass.)\n\npermalinkembedsaveparentreportgive awardreply[\u2013]farmingvillein 0 points1 point2 points 8 days ago\u00a0(0 children)\nIf you're objecting to a English phrase which multiple other people are telling you is fine\n\nIn virtually every single one of my responses I clearly state that this is not what I am objecting to, including the literal post you are directly responding to.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]epicwisdom 0 points1 point2 points 7 days ago\u00a0(4 children)\nGoogle has ~200 examples. That is exceedingly rare for a trigram.\n\nAre you referring to \"depends how much?\" https:\/\/imgur.com\/nu1S1Uq\n1.8m hits seems reasonable for a trigram.\n\nIt's a very awkward sentence\n\n\"Awkwardness\" is a subjective quality. I'm a native English speaker, and it seems a tiny bit awkward at worst. I wouldn't even have noticed if you didn't point it out, and I wouldn't blink twice if somebody talked like that.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]farmingvillein 0 points1 point2 points 7 days ago\u00a0(3 children)\nAre you referring to \"depends how much?\" https:\/\/imgur.com\/nu1S1Uq\n1.8m hits seems reasonable for a trigram.\n\nClick through a few tabs.  You will not be able to go past page ~9, and will get something around a few hundred (at most).\n\nI wouldn't blink twice if somebody talked like that.\n\nAgain, per my myriad of other posts in this thread (not that I expect anyone to read any of them without prompting), it is the entirety of the construct, not \"depends how much\" in isolation.\nThe focus on \"depends how much\" in isolation is an artificial construct of respondents to my original post, which I have multiple times responded to and stated that this is not my focal point.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]epicwisdom 0 points1 point2 points 7 days ago*\u00a0(2 children)\nClick through a few tabs. You will not be able to go past page ~9, and will get something around a few hundred (at most).\n\nThis is not specific to this trigram. Google also exhibits this behavior for search queries like \"a\" and \"the\".\nIf you click the link which includes the \"omitted\" search results, you should get be able to browse a much larger selection, though there's no particular way for me to confirm you can look at each of the millions of results.\n\nAgain, per my myriad of other posts in this thread (not that I expect anyone to read any of them without prompting), it is the entirety of the construct, not \"depends how much\" in isolation.\n\nDid I say I was talking only about \"depends how much\"? The Google result was merely pointing out you are factually incorrect about an empirical claim. (And a ridiculous claim, at that, in understating the true popularity of a phrase by something like 4 orders of magnitude.)\nThe sentence as a whole seems perfectly fine to me.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]farmingvillein 0 points1 point2 points 7 days ago\u00a0(1 child)This is getting a little silly and redundant with other discussions in this thread:\n\nDid I say I was talking only about \"depends how much\"?\nThe sentence as a whole seems perfectly fine to me.\n\nIf you care to discuss--and it is obviously fine if you don't--then please see my discussion elsewhere in this thread on this topic so I don't need to regurgitate.\nThe overall construction is unnatural and inconsistent with how a native speaker would construct such a sentence.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]epicwisdom 0 points1 point2 points 7 days ago\u00a0(0 children)I'm not particularly interested in arguing what native speakers would or wouldn't say, unless there's a methodology sophisticated enough to make an automated, quantitative test for ML models and demonstrably superior to surveying native speakers.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]ma3gl1n 0 points1 point2 points 8 days ago\u00a0(0 children)When the aim is responding like a human, making small mistakes is better and not worse\n\npermalinkembedsaveparentreportgive awardreply[\u2013]SagaciousRaven -2 points-1 points0 points 8 days ago\u00a0(0 children)\nBot: ...There is a reason the rich have a lot of money\n\nYou don't say.\n\npermalinkembedsavereportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 32112 on  r2-app-0a12f037a1410dd83  at 2019-11-17 05:39:29.364894+00:00 running 85b1b7a country code: US."
  },
  "13":{
    "title":"[D] Gary Marcus Tweet on OpenAI still has not changed misleading blog post about \"solving the Rubik's cube\" : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-gaming-funny-pics-worldnews-aww-todayilearned-IAmA-videos-movies-Jokes-mildlyinteresting-nottheonion-tifu-science-sports-gifs-television-LifeProTips-Showerthoughts-TwoXChromosomes-explainlikeimfive-Music-OldSchoolCool-Futurology-space-askscience-dataisbeautiful-nosleep-books-food-Art-history-gadgets-GetMotivated-creepy-WritingPrompts-EarthPorn-photoshopbattles-DIY-UpliftingNews-Documentaries-listentothis-philosophy-announcements-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  20 Oct 201959 points (79% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave818,022 readers2,248 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X55  \u00b7 9 comments [P] baikal: A graph-based functional API for building complex scikit-learn pipelines28  \u00b7 6 comments [D] Lets Talk About Vicarious Inc.274  \u00b7 56 comments [D] Machine Learning Frameworks used at NeurIPS 2019: PyTorch 68 -> 166, TensorFlow 91 -> 744 [D] Recommendations about users and repository that has good organization in ML projects on Github[P] ML consults on building medical decision assistance.2  \u00b7 6 comments [D] Where are withdrawn ICLR papers being submitted to?102  \u00b7 5 comments [P] An Open-Source Course on Hacking Neural Networks238  \u00b7 18 comments [P] Nearing BERT's accuracy on Sentiment Analysis with a model 56 times smaller by Knowledge Distillation6  \u00b7 3 comments [R] Resizable Neural Networks257  \u00b7 42 comments [D] DanNet, the CUDA CNN of Dan Ciresan in Jurgen Schmidhuber's team, won 4 image recognition challenges prior to AlexNetWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7585960Discussion[D] Gary Marcus Tweet on OpenAI still has not changed misleading blog post about \"solving the Rubik's cube\" (self.MachineLearning)submitted 28 days ago by chansung1880 commentssharesavehidereportloading...all 80 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]Veedrac 82 points83 points84 points 28 days ago*\u00a0(29 children)Gary's summary is much more misleading than the blog post.\nConcerns 1-4: \u201cNeural networks didn't do the solving; a 17-year old symbolic AI algorithm did\u201d\nFTA: \u201cWe train neural networks to solve the Rubik\u2019s Cube in simulation using reinforcement learning and Kociemba\u2019s algorithm for picking the solution steps.\u201d\n(NB: I would prefer this to be stated more prominently in less technical terms.)\nConcern 5: \u201cOnly ONE object was manipulated, and there was no test of generalizability to other objects\u201d\nFTA: Five different prototypes were used, a locked cube, a face cube, a full cube, a giiker cube, and a \u2018regular\u2019 Rubik\u2019s cube. The article never claims to do anything other than solve Rubik's cubes.\nConcern 6: \u201cThat object was heavily instrumented (eg with bluetooth sensors). The hand was instrumented with LEDs, as well.\u201d\nFTA: The five different prototypes had different levels of instrumentation. The \u2018regular\u2019 Rubik's cube had none, except small corners cut out of the centre squares to remove symmetry.\nFTA: Videos of the LEDs. They're blinking and red, FFS.\nConcern 7: \u201cSuccess rate was only 20%; hand frequently dropped cube\u201d\nFTA: \u201cOur robot still hasn\u2019t perfected its technique though, as it solves the Rubik\u2019s Cube 60% of the time (and only 20% of the time for a maximally difficult scramble).\u201d\nFTA: A whole section dedicated to this issue.\n\npermalinkembedsavereportgive awardreply[\u2013]briggers 34 points35 points36 points 28 days ago\u00a0(2 children)This is what his book, Rebooting AI, is like.\nMany misrepresentations, and a general argumentation style of \"it isn't perfect, therefore it isn't good.\"\nThere is definitely a case for being much more cautious about ML\/DL than many over-hyped journalists are, but this guy is just looking to fill a contrarian niche.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]mimomusic 20 points21 points22 points 27 days ago\u00a0(1 child)I think Marcus is a well-spoken and intelligent man.\nI also think he is exceedingly pedantic to such a degree that he detracts from the actual problem at hand while most laymen are well capable to read between the lines and see research or blogposts for what they are.\nSure, precision in academia is not something you can just forego without regard for making yourself understood, but the people who actually care about that stuff are very likely to dive into the nitty-gritty anyway. Those who succumb to hype would misunderstand and fall for nonsense headlines even if they were 100% unambiguous and perfectly constructed - but who cares about what The Sun is trying to convey?\nAlmost all of us were well-aware of all the caveats parent poster mentioned, at least most of them. They are almost irrelevant in this context, even something as arguably crucial as generalizability (what a goddamn word!) takes a back seat to the main issue of robotic dexterity. \nI understand that different people approach subjects with different degrees of rigor, and I can feel Marcus' concerns, but I also think they are very much nitpicky and not at all important to the discussion as far as OpenAI's due diligence and openness to critique is concerned.\nHe sure is someone who will always be at odds with the community at large, but whether it's time well-spent is something I view with a healthy portion of skepticism; I think way too much effort goes into scrutinizing things that, as far as we can tell at this stage, barely matter in the long run.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sanxiyn 17 points18 points19 points 28 days ago\u00a0(20 children)I was actually disappointed by corner cutout for regular Rubik's cube. I consider that a significant instrumentation, and I think it is entirely justified to say that OpenAI did not solve vision part of regular Rubik's cube.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]whatevenarecomputers 2 points3 points4 points 27 days ago\u00a0(19 children)They also didn't claim to solve the vision part of Rubik's cube solving (and explicitly said so), so it can't really be used as a way to detract from the OpenAI article. It was an article about the physical manipulation.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]nrmncer 3 points4 points5 points 27 days ago\u00a0(10 children)tbh though what exactly has been achieved here then? Robots built to solve Rubik's cubes have been around for a while, most do it faster than that hand. The accuracy is low, it doesn't generalise well, there's a lot of hacks involved.. I guess the fact that it can fend off the giraffe is a novelty.\nBut without any generalisation and given the low accuracy there's not much news here.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]whatevenarecomputers 6 points7 points8 points 27 days ago\u00a0(1 child)There is a ton of generalization and resilience to new input here - putting scrunches around the fingers, putting it in a glove. Poking it as it solves. The breakthrough is the motion planning and object manipulation is done entirely through RL.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sheeplearning 2 points3 points4 points 26 days ago\u00a0(0 children)Yes but it is unclear if any of that is useful given it is not sufficient to solve the cube. Perhaps new approaches and additional experiments are needed and celebrating mediocrity just makes it harder for anyone to actually solve it. Robot does not really \"solve\", warcraft does not really \"see\", GPT2 is too harmful to the world and BERT outperforms and releases the model without any fuss -- everyone knows what is really going on here.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tshadley 4 points5 points6 points 27 days ago\u00a0(7 children)But why has no one built a Rubik's cube robot implementing a one-handed solve?  It's relatively easy to build a 5 fingered hand mock-up with servomotors.   It has to be because the controller algorithm to hold the cube, turn it, and solve it with 5 fingers is vastly complicated-- way beyond any traditional approach.  The Deep-Neural-Network dexterity algorithm is the amazing accomplishment here.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]kit_hod_jao 2 points3 points4 points 26 days ago\u00a0(0 children)I think this is part of the issue with the demo - it's hard to get a sense of how hard it is. I can certainly imagine it's very difficult to achieve, but one of the benefits of existing benchmarks is our expectations are finely calibrated to detect unusually good performance.\nStill, new benchmarks have to come from somewhere and IMO this is very impressive. It's just hard to appreciate how challenging it is.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]AnvaMiba 1 point2 points3 points 26 days ago\u00a0(3 children)\nIt's relatively easy to build a 5 fingered hand mock-up with servomotors.\n\nIt's not. Five finger robotic hands that can move accurately are crazy expensive. They are only used for research as prosthetics, not as standalone robots, which is why you don't see many people using them to do stunts like this.\nManipulation of objects of known shape and mass with stationary robots is a technologically mature task, there are plenty of industrial robots working on assembly lines which can manipulate objects much faster and more reliably than this. They don't use any fancy RL, just good old control theory and motion planning.\nSo what's the innovation there? That they used RL?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tshadley 0 points1 point2 points 26 days ago\u00a0(1 child)\nManipulation of objects of known shape and mass with stationary robots is a technologically mature task, there are plenty of industrial robots working on assembly lines which can manipulate objects much faster and more reliably than this. They don't use any fancy RL, just good old control theory and motion planning.\n\nAny specific example of comparable complexity?  From what I've seen, industrial robots motion environments are tightly constrained and limited.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]AnvaMiba 0 points1 point2 points 26 days ago\u00a0(0 children)\nFrom what I've seen, industrial robots motion environments are tightly constrained and limited.\n\nYes, for safety reasons. The OpenAI robot hand isn't strong or fast enough to cause injury, which is why they can fiddle with it while it's moving.\nThere are also robots designed for safe interaction with humans, or robust enough to resist external perturbations\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tshadley 0 points1 point2 points 26 days ago\u00a0(0 children)\n\nIt's relatively easy to build a 5 fingered hand mock-up with servomotors.\n\nIt's not. Five finger robotic hands that can move accurately are crazy expensive. They are only used for research as prosthetics, not as standalone robots, which is why you don't see many people using them to do stunts like this.\n\nTo more accurately make my point, I'll say it's relatively easy to obtain a 5-fingered hand mockup.  ShadowRobot seems to have built the first \"dexterous hand\" in 2005.  The hard part is controlling it.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]nrmncer 0 points1 point2 points 27 days ago\u00a0(1 child)\nBut why has no one built a Rubik's cube robot implementing a one-handed solve?\n\nmostly because if you're going to build a specialised machine it makes more sense to build.. well a regular machine. If all it can do is solve the cube then there's no need to make it to resemble a hand.  It's a nice video to look at but they already had dextrous movements down a year ago. This is essentially the same thing with a slightly more modular task.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tshadley 0 points1 point2 points 26 days ago*\u00a0(0 children)\nmostly because if you're going to build a specialised machine it makes more sense to build.. well a regular machine. If all it can do is solve the cube then there's no need to make it to resemble a hand.\n\nBut all regular machines for Rubik's solving have been built; clamps, rotating platforms, etc..  This was an obvious next step.\n\nIt's a nice video to look at but they already had dextrous movements down a year ago\n\nManipulating a solid cube with one hand is a vastly simpler than rotating individual planes of a Rubik's cube with one hand.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sanxiyn 2 points3 points4 points 27 days ago\u00a0(3 children)Isn't vision (or state estimation by vision) fundamental part of manipulation? I guess with Bluetooth instrumentation OpenAI showed manipulation \"would have worked\" if vision was working. But they couldn't get vision working.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]whatevenarecomputers 1 point2 points3 points 27 days ago\u00a0(2 children)I think it's much more likely that they wanted to focus on a solution for the physical motion planning. I would not be surprised if there were independent projects to handle the object recognition\/position portion (which is effectively a separate problem).\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sanxiyn 0 points1 point2 points 27 days ago\u00a0(1 child)OpenAI directly stated in the paper that they couldn't get vision working. See page 16. To quote:\n\nWe experimented with a recurrent vision model but found it very difficult to train to the necessary performance level. Due to the project\u2019s time constraints, we could not investigate this approach further.\n\n\npermalinkembedsaveparentreportgive awardreply[\u2013]whatevenarecomputers 0 points1 point2 points 27 days ago\u00a0(0 children)https:\/\/openai.com\/blog\/learning-dexterity\/\nThis appears to be their ongoing effort to implement the vision portion.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]ispeakdatruf -1 points0 points1 point 27 days ago\u00a0(3 children)So what does \"solve\" in the title mean? For a human, the harder part is figuring out the steps involved. I can teach a 5yo how to rotate the cube in a minute. But teaching the kid to actually solve the cube will take much longer.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]whatevenarecomputers 3 points4 points5 points 27 days ago*\u00a0(2 children)Yes, a rule of thumb for AI is the more intuitive for a human, the harder it is to make a computer do, and vice versa. We see this phenomena everywhere. Resilient motion planning and balance, object recognition, natural language processing, object location estimation. Humans do all this by the age of of 5.\nIt's easy to make a computer to solve (symbolically) Sudoku or a Rubik's cube. Hard or time consuming for a human (without lots of training). \"Can we figure out the order of rotations to solve a cube\" is not what OpenAI is trying to solve. That's a well explored, solved problem.\nConversely, human brains find spacial manipulation very intuitive past the age of like 3. But it's hard to build a system, even with fine-grained closed-loop feedback, that can manipulate physical objects. We have to design all sorts of loops and heuristics to estimate the physics of the object, how to move it in space, how to not drop it, how it can be folded or rotated or whatever. Letting reinforcement learning figure out all these nitty-gritty details represents novel progress being made in this space. \nThey have a system which seems to have figured out how to compensate for all sorts of messy inconsistencies like actuators not responding exactly how the model would expect it to (they mention it being resiliant even when actuators entirely break), all the way up to \"how do we figure out the individual finger movements to grasp and rotate a cube face\".\n\npermalinkembedsaveparentreportgive awardreply[\u2013]ispeakdatruf 0 points1 point2 points 27 days ago\u00a0(1 child)In my limited experience with robotics, I totally concur with you.\nIt would have be somewhat OK to title an academic paper with that title. People in the area would understand.\nBut that's not what OpenAI did. They put out a blog post with that title, which is clearly intended for the general lay audience. The average person, who knows nothing about how hard actuator control, sensors, etc., are, will naturally assume that the harder, cognitive problem is being solved.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]whatevenarecomputers 0 points1 point2 points 27 days ago\u00a0(0 children)What's the harder cognitive problem to solve here? If it's symbolically solving a cube, that's just not an interesting problem to solve, and we don't need ML to do it. It's not a game of Go. The interesting cognitive problem is the motion planning.\nI just disagree that the blog post is misrepresenting what OpenAI has accomplished. Its entire focus is on the hand, its motion, and the feedback systems involved.\nEven the title is \"Solving Rubik\u2019s Cube with a Robot Hand\". Sure, somebody could read only the title and come to the wrong conclusion. But that's not really OpenAI's problem.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]yuvalpinlp[\ud83c\udf70] 1 point2 points3 points 26 days ago\u00a0(3 children)So, about 1-4, in what sense does the RL net \"solve\" the cube?\n\"train to solve... picking the solution steps\" you don't find this phrasing very misleading?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Veedrac 0 points1 point2 points 26 days ago\u00a0(2 children)They say they \u201csolve the Rubik\u2019s Cube with a human-like robot hand.\u201d This is true.\nI agree that the phrasing of \u201cand Kociemba\u2019s algorithm for picking the solution steps\u201d is too technical to be properly transparent to the average reader, even many readers with ML background, and I agree it is not nearly prominent enough\u2014I said as much in my post.\nIf Gary's tweet was about that only\u2014as in, it did not make his other claims, and it was phrased so it was obvious the issue is clarity rather than honesty\u2014I'd have supported his commentary unreservedly.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]yuvalpinlp[\ud83c\udf70] 0 points1 point2 points 25 days ago\u00a0(1 child)I'm sorry, I find it impossible to interpret \"solve\" as anything other than \"figure out what to do at each step\", which is the one thing their RL system *didn't* do.\nAs Gary noted, there are other, much more accurate verbs to use, my vote goes to \"manipulate\".\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Veedrac 0 points1 point2 points 25 days ago\u00a0(0 children)I disagree that bringing a cube to the solved position cannot be described as solving it, but your disaffection is understandable and this wasn't one of my points of disagreement with the original post. I agree that \u2018manipulate\u2019 would be a much clearer term.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]SkiddyX 58 points59 points60 points 28 days ago*\u00a0(6 children)This subreddit\u2019s unquenchable thirst for drama continues... \ud83d\ude02\n\npermalinkembedsavereportgive awardreply[\u2013]booleyan 28 points29 points30 points 28 days ago\u00a0(2 children)Siraj started a fire we can't put out.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]egrefen 11 points12 points13 points 27 days ago\u00a0(0 children)It's always been burning \ud83c\udfb6\nSince GPUs been churning \ud83c\udfb5\n\npermalinkembedsaveparentreportgive awardreply[\u2013]ispeakdatruf 2 points3 points4 points 27 days ago\u00a0(0 children)You_again would beg to differ...\n(with due apologies to Prof Schmidhuber, who has been shafted by the rest of the community)\n\npermalinkembedsaveparentreportgive awardreply[\u2013]LaVieEstBizarre 12 points13 points14 points 27 days ago\u00a0(1 child)Experts hate hype machines\n\npermalinkembedsaveparentreportgive awardreply[\u2013]dod_worker 12 points13 points14 points 27 days ago\u00a0(0 children)And hypers hate expert machines!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]MonstarGaming 2 points3 points4 points 26 days ago\u00a0(0 children)For real. We ban beginner tutorials only to fill the gap with community drama. WTF? I wish we could tag and filter this content at the very least.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]balls4xx 13 points14 points15 points 28 days ago\u00a0(0 children)A lego bot can solve (rotate until each side has a single color) a Rubik\u2019s cube, even I can solve one after inputting the tile pattern into some website. I think what they \u2018solved\u2019 here was making a robotic hand do it while being accosted by a stuffed giraffe.\n\npermalinkembedsavereportgive awardreply[\u2013]tradediscount 37 points38 points39 points 28 days ago*\u00a0(17 children)I think Marcus is being a little disingenuous here. The key achievement of the OpenAI research he refers to is using reinforcement learning for really hard real world manipulation of physical objects using a robot hand.\nThe Rubik's cube is used as a prop to represent a hard real world problem (hard as in difficult to manipulate effectively).\nOpenAI's blog post explicitly (but perhaps not prominently enough for Marcus or seemingly many subeditors who missed it in their reporting) states they use Kociemba's algorithm to determine the next move. This non AI shortcut was presumably used to reduce the number of steps, given the already high difficulty physical manipulation task they'd set themselves.\nGranted, many newspapers reported is as if the ML part had also worked out how to solve the cube, <and OpenAI have not tried to correct the misreporting>, but I'm not sure that's feasible or even necessary.\nEdit: bit between angle brackets not true, see u\/thegdb comment below.\nIn addition, the cube has been solved using deep nets by several other teams (a quick Google shows published in reputed journals too) so while not trivial I have no doubts OpenAI could also solve it if they chose to.\nFinally, Marcus seems to like creating controversy to publicise his view that a lot of the DL community misrepresent the promise and capabilities of DL, which in my view simply isn't true. Hinton, Bengio, Le Cun, Chollet et al have all in my view been very open, measured and fair about the technology.\n\npermalinkembedsavereportgive awardreply[\u2013]thegdbOpenAI 44 points45 points46 points 28 days ago\u00a0(9 children)\nGranted, many newspapers reported is as if the ML part had also worked out how to solve the cube, and OpenAI have not tried to correct the misreporting, but I'm not sure that's feasible or even necessary.\n\nWe ping journalists to ask them to correct factual errors in reporting when we see them (though they may not always agree with our corrections). For example, the Washington Post article (https:\/\/www.washingtonpost.com\/technology\/2019\/10\/18\/this-robotic-hand-learned-solve-rubiks-cube-its-own-just-like-human\/) feels misleading, so we've emailed them and linked them to the relevant sections in our blog post (namely, that we use Kociemba's algorithm as you mention).\nIf you see other articles that need correcting, always feel free to let me know \u2014 gdb@openai.com!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tradediscount 7 points8 points9 points 28 days ago\u00a0(0 children)I stand corrected. Nice one!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]openaievolution 1 point2 points3 points 27 days ago*\u00a0(1 child)Tbf this is an artifact of your \"science by press release\" strategy as well. If you release a public preprint first, journalists will have an easier time sourcing opinions from other well informed folks in the field, and presumably the reporting would get better.Zach Lipton elaborates more on this point in this thread here: https:\/\/twitter.com\/zacharylipton\/status\/1184237037622136832 \nPS: To be clear, I am not arguing for not doing press releases, but rather putting out a preprint first and allowing some time b\/w the preprint and the press release.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]whatevenarecomputers 2 points3 points4 points 27 days ago\u00a0(0 children)When has a reporter ever erred on the side of measured response from experts in the field instead of writing up the most sensationalized version they could concoct and still maintain plausible deniability?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus -2 points-1 points0 points 28 days ago\u00a0(4 children)why not post some sort of clarification on your own site? it is clear that your blog was prone to misinterpretation.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Ghenlezo 32 points33 points34 points 28 days ago*\u00a0(3 children)I am a little baffled by your reaction to this. You worked with robots before, yes? The fact that they actually got a hand to sort of work on an intricate task, and to the point that it is able to adapt to many perturbations, is astonishing. \nDid they make any deep algorithmic breakthroughs? No, but nor did they claim to. They scale things up and see how far they can push them. This is super useful work. AI is an engineering discipline not a science, and unfortunately is half-ashamed of this fact. \nWas anyone with any literacy fooled into thinking the cube-solver was learned? It says right in the post it was done symbolically. Even if the solver was learned that is, frankly, much less impressive than demonstrating modestly robust physical dexterity.\nYour critique of the major deep learning figures is of naked emperors. But I see scholars constantly apologizing for their state of undress, baffled at how well they are weathering ever-colder temperatures.  \nOne begins to wonder if invisible wool does, in fact, exist.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus 0 points1 point2 points 28 days ago\u00a0(1 child)Curious for your take compared to the much less hyped Baoding balls the week before. Here's what I said in the tweet that you apparently didn't read: I will say again that the work itself is impressive, but mischaracterized, and that a better title would have been \"manipulating a Rubik's cube using reinforcement learning\" or \"progress in manipulation with dextrous robotic hands\" or similar lines.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Ghenlezo 30 points31 points32 points 28 days ago*\u00a0(0 children)I read your \u201cdetailed analysis\u201d meme. I have not read every tweet you wrote on the matter. I am glad you admit that the progress on the actual task they were attempting was good.\nYour image macro makes it look as if you are dismissing impressive work for trivial misunderstandings.  Anyone with any experience in this stuff knows, watching the video not even reading the paper, that what is impressive is the dexterity, and that solving a cube is trivial symbolically.\nImagine we\u2019re watching a ski race on television and someone said, \u201cYou know they may be able to ski down fine but what they don\u2019t show you is they don\u2019t ski up! They use a chairlift!\u201d\nThat\u2019s the impression your image macro gives me.\nThey say right in the post that it was done symbolically. Failure to spoon feed journalists is not a sin in my book.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tristes_tigres 0 points1 point2 points 27 days ago\u00a0(0 children)\nAI is an engineering discipline not a science\n\nEngineering consists in applying known scientific principles to solve the real-world problems. AI at this point is barely more than alchemy - a compendium of techniques that seem to work from time to time for unknown reasons, that is very useful for extracting funding from wealthy patrons hoping to expand their riches.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]master_yoda_1 -2 points-1 points0 points 27 days ago\u00a0(0 children)The same nonsensical hype you guys created with gpt-2 by not releasing it, and later on you proved yourself wrong and released it.\nWhat is your comment about that?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]m_nemo_syne 2 points3 points4 points 26 days ago\u00a0(3 children)(I have to be pedantic for a moment: you call Kociemba's algorithm a \"non AI shortcut\", but it is AI, just not machine learning. This is an instance of the \"AI effect\": https:\/\/en.wikipedia.org\/wiki\/AI_effect)\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tradediscount 1 point2 points3 points 26 days ago*\u00a0(1 child)I strongly disagree. You are being precise, not pedantic, and I appreciate it thoroughly.\nedit: would \"non ml\" be better?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]m_nemo_syne 1 point2 points3 points 26 days ago\u00a0(0 children)Thanks! I think so :)\n\npermalinkembedsaveparentreportgive awardreply[\u2013]WikiTextBot 0 points1 point2 points 26 days ago\u00a0(0 children)AI effect\nThe AI effect occurs when onlookers discount the behavior of an artificial intelligence program by arguing that it is not real intelligence.Author Pamela McCorduck writes: \"It's part of the history of the field of artificial intelligence that every time somebody figured out how to make a computer do something\u2014play good checkers, solve simple but relatively informal problems\u2014there was a chorus of critics to say, 'that's not thinking'.\" AIS researcher Rodney Brooks complains: \"Every time we figure out a piece of it, it stops being magical; we say, 'Oh, that's just a computation.'\"\n\n[ PM | Exclude me | Exclude from subreddit | FAQ \/ Information | Source ]\nDownvote to remove | v0.28\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus -1 points0 points1 point 28 days ago\u00a0(1 child)i am not aware of any system that has solved the cube with pure RL; the ones i have seen are hybrids that also include monte carlo tree search. correct me if i am wrong...\n\npermalinkembedsaveparentreportgive awardreply[\u2013]nikitau 1 point2 points3 points 23 days ago*\u00a0(0 children)DeepCubeA for example does it with A* and trains the heuristic using function approximation and value iteration. While I haven't seen a system that reliably solves the cube using just RL without search, I feel like the same case could be made about Go too.\nDo you feel that lookahead is somewhat \"cheating\" in this case? Just curios, because at the end of the day, what gives such systems the edge over pure search ones is the fact that they learned how to guide the search.\nupdate: I actually read your write-up about innateness in AlphaZero in the meantime and understand a bit more where your statement is coming from. Its a good read and gave me a bit more insight into your point of view and I will say that I agree that in the philosophical context of AGI, using search definitely equates to injecting priors and is far from a tabula rasa approach.\nI get why you consider why their success may be uninteresting wrt. AGI; however within the domain of fully observable, deterministic environments, search methods could be seen as a common and rather simple denominator of all solvers, which one would be foolish not to use. If we are referring only to this small subset of all environments (which does model a lot of useful processes still) wouldn't AlphaZero (say apart from its use of CNNs) be one of the least biased solvers? I am curios on your thoughts about this.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus -3 points-2 points-1 points 28 days ago\u00a0(0 children)Hinton in particular sometimes over promised quite a bit; i will likely write about that soon.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]JonathanFly 13 points14 points15 points 28 days ago*\u00a0(7 children)I don't have the expertise to comment on the physical simulation part of this, so there may be some valid critique on that end, but I don't understand the primary criticism in this particular post.\nIsn't it obvious that solving the Rubik's cube is just a proxy for any dexterity challenge?  Learning how to solve a Rubik's cube is trivial, it's inconsequential.\nFor example, if OpenAI's project was 'robot that plays Tic Tac Toe in adverse conditions' and then in the video we see the Tic Toe paper oriented in different directions or moving around the table, in a room with dark or very bright light, on a table that's vibrating, with leaves blowing all around obstructing vision, using random types of pens and pencils that the robot arm has to adapt to on the fly -- this would basically be the same paper.  Would you apply your same top-line criticisms to that project? Would you say the 'neural network isn't actually playing Tic Tac Toe, it's the 2000 year old Tic Tac Toe algorithm?'\nMaybe the problem is Rubik's cube have a mystique around them when I thought it was pretty clear that figuring out what to rotate is a trivial problem that any robot or human can already solve.\n\npermalinkembedsavereportgive awardreply[\u2013]ispeakdatruf 2 points3 points4 points 27 days ago\u00a0(3 children)\nLearning how to solve a Rubik's cube is trivial, it's inconsequential.\n\nSo, you have an RL algorithm that figured out how to solve Rubik's Cube?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sanxiyn 1 point2 points3 points 26 days ago\u00a0(1 child)You may like Solving the Rubik's Cube Without Human Knowledge.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]ispeakdatruf 0 points1 point2 points 26 days ago\u00a0(0 children)Thank you, I was unaware of that work. Upvoted!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus 0 points1 point2 points 28 days ago\u00a0(1 child)many many people misunderstood the article given how it was framed; the washington post coverage is a case in a point.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Ghenlezo 19 points20 points21 points 28 days ago*\u00a0(0 children)Journalists have terrible incentives, as a rule no technical training, and little time. \u201cJournalists misunderstand you in the manner most likely to grab clicks\u201d is a universal argument against anyone who has interacted with a journalist.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]subsampled 5 points6 points7 points 27 days ago*\u00a0(0 children)I think Marcus regularly raises interesting objections and ideas in the nature vs nurture (and symbolic vs connectionist) debate. Here, however, he may have missed the main point of this work, which emerges pretty clearly from the series of works by the same group.\nThe main progress is clearly is in the context of in-hand manipulation via RL, whose complexity is very well-known to roboticists.\nControlling a complex tendon-driven hand like the Shadow Hand to reconfigure an object with several degrees of freedom in presence of multiple contacts and disturbances has been a moonshot in robotics since forever. It's also true that OpenAI may have done better with choosing the title, but the work seems still a significant breakthrough, for sure in its robotics and transfer parts.\nAnd yes, in my experience 60% performance for the average case is definitely a good result for robotics demos standards of similar complexity.\n\npermalinkembedsavereportgive awardreply[\u2013]garymarcus 7 points8 points9 points 28 days ago\u00a0(1 child)what\u2019s most notable about many of the comments here is that it is largely just ad hominem attacks; nobody can really argue that the screenshot on the left half of the slide of analysis (ie the opening of openAI\u2019s blog) actually matches what the paper did, and few people here are willing to acknowledge how widely the result was misinterpreted.  \nPR that invites serious misinterpretation is the definition hype; in the long run ML will suffer from a pattern of overpromising, just as earlier approaches (eg expert systems) have.\n\npermalinkembedsavereportgive awardreply[\u2013]adventuringraw 22 points23 points24 points 27 days ago\u00a0(0 children)man, I came here ready to jump on OpenAI for being overly hyped, but their coverage itself really did seem measured, in spite of the press apparently misunderstanding it. Reading through the comments, I see mostly praise for you, combined with everyone roughly saying 'but in this case, it seems like Marcus jumped the gun, here's why'.\nYou taking such a measured community reaction here as being nothing but 'ad hominem attacks' really makes me question what thread you were reading, because it apparently wasn't this one. If you're going to dig around to make sure claims are perfectly represented with no room for misinterpretation (a worthwhile activity given the current AI hype, don't get me wrong) you really don't get to so badly misrepresent your own treatment on a little subreddit like this. Literally anyone can read the other 30 comments on here. Does anyone else see 'ad hominem attacks'? Because I sure don't. Aside from a passing comment about 'filling a contrarian niche' it seems to be more about OpenAI's coverage, your specific critiques, and what people think about the issue. I saw your post, I read the blog post, it might have been easier than it should have been for a lay audience to misinterpret, but I really don't buy that it was on purpose. I don't even buy that it needs to be changed now that the mainstream reporters have come and gone, I honestly read OpenAI's coverage as intended, this was an impressive milestone in physical dexterity, that's it. As another comment pointed out, doing the whole solution (solving and all) in one learned architecture probably wouldn't have been radically harder than what was achieved even, assuming the other comment was correct, and there are other papers doing the actual Rubik's Cube solution finding. The reasons given in other comments for not buying your reasoning matches my own. My (honestly mostly unformed, I don't know your work well) opinion of you as a person doesn't factor into my not accepting your analysis in this case.\nAside from one apparently actually rude ad hominem attack (that was called out by someone else, the original user deleted their post now) what's left is a long ways away from being unfair to you. If you're going to misrepresent your own treatment in such an obvious way, I'm not impressed when the topic you're trying to push is another group misrepresenting their research.\nThat said, even if you were maybe a little overzealous in this case, and even if you're taking it a little personally that not everyone else here agrees with you, I wholeheartedly wish that mainstream reporting was more realistic, so Godspeed on your quest.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus 1 point2 points3 points 28 days ago\u00a0(13 children)you may have caught a minor error here but mostly you are comparing apples and oranges. \nmy main point was that the popular presentation (ie the blog) was misleading; finding stuff in the fine print in the technical paper doesn\u2019t fix that.  and even so,  note that the title of the article itself is misleading, as is the opening framing, as i detailed in a previous tweet. so the article itself has its own issues. \ni am really most concerned though with your anemic defense of point 5: it doesn\u2019t matter whether openAI claimed to have looked at more than one object or not; the point is that if you don\u2019t have stronger tests of generalization, you can\u2019t make profound claims.  5 slightly different cubes doesn\u2019t mean you could not tighten a screw, open a lock, or button a shirt.\n\npermalinkembedsavereportgive awardreply[\u2013]Veedrac 17 points18 points19 points 28 days ago\u00a0(7 children)You replied to the post rather than me.\n\nfinding stuff in the fine print in the technical paper\n\nEverything I said was from the blog post, and not even a particularly close read of it. I don't expect the press to read dense technical papers, but I do expect them to read more than the title of the summarizing blog.\n\n5 slightly different cubes doesn\u2019t mean you could not tighten a screw, open a lock, or button a shirt.\n\nOpenAI never claimed otherwise.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus -3 points-2 points-1 points 28 days ago\u00a0(6 children)perhaps i should have said blog abstract (ie the part reproduced in my slide); the Washington Post story stands as a testament to how prone the piece was to being misread, \nit\u2019s not just the title, but the full framing in the abstract i reproduced. and how much emphasis there is in the article on learning relative to the small space devoted to the large innate contribution, etc\n.and even on your last point \u201cunprecedented dexterity\u201d at top suggests that they ought to be able to do this in general in some\nform; they haven\u2019t actually tested that (aside from variants on a cube). as someone apparently in Ml, you should recognize how unpersuasive that is. there is a long history of that sort of thing having seriously trouble generalizing.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Veedrac 14 points15 points16 points 28 days ago\u00a0(1 child)The quote is \u201cThis shows that reinforcement learning isn\u2019t just a tool for virtual tasks, but can solve physical-world problems requiring unprecedented dexterity.\u201d I find it very hard to understand where your objection is coming from; that sentence is plenty reasonable.\nAt this point I think my comments stand on their own, so I'm going to bow out.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus 4 points5 points6 points 28 days ago\u00a0(0 children)Which problems? without a test of generalizability to other noncubic, noninstrumented objects, and without a comparison to the Baoding result from a week before, I think the sentence is overstated. what are the plural \"problems\" even? I see one problem, no test of transfer. By know we should know that this is a red flag.\nWhich doesn't mean that I am unimpressed. In fact,  I  said the following, in a immediate reply to my own tweet that you must not have read: \"I will say again that the work itself is impressive, but mischaracterized, and that a better title would have been \"manipulating a Rubik's cube using reinforcement learning\" or \"progress in manipulation with dextrous robotic hands\" or similar lines.\"\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sanxiyn 1 point2 points3 points 28 days ago\u00a0(3 children)We can all agree that move finding was innate, but why does that mean \"large innate contribution\"? It was a small part of the work, so innate contribution was small.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus 2 points3 points4 points 28 days ago\u00a0(2 children)I guess this depends on how you define solving. But: You take out the innate part, and it no longer solves the cube.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sanxiyn 1 point2 points3 points 27 days ago\u00a0(1 child)I am all for retitling the post to \"Manipulating Rubik's Cube\" as you suggested. After retitling, innate contribution was small.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus -1 points0 points1 point 27 days ago\u00a0(0 children)That title would certainly help a lot, and reduce the importance of innate component, though elsewhere there is still a fair amount of carefully engineered innate detail of different sorts in the precise structuring of the visual system etc. It's not like it was a big end-to-end network fed from a bunch of sources that worked everything out for itself.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]simpleconjugate 12 points13 points14 points 28 days ago*\u00a0(4 children)As time has progressed, your criticisms come off as \u201cbad faith criticisms\u201d.\nIn this case you disguise problems with science and tech journalism as problems with OpenAI\u2019s communication of achievement. GDB is right, they never made any large claims outside being able to manipulate the cubes.\nIt would be great to have people out there who are keeping conversation around AI grounded, but that doesn\u2019t seem to be your primary interest or goal.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]garymarcus 7 points8 points9 points 28 days ago\u00a0(1 child)the problem here was with openAi\u2019s communication; i have been clear about that, posting repeatedly on twitter that result was impressive though not as advertised.  here is an example since you seem to have missed it: https:\/\/twitter.com\/garymarcus\/status\/1185680538335469568?s=21\nno person in the public would read the claim of \u201cunprecedented dexterity\u201d as being restricted to cubes.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]simpleconjugate 4 points5 points6 points 28 days ago*\u00a0(0 children)A change in title should be made for sake of honesty (social media isn\u2019t known for its in depth readings).\nHowever unprecedented dexterity is certainly a reasonable description of the impressive result.  I also don\u2019t think that the same \u201cperson in the public\u201d would read your tweets and think that OpenAI achieved anything important. In this sense, you mischaracterized OpenAI\u2019s own claims and achievements while reporting their own failures to communicate. \nYou are doing great work out there by pointing out the flaws in the hype. But at the same time, it feels that your criticisms serve Robust.AI more than the public. As someone who think ML needs to be become more rigorous in reporting results, I think recent posts highlight things that journalist irresponsibly reported on as well as mistakes made by OpenAI.\nSuffice to say, lately I feel the same about both you and OpenAI as you feel about OpenAI and the \u201cperson in the public\u201d.\n\npermalinkembedsaveparentreportgive awardreply[\u2013][deleted] 28 days ago\u00a0(1 child)[deleted]\n\n[\u2013]simpleconjugate 1 point2 points3 points 28 days ago\u00a0(0 children)That seems like an unnecessary personal attack.  There is a clear line between criticizing his ideas and attacking him. You crossed it.\n\npermalinkembedsavereportgive awardreply[\u2013]Rasko__ 0 points1 point2 points 26 days ago\u00a0(0 children)Jesus Christ who cares\n\npermalinkembedsavereportgive awardreply[+]SugarAdamAli comment score below threshold-13 points-12 points-11 points 28 days ago\u00a0(0 children)This is all way too over my head, but I\u2019ll take your word for it\n\npermalinkembedsavereportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 14708 on  r2-app-01066b27922181a56  at 2019-11-17 07:41:59.953985+00:00 running 85b1b7a country code: US."
  },
  "14":{
    "title":"[D] Siraj Raval - Potentially exploiting students, banning students asking for refund. Thoughts? : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-aww-funny-worldnews-gaming-todayilearned-pics-videos-Jokes-gifs-movies-mildlyinteresting-tifu-LifeProTips-television-creepy-Showerthoughts-nottheonion-OldSchoolCool-Futurology-science-TwoXChromosomes-dataisbeautiful-askscience-IAmA-sports-Art-nosleep-food-explainlikeimfive-books-space-Music-photoshopbattles-EarthPorn-UpliftingNews-gadgets-history-DIY-WritingPrompts-Documentaries-GetMotivated-listentothis-philosophy-announcements-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsother discussions (5)Want to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  21 Sep 20191,259 points (98% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave818,555 readers2,385 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X30  \u00b7 10 comments [D] Is the inception architecture\/block a failure?8  \u00b7 1 comment [D] Machine Learning - WAYR (What Are You Reading) - Week 7513  \u00b7 8 comments [R] Neural Network Processing Neural Networks240  \u00b7 24 comments [P] baikal: A graph-based functional API for building complex scikit-learn pipelines4 [D] Best resources to learn about Anomaly Detection on Big Datasets?2  \u00b7 1 comment [N] Microsoft Incorporates Graphcore AI Chips in Azure Cloud42  \u00b7 8 comments [D] Lets Talk About Vicarious Inc.23  \u00b7 4 comments [D] Recommendations about users and repository that has good organization in ML projects on Github0 [D] Transfer Learning for Survival Models0 [D] Statistical\/ML analysis of intention + wordnets, phrasenetsWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7125812591260Discussion[D] Siraj Raval - Potentially exploiting students, banning students asking for refund. Thoughts? (self.MachineLearning)submitted 1 month ago * by nord2rocksI'm not a personal follower of Siraj, but this issue came up in a ML FBook group that I'm part of. I'm curious to hear what you all think.\nIt appears that Siraj recently offered a course \"Make Money with Machine Learning\" with a registration fee but did not follow through with promises made in the initial offering of the course. On top of that, he created a refund and warranty page with information regarding the course after people already paid. Here is a link to a WayBackMachine captures of u\/klarken's documentation of Siraj's potential misdeeds: case for a refund, discussion in course Discord, ~1200 individuals in the course, Multiple Slack channel discussion, students hidden from each other, \"Hundreds refunded\"\nAccording to Twitter threads, he has been banning anyone in his Discord\/Slack that has been asking for refunds.\nOn top of this there are many Twitter threads regarding his behavior. A screenshot (bottom of post) of an account that has since been deactivated\/deleted (he made the account to try and get Siraj's attention). Here is a Twitter WayBackMachine archive link of a search for the user in the screenshot: https:\/\/web.archive.org\/web\/20190921130513\/https:\/twitter.com\/search?q=safayet96434935&src=typed_query. In the search results it is apparent that there are many students who have been impacted by Siraj.\nUPDATE 1: Additional searching on Twitter has yielded many more posts, check out the tweets\/retweets of these people: student1 student2\nUPDATE 2: A user mentioned that I should ask a question on r\/legaladvice regarding the legality of the refusal to refund and whatnot. I have done so here. It appears that per California commerce law (where the School of AI is registered) individuals have the right to ask for a refund for 30 days.\nUPDATE 3: Siraj has replied to the post below, and on Twitter (Way Back Machine capture)\nUPDATE 4: Another student has shared their interactions via this Imgur post. And another recorded moderators actively suppressing any mentions of refunds on a live stream. Here is an example of assignment quality, note that the assignment is to generate fashion designs not pneumonia prediction.\nUPDATE5: Relevant Reddit posts: Siraj response, question about opinions on course two weeks before this, Siraj-Udacity relationship\nUPDATE6: The Register has published a piece on the debacle, Coffezilla posted a video on all of this\nUPDATE7: Example of blatant ripoff: GitHub user gregwchase diabetic retinopathy, Siraj's ripoff\nUPDATE8: Siraj has a new paper and it is plagiarized\nIf you were\/are a student in the course and have your own documentation of your interactions, please feel free to bring them to my attention either via DM or in the comments below and I will add them to the main body here.\n\u200b\nhttps:\/\/preview.redd.it\/i75r44bku7o31.jpg?width=347&format=pjpg&auto=webp&s=ec2f02ee1998e27ea00d529ffb2086657dc60d77\n\n500 commentssharesavehidereporttop 200 commentsshow all 500sorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]rayryeng 134 points135 points136 points 1 month ago*\u00a0(8 children)We posted something similar in r\/learnmachinelearning a while back and it gained almost no traction. \nhttps:\/\/www.reddit.com\/r\/learnmachinelearning\/comments\/cp7kht\/guys_what_do_you_think_about_siraj_ravals_new\/\nWe should have posted here to gain momentum. This guy is a fake through and through. I actually practice ML as a career but took his course to network and to see what his perspective was on the different industries he was going to talk about.  Part of his course has a Slack workspace where people connect and discuss the course. Some of us couldn't send messages on Slack to each other as we couldn't find our peeps who joined, which we found weird.  We then found out that he had two Slack workspaces going on at the same time, one with about 500 students and the other about 770 students at the time (as of September 4th, 2019).... so there were almost 1200 students enrolled.  He imposed a 500 student limit at the beginning when signing up for the course. Not only did he lie about the 500 max limit of enrollment, he actively hid it from all of us - one Slack workspace didn't know the other Slack workspace existed.  With almost 1200 students, this is the main reason why he was virtually non-existent and not around answering questions.  He couldn't handle having so many students all by himself but he somehow manages to find time posting content on YouTube.  I believe that 500 student limit was his \"clever\" way of creating a FOMO moment so that there were more than 500 signing up which would rake in quite a bit of cash.  Some of us all pooled together and made an official complaint on the larger Slack workspace. \nWhen Siraj finally got caught, he decided to own up to his mistakes and apologized for \"making a few exceptions\" which ended up letting more people in than he should have.  When we all purchased the course, he did not have an official refund policy.  As the School of AI is a registered Calfornia business, commerce law mandates that you have 30 days to ask for your money back if you feel dissatisfied with the service if no official refund policy is in place at the time of purchase.\nHe tried to circumvent this by handling refunds on a \"case-by-case\" basis and put up a refund policy only *after* he got caught enrolling more people than he should have.  On top of other issues like lack of availability, not answering many questions he was asked and not hiring TAs to help him with the course, we all started to ask for our money back.  BTW he has some TAs now so I suppose that's one thing going for him.\nHe has given some of us our money back (myself included) but there are still some students who have been ignored or have been promised refunds and have not received them yet.  He moved the course over to Discord where his TAs are now running the show and anyone who is asking for a refund has been stifled and kicked from the server.\nIn the end, many of us felt disheartened, disenfranchised regarding our right to a voice and lost respect for who Siraj is as a large online presence.  We have left the course but hope that the rest of the students remaining will get something good out of what's left of it. Judging from the comments here, there's no hope in hell of that happening.\nEdit: For language and flow\n\npermalinkembedsavereportgive awardreply[\u2013]nord2rocks[S] 27 points28 points29 points 1 month ago\u00a0(2 children)\nHe tried to circumvent this by handling refunds on a \"case-by-case\" basis and put up a refund policy only *after* he got caught enrolling more people than he should have.  On top of other issues like lack of availability, not answering many questions he was asked and not hiring TAs to help him with the course, we all started to ask for our money back.  BTW he has some TAs now so I suppose that's one thing going for him.  \nHe has given some of us our money back but there are still some students who have been ignored or have been promised refunds and not received them yet. \n\nHi, I just used some of your comment to form this question in the r\/legaladvice subreddit here\n\npermalinkembedsaveparentreportgive awardreply[\u2013]rayryeng 10 points11 points12 points 1 month ago\u00a0(1 child)Thanks. Please feel free to use any information from me or request anything else. I'm amongst many disgruntled people who have been dissatisfied.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)[\u2013]brownck 7 points8 points9 points 1 month ago\u00a0(3 children)He lost me when I was reading an interview with him and he said his first \"AI\" project was linear regression and he used sklearn to do it. If you can't even write a linear regression code from scratch you shouldn't be teaching a course in AI at all.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]kasanitej 5 points6 points7 points 1 month ago\u00a0(1 child)most ppl started with linear regression & sklearn... I started like that\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)load more comments\u00a0(1 reply)load more comments\u00a0(1 reply)[\u2013]Philanthrapist 92 points93 points94 points 1 month ago\u00a0(11 children)He used to have a cryptocurrency and some bs scheme around it which reeked of fraud. Thought the dude was entertaining back when I was a newbie, stopped following long ago. I can't find his \"Sirajcoin\" stuff on youtube anymore, he's probably deleted it.\n\npermalinkembedsavereportgive awardreply[\u2013]spamkeke 37 points38 points39 points 1 month ago\u00a0(6 children)http:\/\/www.sirajcoin.io seems to be still up. Looks very sketchy.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]SupportVectorMachine 46 points47 points48 points 1 month ago\u00a0(4 children)Well, for one thing, even the thumbnail for his \"whitepaper\" (\"SirajCoin Explained\") is stolen from the first page of Benet's for Filecoin with the title and author chopped off.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]clickbait_hmmm 5 points6 points7 points 1 month ago\u00a0(0 children)wth\nthat is fucked up\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(3 replies)load more comments\u00a0(1 reply)[\u2013]yakri 56 points57 points58 points 1 month ago\u00a0(3 children)He has some, mostly older, introductory type content that's perfectly decentish, aside from being clogged with meme editing and the stereotype brogramming youtube HIGH ENERGY ARE YOU EXCITED bs that's everywhere now. However anything that is supposed to be more meat and potatoes in depth lacks any depth and is about on the same level as the introductory stuff, presumably because he doesn't have that depth of knowledge.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]SupportVectorMachine 51 points52 points53 points 1 month ago\u00a0(1 child)\nbrogramming\n\nI can't believe this is the first time I've seen this term.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]nwoodruff 11 points12 points13 points 1 month ago\u00a0(0 children)It's so accurate I might start using it\n\npermalinkembedsaveparentreportgive awardreply[\u2013]ProfessorAlgorithm 5 points6 points7 points 1 month ago\u00a0(0 children)If you watch his videos carefully, you will also notice that he doesn't write the code himself.  Its always some other user's GitHub page he links to, then he just types out the code.  Basically, he finds a cool GitHub repo, and makes a video about it (unsure with or without permission).  \nIt is pretty clear to me that he doesn't understand all of the code he types, since I watch with a different perspective.  I watch to see if this could be a good way of students learning the basics of ML.  It isn't.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Lost_City_ 587 points588 points589 points 1 month ago\u00a0(210 children)I've been warning people about this dude for a while. His entire existence is just meant to exploit people who romanticize the field with low tier educational content that is mostly inflated with hype. I was kind of irritated when Lex Fridman had him on the show because I feel like it gave him some air of legitimacy. I'm not sure how anyone could go to Siraj's website and think anything other than snake oil salesman.\n\npermalinkembedsavereportgive awardreply[\u2013]EmbersArc 335 points336 points337 points 1 month ago*\u00a0(34 children)I once trained a reinforcement learning agent to land SpaceX rocket on a pad. He made a pretty half-assed video about it giving minimal credit on his GitHub. He didn't even bother training it himself with my code and instead just played the GIF from my GitHub page. People where rightfully confused about how to do it themselves, which I pointed out to him. He never even acknowledged it. Quite disappointing and counterproductive really.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]walesmd 85 points86 points87 points 1 month ago\u00a0(2 children)A former employer of mine was working with him on some educational content and we had to have a long talk with him about how taking code from other people's GitHub\/blogs, treating it as your own and not attributing the original author, was both wrong and illegal.\nI'm so glad I didn't have to directly work on this project.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]jambonetoeufs 25 points26 points27 points 1 month ago\u00a0(1 child)Udacity?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Naveos 16 points17 points18 points 1 month ago\u00a0(0 children)Explains why you won't find any of his videos nor work at Udacity's nanodegree anymore. They wiped him off entirely from their platform.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]MrKlean518 35 points36 points37 points 1 month ago\u00a0(11 children)He did the same thing with an RL agent on a drone flight controller. He said his code was an \u201ceasy to use high-level wrapper\u201d for the original code when his code didn\u2019t even work properly on my machine and the referenced code did. It was pretty clear he just ripped the code and rewrote some functions without refactoring the references or something.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]programmerChilli 10 points11 points12 points 1 month ago\u00a0(1 child)Rewrote functions? Good one. Usually he just copy pastes the whole repo while making no changes except adding his branding.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)load more comments\u00a0(9 replies)[\u2013]Linooney 70 points71 points72 points 1 month ago\u00a0(16 children)Lmao he didn't even spell the Python command properly at the end to run the command... unless he mapped \"python\" to \"pyton\" for some reason...\n\npermalinkembedsaveparentreportgive awardreply[\u2013]muntoo 234 points235 points236 points 1 month ago\u00a0(15 children)I dunno about you, but this is my ~\/.aliases file:\nalias pyton=\"python\"\nalias pyon=\"python\"\nalias pyhton=\"python\"\nalias phyton=\"python\"\nalias hpyton=\"python\"\nalias hyptom=\"python\"\nalias ptjghn=\"python\"\nalias afsadf=\"python\"\n\nfor ((i=1; i < 999999; i++)); do\n    cmd=\"$(dd if=\/dev\/urandom bs=6 count=1)\"\n    eval \"alias ${cmd}='python'\"\nend\n\nIt's very practical and I recommend everyone add it to theirs.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Ravenhaft 33 points34 points35 points 1 month ago\u00a0(0 children)Oh god I can\u2019t stop laughing. Gotta show this to my coworkers on Monday.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]geneorama 11 points12 points13 points 1 month ago\u00a0(2 children)I have something just like this for R!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]NotAlphaGo 60 points61 points62 points 1 month ago\u00a0(1 child)alias R=\"python\"?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]RememberToBackupData 10 points11 points12 points 1 month ago\u00a0(0 children)That's funny but it's also heresy D:\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Linooney 5 points6 points7 points 1 month ago\u00a0(0 children)Touche, gonna save this for April Fool's next year...\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(8 replies)[\u2013]stevevaius 27 points28 points29 points 1 month ago\u00a0(0 children)I was suspicious on his coding skills because all his codes come from other github found by github search on same topic. I will unsubscribe  his channel now to support original coders\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)[\u2013]TheRiceDude 39 points40 points41 points 1 month ago\u00a0(0 children)If you ever watch his \"Interview series\" especially the one with 3blue1brown, you can definitely tell that this dude is just all hype. Grant Sanderson (3blue1brown) gives incredible answers and questions some of the stuff that Siraj asks of him and from the way Siraj handles it gives off the vibe that this guy is just all about the \"mysticism\" of machine learning and all of that. \n\u200b\nDefinitely take things with a grain of salt with this guy.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]jbcraigs 81 points82 points83 points 1 month ago\u00a0(20 children)There are quite a few other \u2018AI Influencers\u2019  on LinkedIN now a days who talk a lot about their ground breaking ML research but ultimately seem to be peddling their ML trainings and seminars! Look up Tarry Singh and Deepkapha.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]winchester6788 55 points56 points57 points 1 month ago*\u00a0(17 children)\nTarry Singh\n\nThis guy is a fucking fraud. His entire MO is selling complete newbies \"AI classes\".\n\npermalinkembedsaveparentreportgive awardreply[\u2013]mlbatman 21 points22 points23 points 1 month ago\u00a0(5 children)His posts are fucking annoying . And he keeps posting like a million times a day. I dont follow him but some of my LinkedIn do and some or the other person keeps liking his posts and it's so annoying to see him appear again.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]winchester6788 20 points21 points22 points 1 month ago\u00a0(1 child)Yeah, all these people \"networking\" on linkedin to sell shitty ml courses to newbies are assholes. What i don't get is, why accomplished ml\/dl people not callout these assholes.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Mefaso 18 points19 points20 points 1 month ago\u00a0(0 children)\nwhy accomplished ml\/dl people not callout these assholes.\n\nNot much to gain by doing so and you risk looking like the big guy shitting on small people, who are only trying to bring ML to a wider audience.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]brownnkinky 10 points11 points12 points 1 month ago\u00a0(0 children)I wish I could like this msg chain 5 times more. So true.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]atulsachdeva 3 points4 points5 points 1 month ago\u00a0(0 children)Dude, i have the same problem... His posts keep popping up in my feed even though i don't follow him...\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)[\u2013]stochastic_zeitgeist[\ud83c\udf70] 9 points10 points11 points 1 month ago\u00a0(3 children)He is a fraud of the highest order. \nIf you really, I repeat really wanna have some fun sunday morning cereal read:  https:\/\/deepkapha.ai\/ai-research\/\nThe dude has 2 upcoming papers and 2 papers (where he or any deepkapha.ai person is not the author) listed on his website. LMAO.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]jbcraigs 4 points5 points6 points 1 month ago\u00a0(1 child)I also noticed that he has over 35 K twitter followers but hardly gets 4-5 likes on his tweets. If I remember correctly he also had PhD at Columbia  listed somewhere on his LinkedIn profile with following in the parenthesis .. ( To be completed eventually at Columbia or some other school)!\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)load more comments\u00a0(1 reply)[\u2013]venkarafa 6 points7 points8 points 1 month ago\u00a0(4 children)He once tried to run his mouth on a very basic probability distribution (Gaussian) on Linkedin. Real statisticians took him to the cleaners there.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(4 replies)load more comments\u00a0(2 replies)[\u2013]y_must_be_l 10 points11 points12 points 1 month ago\u00a0(0 children)I wish to time travel in future where the word Influencer is treated with disgust. Most of the influencers today just mislead lot of curious people in wrong directions\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)[\u2013]nord2rocks[S] 94 points95 points96 points 1 month ago\u00a0(22 children)Inflated with hype -- most definitely. I'm concerned because I read somewhere that Netflix might be partnering with him for a show? I think it's called \"AI for Humans\" and it'll be a docuseries.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Lost_City_ 86 points87 points88 points 1 month ago\u00a0(10 children)I have to give him some credit, he built a hell of a brand for himself.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]nord2rocks[S] 113 points114 points115 points 1 month ago\u00a0(8 children)True true, and in only ... 5 minutes\n\npermalinkembedsaveparentreportgive awardreply[\u2013]evanthebouncy 67 points68 points69 points 1 month ago\u00a0(7 children)That's 3 minutes longer than 2 minutes papers LMAO\n\npermalinkembedsaveparentreportgive awardreply[\u2013]saaadyi 35 points36 points37 points 1 month ago\u00a0(3 children)But those papers are never 2 minutes either.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]aunickuser 42 points43 points44 points 1 month ago\u00a0(2 children)But what they are doing is awesome\n\npermalinkembedsaveparentreportgive awardreply[\u2013]piyush-kgp 42 points43 points44 points 1 month ago\u00a0(1 child)I treat 2 minute papers as a news feed for what people are working on\/what new thing came out (If I'm interested I'd read the actual paper). I don't think it's intended to teach anyone anything (they don't claim it too).\n\npermalinkembedsaveparentreportgive awardreply[\u2013]kdtrey35god 9 points10 points11 points 1 month ago\u00a0(0 children)yea its useful for gaining inspiration\/seeing the cool things ppl are doing\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(3 replies)load more comments\u00a0(1 reply)[\u2013]MarcoNasc505 16 points17 points18 points 1 month ago\u00a0(3 children)actually he just did  a trailer and posted on his channel, but it was like a proposal for a series, he prompted his subscribers to ask Netflix for it on Twitter or whatever, but I don't  know if it worked\n\npermalinkembedsaveparentreportgive awardreply[\u2013]jmmcd 18 points19 points20 points 1 month ago\u00a0(2 children)In the conversation with Lex Fridman he talked about how a Netflix show was a central goal of his life. Really weird. I think of him as a bit like an ML groupie crossed with a brand name.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(2 replies)[\u2013]CockGoblinReturns 15 points16 points17 points 1 month ago\u00a0(1 child)if that happens we'll all need to contact Netflix to let them know he's a scammer\n\npermalinkembedsaveparentreportgive awardreply[\u2013]nord2rocks[S] 20 points21 points22 points 1 month ago\u00a0(0 children)It'd be great if some Netflix ML folks see this and can pass it on...\n\npermalinkembedsaveparentreportgive awardreply[\u2013]jbuddy_13 4 points5 points6 points 1 month ago\u00a0(0 children)All we can do is continue to shed light on his practices via Reddit and other social media and Netflix will clue in. They\u2019re a research based company who take AI seriously given how it revolutionized their recommender system.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(4 replies)[\u2013]shinfoni 97 points98 points99 points 1 month ago\u00a0(12 children)Siraj's youtube videos is the final straw that made me realize that I shouldn't blindly jumping into this ML hypetrain.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]kadblack 111 points112 points113 points 1 month ago\u00a0(9 children)His videos are absolute garbage. Just clickbait titles and his explanation is so vague even i got confused even though i know the topic. Also he believes in a unified consciousness because of a dmt trip he had. He's borderline delusional and should not be fit to teach others.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]shinfoni 78 points79 points80 points 1 month ago\u00a0(7 children)Maybe I'm biased as well, but I'm still salty that one time I was so new to ML world, and I need some help to learn ML asap for college assignment. I waste like an hour watching him fidgeting and spouting nonsense.\nThanks God YT suggests me to watch 3Blue1Brown instead.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]kadblack 65 points66 points67 points 1 month ago\u00a0(1 child)When a maths major can explain neural networks 100 times better than someone who specializes in machine learning then you know there is something wrong.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Fewond 82 points83 points84 points 1 month ago\u00a0(0 children)Well to be fair 3B1B is not just any math major, he has mastered the skill of making difficult material accessible without dumbing things down too much.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(5 replies)[\u2013]Jaggednad 12 points13 points14 points 1 month ago\u00a0(0 children)Yea this is exactly right. He has these very bold claims in the video titles. I tried following through one once and it turned out super vague and useless, even though I work in ML. Can't imagine it'd be any help at all to someone new to the field.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)[\u2013]rohansway 133 points134 points135 points 1 month ago\u00a0(7 children)I've been sending Siraj money for a year and a half and buying all his programs.  Last week I completed a very amazing logistic analysis of a complex Boston housing dataset.  My skills are huge compared to where I was before.  But I can't understand why I'm not break into the field.  I know I only have an associates degree in psychology.  But I've spent so much time learning from Siraj and watching his videos.\nI'm still having to collect plastic bottles for money for recycling and work as a part-time drug mule for MS13, while I practice my code.  Maybe if I send him more money or get my hair dyed, I will become a great machine learning expert and then one day my girlfriend will take me back.  She's still pissed that I pawned all her jewelry to pay for a Deep Learning MOOC.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]MemeTeam6Operative 43 points44 points45 points 1 month ago\u00a0(0 children)I thought this was serious until I got to the second paragraph... I'm laughing so hard\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Lost_City_ 43 points44 points45 points 1 month ago\u00a0(4 children)Yeah you need to get the front middle of your hair dyed white to channel the machine learning\n\npermalinkembedsaveparentreportgive awardreply[\u2013]rohansway 26 points27 points28 points 1 month ago*\u00a0(2 children)Is that what this thing they called a loss function is?  loss of color of hair?  That term 'loss function' is like everywhere, but I'm not quite sure what they mean...\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sujithvemi 15 points16 points17 points 1 month ago\u00a0(0 children)Actually \"loss function\" refers to you losing your girlfriend's jewelry. Dyeing your hair is highlighting the gradients for visualisation.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)load more comments\u00a0(1 reply)load more comments\u00a0(1 reply)[\u2013]sigmoidx 21 points22 points23 points 1 month ago\u00a0(12 children)Didn't udacity partner with him too?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Lost_City_ 48 points49 points50 points 1 month ago\u00a0(11 children)I think they did temporarily. I dislike Udacity as well. I did their Self Driving Car nanodegree and I would routinely get project reviews that amounted to \"This is good\" and no other feedback. The whole reason I'm paying for that course is for good feedback. If you think about it though the people giving the feedback are students who also finished the program but can't get jobs elsewhere so it makes sense. Udacity continues to drive up the price of their courses while content suffers.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Rocketshipz 20 points21 points22 points 1 month ago\u00a0(6 children)Wait so this is what you get for paying over 1k USD for a class ? Damn ...\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Lost_City_ 43 points44 points45 points 1 month ago\u00a0(5 children)You ultimately are paying for a course syllabus and assignments you can find on github. The videos are pretty terrible, usually just 2-3 minutes long each and then walls of text to read. I learned way more from the deeplearning.ai course.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sahilwasan 16 points17 points18 points 1 month ago\u00a0(3 children)\nI think they did temporarily. I dislike Udacity as well. I did their Self Driving Car nanodegree and I would routinely get project reviews that amounted to \"This is good\" and no other feedback. The whole reason I'm paying for that course is for good feedback. If you think about it though the people giving the feedback are students who also finished the program but can't get jobs elsewhere so it makes sense. Udacity continues to drive up the price of their courses while content suffers.\n\ndeeplearning.ai is far better for beginners. I finished and liked it very much. Udacity is also exploiting students with ML and AI hype. Their nano degrees are so expensive and students who are taking thinks they will get the jobs after them.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Lost_City_ 5 points6 points7 points 1 month ago\u00a0(1 child)They used to do the whole \"Get you a job or your money back\" thing, but AFAIK they were just rehiring graduates to be mentors\/graders.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)load more comments\u00a0(1 reply)[\u2013]sigmoidx 6 points7 points8 points 1 month ago\u00a0(0 children)Same experience.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]bushrod 16 points17 points18 points 1 month ago\u00a0(3 children)Udacity is fucking trash.  They charge around $2000 for a meaningless \"nanodegree\" and you don't even get to keep access to the digital content unless you officially complete the coursework in some timeframe. Apparently $2000 isn't enough for a guaranteed maybe 10 cents worth of server bandwidth.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(3 replies)[\u2013]UltraMarathonMan 85 points86 points87 points 1 month ago\u00a0(18 children)Lex here. I understand your irritation. I think about snake oil salesmen a lot, especially since conversations I've had have recently gotten a bit of attention. My hope with these is to arrive at kernels of truth, insight, or just an inspiring idea. Having controversial people on can hurt that or it can help it, it's in part up to the interviewer. So if you listen to a conversation I've had and feel that it didn't give you something new and interesting, then I failed. But I hope to have the guts to talk to people who are deeply controversial, and through long-form conversation reveal something insightful.\nLet me put a hypothetical name down to clarify my point: Vladimir Putin. Many would shy away from that conversation. I will not.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Rocketshipz 67 points68 points69 points 1 month ago*\u00a0(14 children)Hey Lex, I think you should not miss the crucial difference between people controversial for their ideas, like Thiel, Eric Weinstein. Actually, even Musk, LeCun, Goodfellow, Hotz, Chollet, Oriol, Schmidhuber are sometimes controversial. But they are not snake oil salesmen.\nThe problem is that your platform is huge and gives a lot of credibility to people. Siraj does not deserve as much as he already had before being on your podcast, and he creates a lot of false hype on a really basic level about AI, which is not good. I understand you also benefit from that hype, but you also are a really credible scholar. Associating with those people not only hurt the field through your platform, but also hurts your image to experienced practitioners.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]c_o_r_b_a 8 points9 points10 points 1 month ago\u00a0(1 child)He kind of covered that already in his post, though. Putin could perhaps be considered a particularly successful snake oil salesman, but in any case I think he clearly has less credibility and more to dislike than Siraj does.\nLex interviewed him well before any of this came out, and whatever people are saying about his vibe or content or something, I don't think Lex would have had any reason to consider him questionable at that time. I've never been a fan of his content, personally, but I wouldn't have predicted this before now. And although it's looking like it may be pretty indefensible, so far, he should also have a chance to publicly respond before he's dubbed a conman and \"canceled\".\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)[\u2013]UltraMarathonMan 24 points25 points26 points 1 month ago\u00a0(10 children)I hear you, and agree, but I have to take risks and seek kernels of truths. Perhaps a better example I can mention is Ben Goertzel (SingularityNET) and David Hanson (creator of Sophia), both people I am thinking of talking with. Should I not do it because they have some elements of snake oil salesmanship? Or should I do it and work hard at finding the genuine, profound insights that each can reveal.\nOr another example is Donald Trump. Should I not talk to the President of the US about the AI Initiative?\nAnyway, I will keep taking risks, learning, and hopefully getting better.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]leostrauss 21 points22 points23 points 1 month ago\u00a0(3 children)\nanother example is Donald Trump\n\nI'm not sure what kind of insight you'd hope to glean from that conversation. I mean, yes he has the job of a US president but do you honestly hope to glean one iota of wisdom from a narcissistic man-child who struggles to formulate a coherent thought on much simpler issues?\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(3 replies)load more comments\u00a0(6 replies)load more comments\u00a0(1 reply)[\u2013]CockGoblinReturns 16 points17 points18 points 1 month ago\u00a0(0 children)Vladimir Putin is not an apt analogy. Everyone will know the degree if his corruption with or without your interview. Your interview would not give Vladimir Putin any credibility. \nYour interview with Siraj otoh, does give him credibility. Maybe you can argue it shouldn't. But there's going to be a lot of people who will buy his courses who shouldn't have, because of your interview.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]PlusImagination 7 points8 points9 points 1 month ago\u00a0(0 children)I don't blame you for your interview with Siraj, it's clear you thought of him as an entertainer, educator, and media personality, and it was hard to know about Siraj's scammer practices unless you did some digging. \nHowever, you should be aware by now that he's misleading people about the level of expertise he has about machine learning, that his courses are riddled with inaccuracies, and that he has been scamming people. \nAs a public figure in machine learning, you would probably have to verify these claims before making any sorta of statement on them, but for the sake of your reputation, at the very least make a statement that confirms your notion that you only see Siraj as a media personality, and not an expert, and haven't verified if he has the level of expertise to author a machine learning course.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)[\u2013]metacurse 135 points136 points137 points 1 month ago\u00a0(57 children)Lex is a sketchy dude himself, branding MIT all over his personal undertakings. His course etc., are also of poor quality content-wise but clickbaited to the maximum extent. I don't understand why people wouldn't simply take Hinton's or Levine's course online which are free and also better and have orders of magnitude more legitimacy.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]bushrod 28 points29 points30 points 1 month ago\u00a0(1 child)I understand your point regarding his course content and stuff but I think \"sketchy\" is harsh.  Lex wouldn't be a research scientist at MIT if he wasn't doing legit research, and his interviews are a true asset to the field.  On top of that, he seems like a very decent guy - not what I'd call sketchy in any substantive way.  This sub can be overly harsh.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)[\u2013]nrmncer 53 points54 points55 points 1 month ago*\u00a0(18 children)https:\/\/www.deeplearningbook.org\/\nthere's also Bengio's, Goodfellow's and Courville's book which is extremely thorough and the web version is available for free. If one manages to work through the entire book you'll have a solid overview over the state of ML. \nThat people constantly keep pushing these low quality youtube bait courses is just frustrating.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(18 replies)[\u2013]UltraMarathonMan 102 points103 points104 points 1 month ago\u00a0(8 children)Lex here. I agree. I will do better.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sachio222 14 points15 points16 points 1 month ago\u00a0(0 children)Man if you\u2019re really Lex, you don\u2019t deserve the shade. You\u2019re an awesome guy.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]dakry 24 points25 points26 points 1 month ago\u00a0(0 children)Hey Lex, your podcast has quickly become a huge favorite of mine. You are clearly improving all the time and I appreciate your contributions.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]TwerpOco 32 points33 points34 points 1 month ago\u00a0(0 children)I found out about you a little while ago and have been watching your interviews. I was kind of on the fence about them, but just seeing how well you take feedback here definitely pushes me towards liking you and your work more. You have some fantastic guests, but sometimes I feel like the content is too surface level. Hope to see more great content soon!\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(5 replies)[\u2013]Fewond 10 points11 points12 points 1 month ago\u00a0(0 children)\nI don't understand why people wouldn't simply take Hinton's or Levine's course online which are free and also better and have orders of magnitude more legitimacy.\n\nFor the same reason people still buy Ultimate Speed Fat Burner No Sweat RequiredTM or fall into MLM, getting the results without putting in the work. Also this kind of courses are extremely well marketed and with good salesmanship you can sell anything to anyone.\n\npermalinkembedsaveparentreportgive awardreply[\u2013][deleted] 1 month ago\u00a0(3 children)[deleted]\n\nload more comments\u00a0(3 replies)[\u2013]muntoo 8 points9 points10 points 1 month ago\u00a0(0 children)His course was literally taught at MIT. Do you want him to label it as \"metacurse's college for people who dislike MIT-branded content: Self-Driving Cars (6.S094)\"?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]matcheek 4 points5 points6 points 1 month ago\u00a0(0 children)\nI don't understand why people wouldn't simply take Hinton's or Levine's course online which are free and also better and have orders of magnitude more legitimacy.\n\nBecause they have not heard about the other two?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sachio222 6 points7 points8 points 1 month ago\u00a0(0 children)Amongst all the bashing, I\u2019ve got to defend Lex here. Ok maybe he\u2019s a bit eccentric. But his interviews are nearly always interesting, challenging to the interviewee and real. I love hearing them. Also his videos on the state of ai are great primers. \nFor what it\u2019s worth, whatever personality quirks he may have (we all have them) I\u2019m not going to bash on him for his content. \nI haven\u2019t seen or heard any advertisements for his own courses and I\u2019ve been following him for a while. I really like Lex. He\u2019s doing a great thing. Something inside said I need to defend this dude in this hate pile of a thread.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]ProfessorPhi 4 points5 points6 points 1 month ago\u00a0(0 children)He's had a few good things on his YouTube channel tbh. But yeah, Hinton's course is still my gold standard on deep learning.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(17 replies)[\u2013]meaninglessLives 8 points9 points10 points 1 month ago\u00a0(1 child)Your criticism of siraj is valid.  I completely agree with it.\nI was wondering why exactly did you think about snake oil salesman...\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Lost_City_ 13 points14 points15 points 1 month ago\u00a0(0 children)In modern usage it is used to describe someone who uses deceptive sales techniques.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]terriblestraitjacket 12 points13 points14 points 1 month ago\u00a0(0 children)The tragic part is I doubt he thinks of himself as a scam. He seems to genuinely think barebones, superficial knowledge is complete knowledge! He works really hard in the wrong direction (worst offender - learn physics in 2 months video). I always felt he doesn't use evangelical rhetoric to convince us. His rhetoric is to convince himself that he's special, does real work, and is a good person. \ni just want to hug him and tell him: \"No. You're not.\"\nHe's an amateur who is now flying too close to the sun. I hope his victims find legal recourse!!\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(16 replies)[\u2013]MoreDonuts 212 points213 points214 points 1 month ago\u00a0(5 children)How to make money with machine learning:\n\nMake a course titled \"Make Money with Machine Learning\"\nCharge money for the course\n???\nProfit\n\nKind of a pyramid scheme to be honest\n\npermalinkembedsavereportgive awardreply[\u2013]davesidious 99 points100 points101 points 1 month ago\u00a0(0 children)To be fair it's not specified who will make the money...\n\npermalinkembedsaveparentreportgive awardreply[\u2013]lstama 28 points29 points30 points 1 month ago\u00a0(0 children)It's just straight up scam\/fraud imo, pyramid scheme is at least profitable for the early bird.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]DSPGerm 8 points9 points10 points 1 month ago\u00a0(1 child)There\u2019s literally \u201cmake money online\u201d courses about how you can make a course about selling courses to other people. \nLife coaches are the worst\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)[\u2013]Mr-Yellow 5 points6 points7 points 1 month ago\u00a0(0 children)^ Every-single-bootcamp-operator-in-any-tech-field\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Laser_Plasma 252 points253 points254 points 1 month ago\u00a0(25 children)Is anyone surprised, really? He never had any quality content other than hype\n\npermalinkembedsavereportgive awardreply[\u2013][deleted] 1 month ago*\u00a0(2 children)[deleted]\n\n[\u2013]iheartrms 12 points13 points14 points 1 month ago\u00a0(0 children)Hello world, it's c-c-c-cain!\n\npermalinkembedsavereportgive awardreplyload more comments\u00a0(1 reply)[\u2013]Capn_Sparrow0404 134 points135 points136 points 1 month ago\u00a0(18 children)Exactly. Even as a beginner, I was able to differentiate his BS from other quality YouTube videos.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]ai_ja_nai 4 points5 points6 points 1 month ago\u00a0(0 children)When he started rapping over the seq2seq lesson I felt seriously embarrassed for him\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(17 replies)[\u2013]PlentifulCoast 47 points48 points49 points 1 month ago\u00a0(0 children)Yeah, honestly couldn't make it through his videos. There are way better channels like Arxiv Insights, etc.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(2 replies)[\u2013]Laser_Plasma 215 points216 points217 points 1 month ago\u00a0(9 children)On the upside - if this goes big, it might be the end of Siraj? One could wish\n\npermalinkembedsavereportgive awardreply[\u2013]NicolasGuacamole 40 points41 points42 points 1 month ago\u00a0(0 children)I really hope so\n\npermalinkembedsaveparentreportgive awardreply[\u2013]stochastic_zeitgeist[\ud83c\udf70] 19 points20 points21 points 1 month ago\u00a0(5 children)It will only end when respectable people in AI  start calling out BS, like any other field. Unfortunately, they choose to be neutral.\n\nThe hottest places in Hell are reserved for those who, in a period of moral crisis, maintain their neutrality. -- Dante Alighieri\n\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(5 replies)load more comments\u00a0(2 replies)[\u2013]Insert_Gnome_Here 55 points56 points57 points 1 month ago\u00a0(9 children)What jurisdiction is he in?\nI see a lawsuit brewing.\n\npermalinkembedsavereportgive awardreply[\u2013]rayryeng 37 points38 points39 points 1 month ago*\u00a0(6 children)His School of AI, the entity that billed me when I purchased the course, is a registered business in California.\nC4197240    THE SCHOOL OF AI\nRegistration Date:09\/21\/2018\nJurisdiction:CALIFORNIA\nEntity Type:DOMESTIC NONPROFIT\nStatus:ACTIVE\nDid a search here: https:\/\/businesssearch.sos.ca.gov\/CBS\/Detail\nEdit: To address concerns raised about whether nonprofit organizations can sell products, yes they can. They can do so in order to raise money but the funds need to be used for whatever objective they set out or cause they're supporting. He has the legal right to sell this course but what he's actually using the funds for is unknown. My best guess is to fund that sham of a Netflix docu series he's trying to get off the ground.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]lstama 11 points12 points13 points 1 month ago\u00a0(5 children)Domestic nonprofit?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]SupportVectorMachine 16 points17 points18 points 1 month ago\u00a0(0 children)That looks like it might be some light fraud.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]rayryeng 7 points8 points9 points 1 month ago\u00a0(3 children)It's still a registered business even if it's nonprofit.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]lstama 6 points7 points8 points 1 month ago\u00a0(2 children)Is it really a nonprofit if he sells his course? I don't really know about US law, and my first reply is actually asking about the contradiction. Sorry if it's not clear.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]rayryeng 11 points12 points13 points 1 month ago*\u00a0(0 children)Haha I get it! That's what caught me off guard too. I was billed by the School of AI on my credit card statement.\nBut to answer your question, yes nonprofits can sell products in order to raise money but the funds need to be used for whatever objective they set out or cause they're supporting. He has the legal right to sell this course but what he's actually using the funds for is unknown. My best guess is to fund that sham of a Netflix docu series he's trying to get off the ground.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(2 replies)[\u2013]temporaryred 50 points51 points52 points 1 month ago\u00a0(8 children)Of course he is. I've seen a lot of content that is put out that may be accidentally low quality, but his youtube channel is definitely putting out low quality content on purpose. And not just that, he'll then post those videos on reddit.\nhttps:\/\/old.reddit.com\/r\/Python\/comments\/5ewu29\/why_is_p_vs_np_important\/dah3kg8\/\nI've written a couple of critiques of these videos when I first saw them. Ugh it angers me just thinking about him and those videos.\nI can see how someone might make sure videos early on in their career but over time evolve to show better quality material. But no, Siraj defiantly chooses to produce the lowest tier material and that alone. I hope everything he does burns like the flammable garbage that it is.\n\npermalinkembedsavereportgive awardreply[\u2013]Aeon_Mortuum 15 points16 points17 points 1 month ago\u00a0(7 children)Lol his Reddit account is suspended\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(7 replies)[\u2013]serotonin2A 176 points177 points178 points 1 month ago\u00a0(18 children)Always better to pay some addied-out vine star grifter $200 to learn sk-learn and Tensorflow instead of  downloading some O'Reilly PDF's on libgen\n\npermalinkembedsavereportgive awardreply[\u2013]7FigQuant 114 points115 points116 points 1 month ago\u00a0(6 children)Why the fuck would I read a few books and practice over the course of a few years learning where I am weak and improve those areas when somebody is telling me all I have to do is pay him $200 and I'll know machine learning better than Google and Facebook COMBINED in like 5 minutes? Put 2 and 2 together here. Idiot.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(6 replies)[\u2013]shinfoni 21 points22 points23 points 1 month ago\u00a0(9 children)While I love pirating O'Reilly PDF on libgen (I promise I'll buy them when I got my first paycheck), the tricky part is Siraj has one O'Reilly book as well. Now I have small trust issue with O'Reilly\n\npermalinkembedsaveparentreportgive awardreply[\u2013]serotonin2A 10 points11 points12 points 1 month ago\u00a0(0 children)I've had trust issues with O'Reilly ever since he started harassing his interns. No wonder he's publishing a guy like Siraj\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(8 replies)load more comments\u00a0(1 reply)[\u2013]physicswizard 43 points44 points45 points 1 month ago\u00a0(1 child)The only one \"Making Money with Machine Learning\" here is Siraj. He seems like a smart, capable guy, but his content is designed purely to cash in on the ML hype and fool interested laymen into thinking they can get a cushy six figure job or passive income stream by just watching his videos and doing an afternoon's worth of coding.\n\npermalinkembedsavereportgive awardreplyload more comments\u00a0(1 reply)[\u2013]RelevantMarketing 38 points39 points40 points 1 month ago*\u00a0(3 children)I took one of Siraj's paid courses when I was first starting out. He has a huge youtube channel so I figured he must be legit. As I moved up I realized he got a lot of the material wrong. I welcome the guy for making free content on youtube, but he is absolutely unqualified to be teaching any paid course, especially since there are so many legit courses out there, many of which are free.\nEdit:\nI just tried looking up the course I took. It's gone. All the paid courses he used to sell are gone. I'm guessing it's because of reasons like this, they're shitty, and boardline scams if not outright scams.\n\npermalinkembedsavereportgive awardreplyload more comments\u00a0(3 replies)[\u2013]Fin_Win 37 points38 points39 points 1 month ago\u00a0(0 children)People are still in favour of this guy, especially the newcomers. I'm into Statistical Modeling as my profession, I was curious on a time series model, which I got it in my recommendation couple of months ago, due to the number of views it got. It is the basic concept in Statistics, this dude just executed a copied python code and did some scoring that's it. I watched few more videos of his. Literally zero on concepts, just few codes and many eye catching memes. Classic con man move.\n\npermalinkembedsavereportgive awardreply[\u2013]1337InfoSec 29 points30 points31 points 1 month ago\u00a0(4 children)OP, you should make a post in r\/LegalAdvice\n\npermalinkembedsavereportgive awardreply[\u2013]nord2rocks[S] 14 points15 points16 points 1 month ago\u00a0(3 children)Should I just cross post it or what should the post be? I didn't participate in this scheme of his, rather just stumbled across the posts by people.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]bunny113 14 points15 points16 points 1 month ago\u00a0(2 children)Make a new post with layman's terms. Then put that posts link on your edits.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]nord2rocks[S] 3 points4 points5 points 1 month ago\u00a0(1 child)Thank you both for the idea, I've done so here\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)[\u2013]not_novel_enough 28 points29 points30 points 1 month ago\u00a0(6 children)Jeez....this is terrible on so many levels. This needs to go higher and get traction for his response and for others to know.\n\npermalinkembedsavereportgive awardreply[\u2013]nord2rocks[S] 10 points11 points12 points 1 month ago\u00a0(5 children)Sharing with tech news companies could help maybe?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]not_novel_enough 16 points17 points18 points 1 month ago\u00a0(3 children)Yes, medium, etc. Also, he has a huge fan following on twitter, so post it there as well and tag him, maybe he will respond....\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sudharsansai 7 points8 points9 points 1 month ago\u00a0(1 child)I second sharing it on Twitter. I was surprised to see some top researchers following him there!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]not_novel_enough 3 points4 points5 points 1 month ago\u00a0(0 children)I know, I think people need to be made aware of what is going on.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]nord2rocks[S] 5 points6 points7 points 1 month ago\u00a0(0 children)Heck sharing this on LinkedIn might be a good idea as well.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)[\u2013]snendroid-ai 72 points73 points74 points 1 month ago\u00a0(1 child)Well well well, who would have thunk? One of my non-ml friend asked me about this dude when he was thinking about exploring this field. When I saw his YT channel, my immediate reaction was, WHAT IN THE FUCKING FRESH HELL IS ALL THESE!? He is an absolute phony! I mean, anyone with proper educational background in this field or few years of experience can call out this dude for everything that he has posted on his YT channel. What an absolute disgrace to ML community. I mean look at all the titles of his videos; search \"stock market siraj rawal\" and look at all those cringey titles. And on top of all that, something like this course to scam people by selling the snake oil. \nWe need more people to vocal about people like this. They affect the image of this field and perspective of non-ml people who don't know much about this. Lex Fridman did a big mistake by providing this dude a stage among people like LeCun, Francois and Rajat. He should take back that episode once this story proved to be true. And that Netflix series, WTF NETFLIX?\n\npermalinkembedsavereportgive awardreplyload more comments\u00a0(1 reply)[\u2013]--iRON-- 21 points22 points23 points 1 month ago\u00a0(0 children)Watched one of his videos about object detection, as soon as he said YoloV3 was \"most accurate\" detection model (not fast or efficient), I knew he was just a clueless fraud, scamming others of their time and money.\n\npermalinkembedsavereportgive awardreply[\u2013]the_shape89[\ud83c\udf70] 18 points19 points20 points 1 month ago*\u00a0(0 children)He's an obvious snake oil salesman. If making money with machine learning was as easy as he makes it out to be (scanning GitHub for code, copy pasting stuff...DONE!), then he wouldn't need to be making YouTube videos for money.\nAlso, he authored this pile of absolute garbage.\nAnother \"also\", there's no cheap and quick online course that will teach you how to make meaningful amounts of money in ways that are legal, long term feasible and\/or not already available somewhere for free. If you have a good system of making money, you capitalize on it by hiring people to go out and do this stuff and\/or investing in them. You don't go around charging a measly $200 for a handful of people to sign up. Which is the exact same deal as all the other \"TAKE MY PAID COURSE AND I'LL TEACH YOU HOW TO MAKE MILLIONZZZZ\" type guys.\n\npermalinkembedsavereportgive awardreply[\u2013]s4hc 16 points17 points18 points 1 month ago\u00a0(3 children)Not surprised to be honest. The little content I came across on YouTube was always so cringeworthy. \nI was a little disappointed when Daniel Bourke mentioned him in a few of his YouTube videos and when Andrew Trask was on one of his podcasts. No idea why they did this.\n\npermalinkembedsavereportgive awardreply[\u2013]KamWithK 5 points6 points7 points 1 month ago\u00a0(2 children)Those are actually quite simple to answer:\nDaniel Bourke - Loves him as he inspired him to learn about AI, Siraj is literally why he's here (I believe he even took his course)\nAndrew Trask - Both talk about decentralised neural networks, AI safety, believe uni isn't a requirement now, also spreads attention to him (that's how I heard about Trask)\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(2 replies)[\u2013]mcjon77 16 points17 points18 points 1 month ago\u00a0(1 child)The guy just showed everyone how to make money in ML.  Build a brand and sell courses on ML using the strength of your brand. \nThe dude built a $200 course and sold it QUICKLY to 1,200+ people.  So he brought in almost $250K.\nDamn, maybe I need to start building courses online.\n\npermalinkembedsavereportgive awardreplyload more comments\u00a0(1 reply)[\u2013]styx97 28 points29 points30 points 1 month ago\u00a0(3 children)Well, can say I saw something like this happening a mile away. I was really sad that Grant (3b1b) Sanderson did that podcast with him (that way he got tagged with someone original) because he's really a fake. If you really want to know ML, watch the lectures of Alex Ihler, Hinton, abu mostafa or Hugo Larochelle. There's like a hundred better educators on YT.\n\npermalinkembedsavereportgive awardreply[\u2013]type1advocate 16 points17 points18 points 1 month ago\u00a0(1 child)I think it's great that Grant was on there because it was an amazing juxtaposition. If one was on the fence about Siraj before that episode, any doubts were definitely confirmed.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]styx97 15 points16 points17 points 1 month ago\u00a0(0 children)What you say actually makes more sense. But far more people will just see the title and the thumbnail and associate them together.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)[\u2013]sjogerst 12 points13 points14 points 1 month ago\u00a0(0 children)Document and chargeback. Let him figure it out.\n\npermalinkembedsavereportgive awardreply[\u2013]mujtaba87 13 points14 points15 points 1 month ago*\u00a0(2 children)Beware of another spammer like him, I guess his name is Qazi and sells his courses with the name clever programmer. He once published a video \u201cWeb development in Three Minutes\u201d, like seriously!\n\npermalinkembedsavereportgive awardreplyload more comments\u00a0(2 replies)[\u2013]brownck 14 points15 points16 points 1 month ago\u00a0(0 children)Try out my new course instead:\n\u201cHow to make even MORE money with machine learning!\u201d\n\npermalinkembedsavereportgive awardreply[\u2013]UnfriendlySoloutions 13 points14 points15 points 1 month ago\u00a0(0 children)He is a good salesmen, EXACTLY the type of person who can talk investors into dumping cash into a silly startup idea\n\npermalinkembedsavereportgive awardreply[\u2013]psxpetey 11 points12 points13 points 1 month ago\u00a0(0 children)anything with how to make money in the title is a fucking scam bud. they'd be too busy making money if it worked not offering a book or a course on it\n\npermalinkembedsavereportgive awardreply[\u2013]stokhos_phusis 12 points13 points14 points 1 month ago\u00a0(0 children)You pay with a credit card? Do a chargeback.\n\npermalinkembedsavereportgive awardreply[\u2013]AsliReddington 21 points22 points23 points 1 month ago\u00a0(2 children)All he does is make commentary on HN links or papers in the news. No new stuff at all from him. Lame videos that are just cringe.\n\npermalinkembedsavereportgive awardreply[\u2013]trexgomez 18 points19 points20 points 1 month ago\u00a0(0 children)The cringiest part is where he puts a meme from 2015 every 5 seconds in his videos.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]lambda_pie 5 points6 points7 points 1 month ago\u00a0(0 children)\ncringe\n\nThis.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Safayet_Khan 22 points23 points24 points 1 month ago\u00a0(7 children)Let me clarify something. I am SAFAYET KHAN. I deleted my twitter account. Why? \nBecause I have never used Twitter before this drama that you are seeing (Screenshots)! And I don't want to get addicted to it. So why did I open my Twitter account for only 3 days? \nI opened it to attract Mr. Siraj Raval attention because he was not responding to my Emails for refund. After I was twitting about my experience, he agreed to refund my full money back money, which is $199,  I deleted my Twitter accounts for good.\nThis is all! If you have any questions about my tweets please comment here. And for your information, Mr. Siraj Raval didn't give me a single penny much to delete my account. Thank you.\n\npermalinkembedsavereportgive awardreplyload more comments\u00a0(7 replies)[\u2013]bit2bit2 10 points11 points12 points 1 month ago\u00a0(0 children)Thank god I didn't fall for it \ud83d\ude02\n\npermalinkembedsavereportgive awardreply[\u2013]staircase7 9 points10 points11 points 1 month ago\u00a0(0 children)The funny thing is, that in the machine learning community he has always some kind of a joke. If you search by controversial and by all time the second to top post is about one of his oldest videos.\n\npermalinkembedsavereportgive awardreply[\u2013]doodly19 10 points11 points12 points 1 month ago\u00a0(0 children)He is a major youtube fraud claiming to know \"all of AI\" and making superficial and very irritating videos about them which teach you nothing.\n\npermalinkembedsavereportgive awardreply[\u2013]shaman311 9 points10 points11 points 1 month ago\u00a0(0 children)Here is a document a student put together. If you guys are looking for the facts then here it is : https:\/\/case-for-a-refund.s3.us-east-2.amazonaws.com\/feedback.html\nSadly, we (the students) are dealing with a hypeman who has no intention of refund people their money.\n\npermalinkembedsavereportgive awardreply[\u2013]thedmandotjp 9 points10 points11 points 1 month ago\u00a0(1 child)I was really interested in this dude's courses when I first started out earlier this year and I almost signed up.  I ended up not doing it because I was getting weird vibes about how much content he had and how similar it seemed.  Jumped headfirst into Andrew Ng's Coursera course instead and now I'm so glad I did.  That was money and time I couldn't afford to waste because I'm learning on the side and supporting a family.  Fuck Siraj.\n\npermalinkembedsavereportgive awardreply[\u2013]rayryeng 3 points4 points5 points 1 month ago\u00a0(0 children)Hear hear.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]gwchase 8 points9 points10 points 1 month ago\u00a0(3 children)I'm late to this thread, but still wanted to give my two cents.\nSiraj also took my code, and used it in his \"AI In Medicine\" video. He didn't provide any credit, until I asked him to. On top of this, the repo wasn't even forked; it was copied\/ pasted into a new repository. There's a name for this: plagiarism, plain and simple.\nFor reference, you can compare my repo and his repo; like I said, blatantly copied.\n\npermalinkembedsavereportgive awardreplyload more comments\u00a0(3 replies)[\u2013]Mr-Yellow 7 points8 points9 points 1 month ago\u00a0(0 children)\n\"Make Money with Machine Learning\" with a registration fee \n\nObvious scam is obvious.\n\npermalinkembedsavereportgive awardreply[\u2013]mxschumacher 7 points8 points9 points 1 month ago\u00a0(0 children)Seems like he made money with machine learning\n\npermalinkembedsavereportgive awardreply[\u2013]lstama 21 points22 points23 points 1 month ago\u00a0(4 children)I knew this guy name since a while but only today I open his Youtube channel because of your post.\n... and then I found his \"Make Money with Tensorflow 2.0\" video.\n\npermalinkembedsavereportgive awardreply[\u2013]Fin_Win 3 points4 points5 points 1 month ago\u00a0(2 children)In a nutshell, he just came up with an idea of presenting a time series model for making investment decisions.\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(2 replies)load more comments\u00a0(1 reply)[\u2013]hilberteffect 13 points14 points15 points 1 month ago\u00a0(1 child)Always pay using a credit card. No exceptions. Then, when something like this happens, and you have documentation that a) you were ripped off and b) the person has refused to make things right or refund you, you simply submit a chargeback to your credit card company and provide them with the documentation.\nIt's then up to the merchant to provide POSITIVE proof that they did indeed provide the goods\/services as described. If they can't, not only do you get a full refund, but they get slapped with a fat 20% fee on top of the original amount.\n\npermalinkembedsavereportgive awardreplyload more comments\u00a0(1 reply)[\u2013]Dump7 5 points6 points7 points 1 month ago\u00a0(0 children)Now it makes sense.\nI was a active watcher of his content a while ago. I don't know why I then stopped. Maybe I subconsciously knew all of his content was BS.\n\npermalinkembedsavereportgive awardreply[\u2013]humblefool_ 6 points7 points8 points 1 month ago\u00a0(0 children)I am still in his course, I will update this post by letting you know guys that after completion of this course whether he gives a consultation work or not to his graduates as he promised in his course. I really have less to no hope that he will.\n\npermalinkembedsavereportgive awardreply[\u2013]platypusPerry245 6 points7 points8 points 1 month ago\u00a0(0 children)I spent hours and hours watching his BS . I learnt more from deeplizard channel than from siraj's bs. I watched one of his startup videos , I thought he would show some result at the end of 45-50 minutes long video ,turns out all the videos are just hypetrains\n\npermalinkembedsavereportgive awardreply[\u2013]boxxa 18 points19 points20 points 1 month ago\u00a0(8 children)I started watching him early. His videos are good and get you excited but every topic is click bait and doesn\u2019t provide any useful info. I unsubscribed after I found Sentdex who is incredible. He loves programming, his videos have real code, and gives you a ton of examples and content to take on your own and help you find things to dive deeper in. \nhttps:\/\/www.youtube.com\/user\/sentdex\n\npermalinkembedsavereportgive awardreply[\u2013]tensorwave 5 points6 points7 points 1 month ago\u00a0(7 children)I also recommend Arxiv Insights on YouTube\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(7 replies)[\u2013]Ol3k71 5 points6 points7 points 1 month ago\u00a0(0 children)When I Startes ML\/AI a few years ago, he had a patreon account, to accept donations. \nThere was also a deal about personal Q&A for donators, if you spend a specific amount per mounts. \nNone of the promised bonuses were available. \nAnd also, no refund or anything else.\n\npermalinkembedsavereportgive awardreply[\u2013]lunarlustra 5 points6 points7 points 1 month ago\u00a0(0 children)Damn. That is not a good look. Agree that 3Blue1Brown is a great resource. There are also a lot of tutorials online at @weights_biases for beginner, intermediate, and advanced practitioners.\n\npermalinkembedsavereportgive awardreply[\u2013][deleted] 5 points6 points7 points 1 month ago\u00a0(0 children)Well I'm not surprised. His content is basically useless and it made me cringe when people were comparing him to 3blue1brown on his podcast lmao\n\npermalinkembedsavereportreply[\u2013]sujithvemi 5 points6 points7 points 1 month ago\u00a0(0 children)Wow, just wow. I try to distance myself from this guy a lot, except for the list of resources he put up on GitHub for some subjects. This is the only useful thing he does because it is not his original creation, he collects stuff from others who collect stuff, so it is useful. I am so happy to see that actually there are so many people who call out this fraud. One video of his and that's it, you can say he is a fraud. But I have actually come across a few people who follow him a lot. I get it if amateurs are doing this but what I was not able to understand is that some eminent researchers in AI\/ML have actually given this guy a lot of exposure with their tweets and stuff. There are so many frauds now who are making money from gullible ML aspirants, riding the hype that surrounds the field. I mean this guy has written some paper on quantum computing with barely any content and he got a lot of praise for it. I can't believe that I actually started followed him on Twitter long back because I thought I was on the wrong side for calling this guy useless, because he has so much of a celebrity status while I consider myself an amateur-intermediate.\nThis post is gonna help me boost my confidence a lot, thanks for this. Anyway, I guess people are going to be fooled by one or the other until the current hype continues, feel bad for all those aspirants.\n\npermalinkembedsavereportgive awardreply[\u2013]margaret_spintz 6 points7 points8 points 1 month ago\u00a0(0 children)I guess the title of the course 'make money with ML' was only accurate from his perspective \ud83e\udd14\n\npermalinkembedsavereportgive awardreply[\u2013]mimighost 6 points7 points8 points 1 month ago\u00a0(0 children)Why would anyone signed up a course literally named 'Make Money with Machine Learning'? lol\n\npermalinkembedsavereportgive awardreply[\u2013]suzushiro 6 points7 points8 points 1 month ago\u00a0(0 children)One of his videos was a straight up ripoff of a medium article. I pointed it out in the comments but he never replied back. This guy is obviously all hype.\n\npermalinkembedsavereportgive awardreply[\u2013]NightmareOx 5 points6 points7 points 1 month ago\u00a0(0 children)I don\u2019t know how is on the other parts of the world, but here in Brazil his school is pretty shady. I\u2019m a CS masters degree student and my area of research is machine learning and a couple of months ago one of my lab colleagues broad to my attention this Facebook videos from his school that were sooooo wrong. The teacher clearly didn\u2019t know the topic he was teaching, and was sharing the original articles from neural networks, but as the class goes on, it is clear that he haven\u2019t read the articles too. I\u2019ve started digging up more classes and the school\u2019s materials and I was shocked about how wrong or just bad they were. They use this flag of being free as a justification, but they ask for donation all damn time and hat pisses me most is that when you stop to read the comments it is clear that most people there are trying to change their careers. This people are being scammed and he doesn\u2019t give a shit about it. Never liked the guy that much, when doing my research on the topic of GANs it became clear to me that he was fake and not that knowledgeable about all topics that he boasts about, but that is a new kind of low :\/\n\npermalinkembedsavereportgive awardreply[\u2013]PlusImagination 6 points7 points8 points 1 month ago\u00a0(0 children)The ML community needs to do something about Siraj asap. He's just going to wait until this blows over and then scam the next series of students. \nHe's using the work of the machine learning community as deceitful marking material for his courses, and is generating a bunch of copycats. There are other internet marketing people trying to sell shitty courses to newbie programmers who don't know any better. \nI don't believe the 'darwinism' argument. At the end of the day, their using our work to scam other people, particularly aspiring programmers. They're targeting a niche; these may not the same people who would fall for MLM knives or supplements. \nI also don't believe that this is just one fuckup for him. If you read the other discussion, this is a persistent pattern for him. Also think of this, he is a persoon heinous enough to scam his own fans, fans who are looking better their careers. And he did it in an inventive of making a seperate slack channel for refunds, then mass banning them all. This person does not deserve the chance to scam people again. Not only is this an extremely low regard for ethics, it is a clear demonstration of very low empathy. \nIf you look at his Linkedin, he's never held a job for more than a year, and mostly in software engineering. Somehow I doubt he's going to go back into software engineering. He's going to try again. \nPeople with authority in the ML community like \/u\/ UltraMarathonMan should come out with a statement, not just Siraj, but the proliferation of these internet marketers and their ML course scams. But these other scammers mostly take their cue from Siraj.\n\npermalinkembedsavereportgive awardreply[\u2013]sf_degen 10 points11 points12 points 1 month ago\u00a0(0 children)Dispute with your credit card. Always pay with CC so you can dispute things like this.\n\npermalinkembedsavereportgive awardreply[\u2013]mindaslab 8 points9 points10 points 1 month ago\u00a0(2 children)I suspected that guy was a fraud\n\npermalinkembedsavereportgive awardreplyload more comments\u00a0(2 replies)[\u2013]permalip 4 points5 points6 points 1 month ago\u00a0(0 children)To be honest, I feel bad for the people who fell for this trap course, but I also feel that they went into it blindly without doing the research. It's one thing that he says there is only 500 spots and the course is mediocre (or so people says) - but not refunding the unhappy people is scummy. Nevertheless, this still comes back to which terms of service these people agreed to.\nThe problem with Siraj is that he is the hype guy of AI, getting people hyped for it, believing they can learn it without much if any effort. When I started in AI, I thought Siraj was the shit, because I didn't know anything Machine Learning related. After a few months, it was easy to see through the videos.\n\npermalinkembedsavereportgive awardreply[\u2013]gachiemchiep 5 points6 points7 points 1 month ago\u00a0(0 children)200 usd to learn a lesson : don't just believe random guys with big mouth on internet \nsound like a good pricw\n\npermalinkembedsavereportgive awardreply[\u2013]haloworlds 8 points9 points10 points 1 month ago\u00a0(3 children)So asking about general people who purchase courses, do you y'all research the person's industry experience or academic experience? Or just a famous GitHub repo or YouTube channel is fine?\nThis guy, at least according to his LinkedIn profile worked at Twillio and meetup which is nice but as a software engineer not a machine learning or AI or even anything related to data science. Either way he maybe a very good software engineer but doesn't look like a AI or Machine learning expert.\n\npermalinkembedsavereportgive awardreply[\u2013]sj90 11 points12 points13 points 1 month ago\u00a0(1 child)He's not an expert. He basically sold the hype around machine learning in the past few years to develop a brand. And other people in the industry also utilized his brand for their own purposes. It sort of legitimized it over time.\nBut that's what hype in anything does. It creates a strong herd mentality scenario where people who get swept away by the hype buy into the brand.\nThis gets worse when the same hype seeps into the industry in such a way that people started getting jobs with relatively limited backgrounds early on. Making a whole lot of people think it really is that easy and lucrative a field to get into.\nA brand is enough to trigger that mentality anywhere for anyone. And couple the brand with the idea that something interesting is very easy and simple to learn and will make you enough money, then your logical defences drop further.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]haloworlds 4 points5 points6 points 1 month ago\u00a0(0 children)Alright. Got the point. \nFor me personally if I am seeking paid help\/course\/mentoring then either your industry or academic experience should speak for your work or a good work product in open source (tutorials and awesome lists and readme stuff doesn't count towards that no offense on people who does that).\nFor example if I am looking for mentoring in data science field and Wes McKinney is available sure get help from him\n\npermalinkembedsaveparentreportgive awardreplyload more comments\u00a0(1 reply)[\u2013]kekkimo 8 points9 points10 points 1 month ago\u00a0(0 children)In fact, the title of the course is NOT a SCAM.\nSince he is really making money with machine learning by selling this course about ML.\n\npermalinkembedsavereportgive awardreply[\u2013]Schoolunch 4 points5 points6 points 1 month ago\u00a0(0 children)wow, and yet again someone creates a school to scam people\n\npermalinkembedsavereportgive awardreply[\u2013]arfath99 2 points3 points4 points 1 month ago\u00a0(6 children)Why does anyone take a paid courses when u have free YouTube videos from edureka, simpli learn ,free code camp and many more on udemy,Coursera and so on\nI knew from the beginning itself this man has just some basic knowledge which he acquired online from free courses and he started selling just like many others on YouTube (instead of free he started charging) which made it such a fuss.\nThis man is real smart, he made people love the AI first and it's salaries. Then he boosted about his Stanford degree to newbie . Even without this paid courses he was making great income with 200k subscribers atleast\n\npermalinkembedsavereportgive awardreplyload more comments\u00a0(6 replies)[\u2013]iceevil 3 points4 points5 points 1 month ago\u00a0(0 children)How to make money with ML: Scam other people by offering fake courses on ML\n\npermalinkembedsavereportgive awardreply[\u2013]UnfriendlySoloutions 2 points3 points4 points 1 month ago\u00a0(0 children)btw he has an o'reilly book .... https:\/\/www.amazon.ca\/Decentralized-Applications-Harnessing-Blockchain-Technology\/dp\/1491924543\n\u200b\nreviews explain it all\n\npermalinkembedsavereportgive awardreplyload more comments\u00a0(124 replies)aboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 18307 on  r2-app-0890e987654e829c0  at 2019-11-18 00:37:10.100940+00:00 running 85b1b7a country code: US."
  },
  "15":{
    "title":"[P] Ever wondered how to use your trained sklearn\/xgboost\/lightgbm models in production? We developed a simple library which turns your models into native code (Python\/C\/Java) : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-funny-pics-aww-worldnews-gaming-todayilearned-television-gifs-Showerthoughts-Jokes-videos-tifu-mildlyinteresting-TwoXChromosomes-OldSchoolCool-space-creepy-nottheonion-books-movies-personalfinance-LifeProTips-IAmA-explainlikeimfive-dataisbeautiful-Futurology-science-gadgets-askscience-food-sports-nosleep-Music-Art-WritingPrompts-EarthPorn-history-DIY-photoshopbattles-Documentaries-UpliftingNews-GetMotivated-listentothis-philosophy-announcements-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  04 Mar 2019341 points (97% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave818,935 readers2,355 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X53  \u00b7 36 comments [D] An Interesting (in my opinion) Observation While Messing With the Full GPT-295  \u00b7 24 comments [D] Is the inception architecture\/block a failure?30  \u00b7 6 comments [D] Best resources to learn about Anomaly Detection on Big Datasets?33  \u00b7 1 comment [D] Machine Learning - WAYR (What Are You Reading) - Week 755  \u00b7 7 comments [D] Bahdanau attention model26  \u00b7 9 comments [R] Neural Network Processing Neural Networks[R] A New Deterministic Technique for Symbolic Regression1  \u00b7 5 comments [D] Many papers don\u2019t do hyperparameter search on DNN baselines248  \u00b7 28 comments [P] baikal: A graph-based functional API for building complex scikit-learn pipelines2  \u00b7 1 comment [P] Sentence similarity using siamese LSTMWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7340341342Project[P] Ever wondered how to use your trained sklearn\/xgboost\/lightgbm models in production? We developed a simple library which turns your models into native code (Python\/C\/Java) (self.MachineLearning)submitted 8 months ago by krinartImagine that you trained your super accurate model using your favorite tools (Python\/sklearn\/xgboost\/etc.) and now the time has come to deploy your model to production for the greater good.  \nBut consider the following scenarios:\n\n What if your production environment has no Python runtime?\n What if your model should make instantaneous predictions right on a microcontroller device without sending data to a remote server? \n What if prediction speed is a concern too?\n\nThis where m2cgen comes in handy. It's a library that generates Java\/Python\/C code from trained ML models.\nCheck it out: https:\/\/github.com\/BayesWitnesses\/m2cgen\/\n\n55 commentssharesavehidereportall 55 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]LegacyAngel 13 points14 points15 points 8 months ago\u00a0(0 children)This would have been awesome at my old gig.\n\npermalinkembedsavegive award[\u2013]perspectiveiskey 10 points11 points12 points 8 months ago\u00a0(1 child)This is pretty cool because it's super relevant.\nIt's on my list of things to read through and apply.\n\npermalinkembedsavegive award[\u2013]krinart[S] 4 points5 points6 points 8 months ago\u00a0(0 children)Any feedback would be much appreciated! Especially things to improve.\n\npermalinkembedsaveparentgive award[\u2013]Iamabandit 4 points5 points6 points 8 months ago\u00a0(0 children)Thanks! This should be pretty useful. Hopefully I will be able to try this out soon. \n\npermalinkembedsavegive award[\u2013]niloyghosh 2 points3 points4 points 8 months ago\u00a0(0 children)This looks interesting. Will definitely check it out. \n\npermalinkembedsavegive award[\u2013]lildarlin23 2 points3 points4 points 8 months ago\u00a0(0 children)Awesome! I will definitely test this, keep up the good work!\n\npermalinkembedsavegive award[\u2013]Invoker_is_my_city 2 points3 points4 points 8 months ago\u00a0(0 children)great stuff dude\n\npermalinkembedsavegive award[\u2013]KevMuriithi 2 points3 points4 points 8 months ago\u00a0(0 children)This is definitely something to check\n\npermalinkembedsavegive award[\u2013]noviceProgrammer1 2 points3 points4 points 8 months ago\u00a0(3 children)What prompted you to create this project? it seems really cool, you're serializing models and writing an api to generate the code and it's subsequent parameters?? \n\npermalinkembedsavegive award[\u2013]s0ck_r4w 2 points3 points4 points 8 months ago*\u00a0(2 children)Yeah, pretty much! Except you can even skip the serialization step and use Python object directly with m2cgen API\n\nWhat prompted you to create this project?\n\nI work at the company that does Data Science pipeline automation (not sharing the name of the company so that it doesn't count as an advertisement), and this is where I'm going to apply this project to address several challenges:\n\nBackward compatibility of models that we build. Using pickle may cause some problems once we need to update a version of some third-party library like scikit-learn or xgboost.\nModel deployment and productionalization.\nImprove performance while making scoring in stream (this one still requires validation).\n\nUPD: and fun of course!\n\npermalinkembedsaveparentgive award[\u2013]noviceProgrammer1 1 point2 points3 points 8 months ago\u00a0(1 child)I've done a fair amount of reading on pickling and would caution on using them for production. My research interest would actually be to learn how to serialize model objects and share them. Would love to bounce ideas with you. If you haven't, you can check out ONNX which isn't my work, but serializes deep learning models. May get some traction between different communities for feedback too :) \n\npermalinkembedsaveparentgive award[\u2013]s0ck_r4w 0 points1 point2 points 8 months ago\u00a0(0 children)\nI've done a fair amount of reading on pickling and would caution on using them for production. \n\nThis is exactly why we're looking for an alternative to pickling to store our model pipeline so that it can be efficiently served later :) \n\nIf you haven't, you can check out ONNX which isn't my work, but serializes deep learning models\n\nThanks for bringing this one up. I'll definitely take a look!\n\nMay get some traction between different communities for feedback too\n\nThat'd be just great!\n\u200b\n\npermalinkembedsaveparentgive award[\u2013]SelfishNeuron 4 points5 points6 points 8 months ago\u00a0(1 child)MATLAB has this feature in form of their \"coder\".\nIn my opinion, this one of the biggest advantages of MATLAB, there are so many synergies when you can turn any high-level code into C or C++ and then integrate it with any environment.\nOr directly compile.\nIt is good that Python gets such capabilities too.\n\npermalinkembedsavegive award[\u2013]physnchips 7 points8 points9 points 8 months ago\u00a0(0 children)It generates pretty lackluster code. I would definitely not say that MATLAB has an advantage here.\n\npermalinkembedsaveparentgive award[\u2013]s6x 6 points7 points8 points 8 months ago\u00a0(9 children)Just commenting so I can come back to this later.\n\npermalinkembedsavegive award[\u2013]Jonno_FTW 3 points4 points5 points 8 months ago\u00a0(0 children)You can star repos on GitHub for the same effect. \n\npermalinkembedsaveparentgive award[\u2013]bighunt16 0 points1 point2 points 8 months ago\u00a0(0 children)There's a save option underneath the post, in addition to starring on Github.\n\npermalinkembedsaveparentgive award[\u2013]iCogitoTabhiTohHoon -2 points-1 points0 points 8 months ago\u00a0(0 children)Yup\n\npermalinkembedsaveparentgive award[\u2013]VotedBestDressed -2 points-1 points0 points 8 months ago\u00a0(0 children)same\n\npermalinkembedsaveparentgive award[\u2013]noscopethebitch -2 points-1 points0 points 8 months ago\u00a0(0 children)Ditto\n\npermalinkembedsaveparentgive award[\u2013]NowanIlfideme -2 points-1 points0 points 8 months ago\u00a0(1 child)RemindMe! 1 month\n\npermalinkembedsaveparentgive award[\u2013]RemindMeBot 0 points1 point2 points 8 months ago\u00a0(0 children)I will be messaging you on 2019-04-05 12:15:24 UTC to remind you of this link.\nCLICK THIS LINK to send a PM to also be reminded and to reduce spam.\nParent commenter can  delete this message to hide from others.\n\n\n\nFAQs\nCustom\nYour Reminders\nFeedback\nCode\nBrowser Extensions\n\n\n\n\npermalinkembedsaveparentgive award[\u2013]inderjalli -2 points-1 points0 points 8 months ago\u00a0(0 children)RemindMe! 1 month!\n\npermalinkembedsaveparentgive award[\u2013]ryanbuck_ -2 points-1 points0 points 8 months ago\u00a0(0 children)I\u2019m on it! (but just not yet..)\n\npermalinkembedsaveparentgive award[\u2013]ZETTAwith4TEEEES 1 point2 points3 points 8 months ago\u00a0(0 children)Literally going to use this right now \n\npermalinkembedsavegive award[\u2013]hawkxor 1 point2 points3 points 8 months ago\u00a0(0 children)How does the speed compare against libraries like the java xgboost predictor?\n\npermalinkembedsavegive award[\u2013]abinjoabraham 1 point2 points3 points 8 months ago\u00a0(4 children)This is so cool. I was thinking how to implement my python model to production for autonomous driving. Mostly in the industry they use c++ for implementation. \n\npermalinkembedsavegive award[\u2013]krinart[S] 1 point2 points3 points 8 months ago\u00a0(3 children)Hope this helps!\nJust curious, which models did you use for autonomous driving?\n\npermalinkembedsaveparentgive award[\u2013]abinjoabraham 1 point2 points3 points 8 months ago\u00a0(2 children)Like open pose for 2d human pose estimation. \n\npermalinkembedsaveparentgive award[\u2013]krinart[S] 1 point2 points3 points 8 months ago\u00a0(1 child)For now we only support limited set of models, and open pose is not among them, unfortunately.\nHowever, we have a more or less simple mechanism to add support for new models. So if you are interested, you can try to implement open pose support. I will be happy to help you in that venture.\n\npermalinkembedsaveparentgive award[\u2013]abinjoabraham 0 points1 point2 points 8 months ago\u00a0(0 children)I  see. First lemme go through your repo. Actually I wanna do all these things but have limited time now as I am working on my master thesis. :) \n\u200b\n\npermalinkembedsaveparentgive award[\u2013][deleted] 8 months ago*\u00a0(4 children)[deleted]\n\n[\u2013]krinart[S] 0 points1 point2 points 8 months ago\u00a0(3 children)Native R support is probably not possible, the only way to do this is through PMML. That's one feature request we are currently looking into.\n\npermalinkembedsavegive award[\u2013][deleted] 8 months ago*\u00a0(2 children)[deleted]\n\n[\u2013]krinart[S] 0 points1 point2 points 8 months ago\u00a0(1 child)We directly work with Python objects representing models, so there\u2019s no intermediary format.\n\npermalinkembedsavegive award[\u2013]balls4xx 1 point2 points3 points 8 months ago\u00a0(0 children)Starred. \n\npermalinkembedsavegive award[\u2013]cyberdroidmann 1 point2 points3 points 8 months ago\u00a0(0 children)Awesome!!!\n\npermalinkembedsavegive award[\u2013]humanprogression 0 points1 point2 points 8 months ago\u00a0(6 children)Can you go into a bit more depth on the provided example? What\u2019s the Boston dataset and what\u2019s the original model that\u2019s being transformed? How do those relate to the java output that\u2019s shown?\n\npermalinkembedsavegive award[\u2013]krinart[S] 8 points9 points10 points 8 months ago\u00a0(4 children)Boston dataset is one of the \"Hello, world!\" datasets provided by sklearn. The model is LinearRegression and it's trained using this dataset. The java output is exactly the same model, but represented as Java code instead of Python object.\n\npermalinkembedsaveparentgive award[\u2013]humanprogression -2 points-1 points0 points 8 months ago\u00a0(3 children)So the java output is just some sort of netlist representation of the Python model? \n\npermalinkembedsaveparentgive award[\u2013]s0ck_r4w 7 points8 points9 points 8 months ago\u00a0(2 children)I'm not sure what \"netlist\" is, but generally speaking - yes, the generated code is a representation of the Python model.\n\npermalinkembedsaveparentgive award[\u2013]NicolasGuacamole 4 points5 points6 points 8 months ago\u00a0(1 child)Netlist is a term from computer engineering. In hardware description languages you specify a design at a high level, and then something akin to a compiler converts it to a 'netlist' which is a like a logic gate \/ wire level description (which can be implemented in hardware).\nWhat they're getting at I guess is that the Java version is another version of the same model, which of course it is.\n\npermalinkembedsaveparentgive award[\u2013]s0ck_r4w 3 points4 points5 points 8 months ago\u00a0(0 children)TIL! Thanks for explanation\n\npermalinkembedsaveparentgive award[\u2013]s0ck_r4w 3 points4 points5 points 8 months ago\u00a0(0 children)Boston housing dataset is just a demo dataset built into the Scikit-learn library. It's been used for demonstration purposes. In that example a simple linear regression model has been trained using the Boston housing dataset. After that the trained model has been transformed into its Java representation. Basically generated Java code serves a purpose of a model object's predict() method, except it's self-sufficient and doesn't require Python runtime for evaluation.\n\npermalinkembedsaveparentgive award[\u2013]e_j_white 0 points1 point2 points 8 months ago\u00a0(1 child)Cool! Will take a closer look later when I  get home.\nCould this be used to train a model in sklearn and export it in a way that it could be used in Go? (I think Go handles natively compiled Java\/C.)\n\npermalinkembedsavegive award[\u2013]krinart[S] 2 points3 points4 points 8 months ago*\u00a0(0 children)Sure, it is absolutely possible to add support for Go. It should be pretty simple, for example it took literally 120 lines of code to add Java support.\nFeel free to submit a PR, or we will add it some time later.\n\npermalinkembedsaveparentgive award[\u2013]Dagusiu 0 points1 point2 points 8 months ago\u00a0(3 children)Does this create code that can run on a GPU?\n\npermalinkembedsavegive award[\u2013]s0ck_r4w 0 points1 point2 points 8 months ago\u00a0(2 children)The generated function makes a prediction against a single sample so, since there are no matrix computations, I'd say that it's unlikely that this code can benefit from running on GPU. On the other hand it can be ideal for making predictions in streaming fashion.\n\npermalinkembedsaveparentgive award[\u2013]Dagusiu 1 point2 points3 points 8 months ago\u00a0(1 child)Oh, I thought this could be used for some kind of deep learning as well, like a CNN. I guess I misunderstood.\n\npermalinkembedsaveparentgive award[\u2013]krinart[S] 0 points1 point2 points 8 months ago\u00a0(0 children)No neural nets, sorry. Only old school models. \n\npermalinkembedsaveparentgive award[\u2013]manueslapera -1 points0 points1 point 8 months ago\u00a0(5 children)im a pure R\/Python\/golang type of guy, can you explain how we can use the produced code?\nFor example, if the output code is \npublic class Model {\npublic static double score(double[] input) {\n    return (((((((((((((36.45948838508965) + ((input[0]) * (-0.10801135783679647))) + ((input[1]) * (0.04642045836688297))) + ((input[2]) * (0.020558626367073608))) + ((input[3]) * (2.6867338193449406))) + ((input[4]) * (-17.76661122830004))) + ((input[5]) * (3.8098652068092163))) + ((input[6]) * (0.0006922246403454562))) + ((input[7]) * (-1.475566845600257))) + ((input[8]) * (0.30604947898516943))) + ((input[9]) * (-0.012334593916574394))) + ((input[10]) * (-0.9527472317072884))) + ((input[11]) * (0.009311683273794044))) + ((input[12]) * (-0.5247583778554867));\n}\n\n}\nHow would one go into using it?. Im saying this  because if I have to build the whole Java application to serve the predictions, i would rather go with openscoring instead.\n\npermalinkembedsavegive award[\u2013]krinart[S] 6 points7 points8 points 8 months ago\u00a0(0 children)\nIm saying this because if I have to build the whole Java application to serve the predictions\n\nThat's the other way around. You choose the target language depending on your production environment. If you already have a Java environment that all you have to do is to call score() method of the generated model. \nFor example:\nclass MyClass {\n    public static void main(String[] args) {\n        double[] features = new double[]{1, 2, 3};  \/\/ get features from somewhere\n        System.out.println(Model.score(features));\n    }\n}\n\nThat's it.\nIf you have a C production environment, then generate C code for the model and use it similarly.\n\npermalinkembedsaveparentgive award[\u2013]s0ck_r4w 6 points7 points8 points 8 months ago\u00a0(3 children)You're absolutely right, you have to build your own application around this code. Of course this is not as easy as sending a REST API request and perhaps openscoring is exactly what you need, but consider the following:\n\nCost and complexity of maintenance of yet another third-party service in your environment. Instead you can just embed your model anywhere.\n(<1 ms) latency raises some doubts especially without benchmarks to prove it (sorry if that's false, couldn't find any benchmarks on the project page). REST API is not the cheapest way to transfer the data and has some overhead.\nHow well this third-party service scales with data size? m2cgen allows to apply a model inside of a  Spark job as a plain map function.\nConsider a use case for embedded devices where call to a remote service can't be afforded.\n\n\npermalinkembedsaveparentgive award[\u2013]manueslapera -1 points0 points1 point 8 months ago\u00a0(2 children)Thanks for your reply, let me just add some comments about Openscoring.\n\nCost and complexity of maintenance of yet another third-party service in your environment. Instead you can just embed your model anywhere.\n\nWell there is the cost of maintenance of m2cgen if i ever would like to update the model or use a non supported algorithm\n\n(<1 ms) latency raises some doubts \n\nI have seen 3ms total latency with openscoring, which is bananas. It is optimized and well maintained, it supports TONS of different algorithms and its a mature project.\n\nHow well this third-party service scales with data size? m2cgen allows to apply a model inside of a Spark job as a plain map function.\n\nYou can do bulk or single requests with openscoring. It wont scale to parallellized computation (spark RDDs or anything beyond single node computation), so that is a point for mc2gen. However Id like to see the use case of training a random forest in a non spark environment and AFTER use it with spark. And well, besides, you could use pmml-evaluator (the internal library that handles model loading in Openscoring ) by itself with Spark (since the library is Java and so is spark).\n\nConsider a use case for embedded devices where call to a remote service can't be afforded.\nYeah totally, for this use case mc2gen is great.\n\n\npermalinkembedsaveparentgive award[\u2013]s0ck_r4w 0 points1 point2 points 8 months ago\u00a0(1 child)\nHowever Id like to see the use case of training a random forest in a non spark environment and AFTER use it with spark.\n\nThis is actually a pretty common use case. Arguably (and subjectively) the Random Forest (as well as any other ML algorithm) implementation is quite far from being good in Spark. But it's not only about Random Forest, right?\n\npermalinkembedsaveparentgive award[\u2013]manueslapera 0 points1 point2 points 8 months ago\u00a0(0 children)\nThis is actually a pretty common use case.\n\nNever seen that, usually I implement spark pipelines when I have the required amount of data, and usually I want my models to benefit from the biggest dataset I can.  I used RF as an example since its one of the few models mc2gen supports.\nAs a side note, can you elaborate on why the RF implementation in spark is not good?\n\npermalinkembedsaveparentgive awardaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 23533 on  r2-app-0cf8a7879c94f994f  at 2019-11-18 13:47:43.178841+00:00 running 85b1b7a country code: US."
  },
  "16":{
    "title":"[D] Best practice and tips & tricks to write scientific papers in LaTeX, with figures generated in Python or Matlab : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-funny-pics-aww-worldnews-gaming-todayilearned-television-gifs-Showerthoughts-Jokes-videos-tifu-mildlyinteresting-TwoXChromosomes-OldSchoolCool-space-creepy-nottheonion-books-movies-personalfinance-LifeProTips-IAmA-explainlikeimfive-dataisbeautiful-Futurology-science-gadgets-askscience-food-sports-nosleep-Music-Art-WritingPrompts-EarthPorn-history-DIY-photoshopbattles-Documentaries-UpliftingNews-GetMotivated-listentothis-philosophy-announcements-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsother discussions (1)Want to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  18 Mar 2019416 points (98% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave818,951 readers2,365 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X51  \u00b7 36 comments [D] An Interesting (in my opinion) Observation While Messing With the Full GPT-293  \u00b7 24 comments [D] Is the inception architecture\/block a failure?30  \u00b7 6 comments [D] Best resources to learn about Anomaly Detection on Big Datasets?34  \u00b7 1 comment [D] Machine Learning - WAYR (What Are You Reading) - Week 757  \u00b7 7 comments [D] Bahdanau attention model[D] Are design patterns useful to build machine learning projects of python?29  \u00b7 9 comments [R] Neural Network Processing Neural Networks1 [R] A New Deterministic Technique for Symbolic Regression1  \u00b7 5 comments [D] Many papers don\u2019t do hyperparameter search on DNN baselines254  \u00b7 29 comments [P] baikal: A graph-based functional API for building complex scikit-learn pipelinesWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7415416417Discussion[D] Best practice and tips & tricks to write scientific papers in LaTeX, with figures generated in Python or Matlab (self.MachineLearning)submitted 8 months ago by WookaiI'm working on a paper with some colleagues and I just remembered I had collected a series of tips & tricks to make paper writing more efficient, so I figured I'd share here: https:\/\/github.com\/Wookai\/paper-tips-and-tricks\nWhat are your best tips for collaborating on a paper and writing more efficiently?\n\n56 commentssharesavehidereportall 56 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]svldsmnn 40 points41 points42 points 8 months ago\u00a0(12 children)I\u2019d add that matplotlib2tikz is great: the plots are rendered by latex right from your data, and you have all the control over figure sizes etc. defined as variables in your latex document. \n\npermalinkembedsavegive award[\u2013]Wookai[S] 6 points7 points8 points 8 months ago\u00a0(3 children)Yes, it's a great way to do it, too! I remember having some issues with a pretty complicated figure and moving away from it because of that, but I'm not sure about the details now...\n\npermalinkembedsaveparentgive award[\u2013]Mefaso 1 point2 points3 points 8 months ago\u00a0(2 children)There's some weird stuff where it adds \"forget plot\" to all plots causing it to crash and issues like that, but mostly they can be fixed quite easily by pursuing the tracebacks\n\npermalinkembedsaveparentgive award[\u2013]nschloe 5 points6 points7 points 8 months ago\u00a0(1 child)matplotlib2tikz author here. I've just released 0.7.1 with a bunch of fixes for legends; perhaps those satisfy your use case.\n\npermalinkembedsaveparentgive award[\u2013]Mefaso 0 points1 point2 points 8 months ago\u00a0(0 children)Oooo, cool to hear, will look into it :)\n\npermalinkembedsaveparentgive award[\u2013]bokan -2 points-1 points0 points 8 months ago\u00a0(7 children)Could you possibly explain the pitch for Latex to me? It\u2019s become super common in computing recently now that Overleaf is a thing. Personally, it\u2019s hard to actually write anything when I have to worry about essentially designing a webpage too. I want to be able to focus on content, and often need fine grained control over the formatting afterwards. Am I missing something? \n\npermalinkembedsaveparentgive award[\u2013]impossiblefork 16 points17 points18 points 8 months ago\u00a0(3 children)It's always been super common. Basically all maths, physics and computer science papers are written in LaTeX.\n\npermalinkembedsaveparentgive award[\u2013]Telci 3 points4 points5 points 8 months ago\u00a0(1 child)Economics, too. Not only for papers but also for presentations.\n\npermalinkembedsaveparentgive award[\u2013]impossiblefork 1 point2 points3 points 8 months ago\u00a0(0 children)nods\nA lot of older papers appear to be non TeX-y, for example the original Fischer-Black paper doesn't appear to be done in TeX. For actuarial stuff I've seen a bunch of old typewriter-y things and in economics I've seen a lot of word stuff with large spacing between the lines, but I think things are changing with TeX becoming more widespread.\nThe Mack article on chain ladder estimates is old and looks like it's done in TeX though.\n\npermalinkembedsaveparentgive award[\u2013]bokan 0 points1 point2 points 8 months ago\u00a0(0 children)Interesting. It seems to be growing into non-cs computing fields, then (HCI in particular).\n\npermalinkembedsaveparentgive award[\u2013]here_we_go_beep_boop 7 points8 points9 points 8 months ago\u00a0(0 children)This is exactly the point of LaTeX, decoupling content from style.  Where LaTeX gets hard is when you want to micromanage that style, you quickly disappear in arcana. \n\npermalinkembedsaveparentgive award[\u2013]r4and0muser9482 3 points4 points5 points 8 months ago\u00a0(0 children)The whole point of latex is that you should concentrate on content and the publisher is responsible for the style. When writing in latex you should provide the minimal amount of information required to render your thesis correctly in any style the publisher later chooses.\n\npermalinkembedsaveparentgive award[\u2013]A_Philosophical_Cat 2 points3 points4 points 8 months ago\u00a0(0 children)The magic of LaTeX is that you don't need to think about layout. You tell it \"this is a paragraph\" \"this should be in italics\" \"stick a footnote here\", then it just generates a very consistent, professional looking document. The trick is to avoid micromanaging the compiler. \n\npermalinkembedsaveparentgive award[\u2013][deleted] 8 months ago*\u00a0(1 child)[deleted]\n\n[\u2013]Wookai[S] 6 points7 points8 points 8 months ago\u00a0(0 children)Great suggestion, thanks! The only document I have fully using all these tips is my PhD thesis, which can be a bit long to be considered a MWE :) : http:\/\/vincent.etter.io\/publications\/etter2015phd.pdf\n\u200b\nI'll have a look at the source code though, it might still be a good example. If so, I'll link it in the README.\n\npermalinkembedsavegive award[\u2013]doktorneergaard 6 points7 points8 points 8 months ago\u00a0(1 child)This is great!\n\u200b\nThe one sentence per line thing is something I also just started doing, but mainly because I had a split screen setup with not enough real-estate to see sentences that come immediately after a very long sentence. It also comes in handy for commenting out specific stuff and\/or figuring out where an error is located.\n\u200b\nHowever, the math notation section is really dependent on the author and\/or the audience. I've seen many versions on the bold and\/or italicized vector\/matrix situation.\n\u200b\nForked :)\n\npermalinkembedsavegive award[\u2013]Wookai[S] 2 points3 points4 points 8 months ago\u00a0(0 children)Indeed, it is also very dependent on the field! My goal was mostly to share the system I picked as one possible solution. The most important is to pick one way and be consistent :)\n\npermalinkembedsaveparentgive award[\u2013]seraschka 14 points15 points16 points 8 months ago\u00a0(8 children)\nTo write centered equations on their own lines, do not $$...$$ (it is one of the deadly sins of LaTeX use). It works, but gives wrong spacing. Use \\begin{equation} or \\begin{align} instead.\n\nDoesn't \\begin{equation}... number equations by default whereas $$ doesn't?\n\npermalinkembedsavegive award[\u2013]topologique 19 points20 points21 points 8 months ago\u00a0(2 children)It does, but you can use \\begin{equation*} to avoid numbering\n\npermalinkembedsaveparentgive award[\u2013]seraschka 8 points9 points10 points 8 months ago\u00a0(1 child)right, so shouldn't the suggestion be \n\nTo write centered equations on their own lines, do not $$...$$ (it is one of the deadly sins of LaTeX use). It works, but gives wrong spacing. Use \\begin{equation*} or \\begin{align*} instead?\n\n\npermalinkembedsaveparentgive award[\u2013]Wookai[S] 7 points8 points9 points 8 months ago\u00a0(0 children)Good point, I'll make the change! Thanks!\n\npermalinkembedsaveparentgive award[\u2013]TheMiamiWhale 2 points3 points4 points 8 months ago\u00a0(0 children)You can use an asterisk after equation to suppress the numbering. \\begin{equation*}. \nSorry for formatting but I\u2019m on mobile and can\u2019t find the backtick.\n\npermalinkembedsaveparentgive award[\u2013]Raqato 0 points1 point2 points 8 months ago\u00a0(3 children)Yes it does, but if you do not need an equation number you could use \\begin{equation*}...\nAlso, if i recall correctly, \\[ ... \\] should give you equations on their own line just like $$...$$, without committing any sins. \n\npermalinkembedsaveparentgive award[\u2013]seraschka -2 points-1 points0 points 8 months ago\u00a0(2 children)I am not 100% sure but I think that  [ ... ] and $$...$$ lead to identical results as one gets converted into the other automatically.\n\npermalinkembedsaveparentgive award[\u2013]Raqato 1 point2 points3 points 8 months ago*\u00a0(1 child)I don't think they are inter-convertible. You can check this on stack exchange for a nice comparison. \nEdit: Fixed the link. Sorry, I was on mobile when I posted it. \n\npermalinkembedsaveparentgive award[\u2013]seraschka -1 points0 points1 point 8 months ago\u00a0(0 children)the link doesn't work for me.  When I remember though $$ is tex syntax and \\[ is latex syntax. So, it depends on your environment on what \\[ does in your case. But I think unless you specify anything in particular, there will not be much of a difference (of course I would still recommend \\[, was just saying ....)\n\npermalinkembedsaveparentgive award[\u2013]vic4ever 5 points6 points7 points 8 months ago\u00a0(2 children)www.tablesgenerator.com is also helpful in creating Latex tables.\n\npermalinkembedsavegive award[\u2013]Pfohlol 1 point2 points3 points 8 months ago\u00a0(0 children)I've found the latex functions in Pandas to be decent as well. It's usually not perfect, but it's close enough to my desired table that I can fix it up by hand\n\npermalinkembedsaveparentgive award[\u2013]Wookai[S] 1 point2 points3 points 8 months ago\u00a0(0 children)Cool! As someone else mentioned, templating engines like Jinja are also very useful to generate tables. You can have your Python code read the data directly, format it as you want, and then generate the final LaTeX code that you simply have to copy\/paste there.\n\npermalinkembedsaveparentgive award[\u2013]__alk__ 3 points4 points5 points 8 months ago\u00a0(8 children)Thanks, looks pretty good actually.\n\npermalinkembedsavegive award[\u2013]Wookai[S] 2 points3 points4 points 8 months ago\u00a0(7 children)Thanks! The part about figures was the most helpful to me, especially to have consistent font sizes, etc. between figures: https:\/\/github.com\/Wookai\/paper-tips-and-tricks#creating-figures\n\npermalinkembedsaveparentgive award[\u2013]hielkew 0 points1 point2 points 8 months ago\u00a0(1 child)The link to plot_utils.py is dead. Now I don't know how you do it :(. \nI personally made use of rcParams to have consistent figures. Not 100 % reliable somehow. \n\npermalinkembedsaveparentgive award[\u2013]Wookai[S] 0 points1 point2 points 8 months ago\u00a0(0 children)Sorry, I fixed it! Here's the link just in case: https:\/\/github.com\/Wookai\/paper-tips-and-tricks\/blob\/master\/src\/python\/plot_utils.py\n\npermalinkembedsaveparentgive award[+]__alk__ comment score below threshold-6 points-5 points-4 points 8 months ago\u00a0(4 children)Do you write all your work\/research papers in LaTeX or you use some other 'less bloated' typesetters like Groff?\n\npermalinkembedsaveparentgive award[\u2013]hielkew 3 points4 points5 points 8 months ago\u00a0(2 children)I believe in science, LaTeX is pretty much the standard. I actually don't know if groff is really that good. I am afraid you will quickly hit walls if you want to do something specialized or want to have more fine grained control. For what I have seen the way the math renders in Groff is also not very pretty compared to LaTeX. \n\npermalinkembedsaveparentgive award[\u2013]samesense 5 points6 points7 points 8 months ago\u00a0(1 child)Ha. The standard for science. You must not collaborate with biologists or physicians.\n\npermalinkembedsaveparentgive award[\u2013]hielkew 1 point2 points3 points 8 months ago\u00a0(0 children)Well at least they won't write a groff document. \n\npermalinkembedsaveparentgive award[\u2013]Wookai[S] 1 point2 points3 points 8 months ago\u00a0(0 children)I do! It's very powerful, gives great-looking results, and is pretty much understood by everybody so easy to collaborate with.\nEDIT: math looks awesome, too :)\n\npermalinkembedsaveparentgive award[\u2013]seraschka 2 points3 points4 points 8 months ago\u00a0(1 child)\ncan call its ith column \\vxi (it is a vector, thus in bold) and one if its element x{ij}, not \\vXi and \\vX{ij}.\n\nI'd further suggest \"\\vX{i,j}\" instead of \"\\vX{ij}\" because if you have something like \\vX_{123} it will be unclear what that means ;)\n\npermalinkembedsavegive award[\u2013]Wookai[S] 0 points1 point2 points 8 months ago\u00a0(0 children)Sure, if you ever have a case where it might be unclear, add a ,. In my case, I always used single letters indices so it made the notation much lighter not having the ,.\n\npermalinkembedsaveparentgive award[\u2013]anterak13 1 point2 points3 points 8 months ago\u00a0(0 children)not really a tip per se but I really like madoko (its a literate markdown variant and allows to export to PDF through latex and to html\/reveal.js) \nThe way it allows to mix code and mathmode with transformations is really cool\nhttp:\/\/madoko.org\/reference.html#sec-pre\n\npermalinkembedsavegive award[\u2013]johndoez01 1 point2 points3 points 8 months ago\u00a0(1 child)Thank you! \n\npermalinkembedsavegive award[\u2013]Wookai[S] 0 points1 point2 points 8 months ago\u00a0(0 children)You're very welcome!\n\npermalinkembedsaveparentgive award[\u2013]M4mb0 1 point2 points3 points 8 months ago\u00a0(0 children)Is there a guide on how to make the font size in an image equal to the font size of the paper?\nAs far as I can tell, with matplotlib, one has to set figsize equal to the dimensions of the image in the paper, in inches. This is pretty annoying because once you change anything in the TeX (say you decide to make the image a bit bigger\/smaller) the font size end up not matching anymore....\n\npermalinkembedsavegive award[\u2013]QuantumCakeIsALie 1 point2 points3 points 8 months ago\u00a0(1 child)For complex and long documents like theses, you should consider using latexmk for compiling. \nIt's an excellent perl program that can compile the minimum number of times required ([pdf,la]{tex}, bibtex, even detect modified figures).\nIt can even compile continuously, compiling the minimum required stuff each time a file changes. It's particularly best with a pdf reader doesn't lock the pdf and automatically reloads the modified file, like most Linux readers I've seen.\nSee an example makefile using it here.\n\npermalinkembedsavegive award[\u2013]Wookai[S] 0 points1 point2 points 8 months ago\u00a0(0 children)Indeed, latexmk is really useful! I'll mention it when I update the doc.\n\npermalinkembedsaveparentgive award[\u2013]nuggetman415 1 point2 points3 points 8 months ago\u00a0(1 child)I highly recommend LyX. It is a free word processor that renders out full LaTeX and abstracts away a lot of the nasty markup. It\u2019s been incredibly useful for me, especially when dealing with math and formulae with lots of variables and such. I\u2019m not exaggerating when I say it saved me probably hundreds of hours dealing with actual LaTeX.\nIt might take a little bit of getting used to the UI (at least, it did when I was in college a few years back) but I ended up getting really familiar with it and ended up using it for almost every course I took. Even put my resume through it.\n\npermalinkembedsavegive award[\u2013]anuumqt 1 point2 points3 points 8 months ago\u00a0(0 children)I don't think it works with a lot of packages.  It also works poorly with collaborating who don't use LyX themselves.  It is better to just learn LaTeX.\n\npermalinkembedsaveparentgive award[\u2013]lunaticneko 0 points1 point2 points 8 months ago\u00a0(0 children)Recommend that if you have tons of things to process, a makefile should be a good idea. It makes sure that your scripts do not get ignored when you want to update figures. Plus, they are quite flexible and you can create different actions (compilation steps) for different script files.\nDone properly, this can reduce error and increase productivity.\n\npermalinkembedsavegive award[\u2013]xayma 0 points1 point2 points 8 months ago\u00a0(0 children)While you can use packages to round numbers you shouldn't have it as a default. You should know how many significant figures each of your results have and it will vary, an arbitrary rounding can give erroneous results when you have things like catastrophic cancellation in your code. (Even in the example it moves something that ends in .5 to .500 which is two orders of magnitude more precise).\nAlso using too many of your own commands can ruin the style guides of journals if they provide it. \n\npermalinkembedsavegive award[\u2013]brunhilda1 0 points1 point2 points 8 months ago\u00a0(0 children)Gnuplot+makefiles.\n\npermalinkembedsavegive award[\u2013]Wookai[S] 0 points1 point2 points 8 months ago\u00a0(0 children)Thanks all for the great feedback and discussion, I'll update this thread once I push an update. If you're interested, there was a great discussion on HN as well: https:\/\/news.ycombinator.com\/item?id=19425637\n\npermalinkembedsavegive award[\u2013]saforem2 0 points1 point2 points 8 months ago\u00a0(0 children)I really like the style of your thesis, I was wondering if you could share the .sty file or template that you used for it?\n\npermalinkembedsavegive award[\u2013]SageBait 0 points1 point2 points 8 months ago\u00a0(1 child)What's the best way to use wrapfig(https:\/\/www.overleaf.com\/learn\/latex\/Wrapping_text_around_figures) to have my images in line? The link I posted just has a simple syntax and sometimes when I use wrapfig near a page break it fucks up my whole document.\n\npermalinkembedsavegive award[\u2013]QuantumCakeIsALie 0 points1 point2 points 8 months ago\u00a0(0 children)Wrapfig has always been finicky. I used to put some \\vspace before and after it and manually adjust them once the document is about finished.\n\npermalinkembedsaveparentgive award[\u2013]SageBait -1 points0 points1 point 8 months ago\u00a0(1 child)Also how do you deal with collaborating with people who don't know LaTeX but use Word? Is there some sort of middle ground besides pandoc?\n\npermalinkembedsavegive award[\u2013]xgfs 0 points1 point2 points 8 months ago\u00a0(0 children)Overleaf tries to bridge the gap to such poor souls\n\npermalinkembedsaveparentgive awardaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 18526 on  r2-app-0efa2b46a0ca56c64  at 2019-11-18 14:13:44.285724+00:00 running 85b1b7a country code: US."
  },
  "17":{
    "title":"[Discussion] Agree or disagree: Data science jobs will undergo radical change with automated software in next 5 years. : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-funny-pics-aww-worldnews-gaming-todayilearned-television-gifs-Showerthoughts-Jokes-videos-tifu-mildlyinteresting-TwoXChromosomes-OldSchoolCool-space-creepy-nottheonion-books-movies-personalfinance-LifeProTips-IAmA-explainlikeimfive-dataisbeautiful-Futurology-science-gadgets-askscience-food-sports-nosleep-Music-Art-WritingPrompts-EarthPorn-history-DIY-photoshopbattles-Documentaries-UpliftingNews-GetMotivated-listentothis-philosophy-announcements-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  03 Mar 2019276 points (96% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave818,922 readers2,264 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X44  \u00b7 32 comments [D] An Interesting (in my opinion) Observation While Messing With the Full GPT-298  \u00b7 24 comments [D] Is the inception architecture\/block a failure?29  \u00b7 6 comments [D] Best resources to learn about Anomaly Detection on Big Datasets?37  \u00b7 1 comment [D] Machine Learning - WAYR (What Are You Reading) - Week 754  \u00b7 6 comments [D] Bahdanau attention model30  \u00b7 9 comments [R] Neural Network Processing Neural Networks[R] A New Deterministic Technique for Symbolic Regression\u00b7 4 comments [D] Many papers don\u2019t do hyperparameter search on DNN baselines250  \u00b7 28 comments [P] baikal: A graph-based functional API for building complex scikit-learn pipelines4  \u00b7 1 comment [P] Sentence similarity using siamese LSTMWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7275276277Discussion[Discussion] Agree or disagree: Data science jobs will undergo radical change with automated software in next 5 years. (self.MachineLearning)submitted 8 months ago by [deleted]https:\/\/www.forbes.com\/sites\/forbestechcouncil\/2019\/03\/01\/radical-change-is-coming-to-data-science-jobs\/\nI read this article from the link above. I tend to disagree with the notion that the data science job will be eliminated by auto machine learning software packages like data robot. I hate the idea of someone just throwing their data in and getting results. From my experience as a data scientist, it takes time and energy to analyze the data, implement feature engineering, and evaluating model performance based on the data. \nAs for \u201cwe are automating ourselves out of our job\u201d. Well yeah that\u2019s the idea. And that\u2019s not a bad thing. However, I think we automate one process to move on to automate something else, especially with all types of new data  coming into the digital world.\nI do find it interesting how the author splits the new data science work into 5 areas that will take place at n 5-10 years. Do you agree with this assessment? Will the data scientist \u201cboom\u201d disappear? Will it be replaced by a more specific job? What do you think? If these changes are true, how does it impact our work?\n\n123 commentssharesavehidereportall 123 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]logicchains 256 points257 points258 points 8 months ago\u00a0(31 children)I think https:\/\/stats.stackexchange.com\/questions\/185507\/what-happens-if-the-explanatory-and-response-variables-are-sorted-independently is an example of why data science won't be automated away any time soon. Picking the right data to use, cleaning and validating it correctly, is at least as important as picking the right model. \nPlus, no software is capable of trawling through the bowels of the organisation to find out the correct interpretation of the `Extra2` field on the `Sales` table that takes three values: \"TRUE\", \"Error\" and null.\n\npermalinkembedsavegive award[\u2013]stirling_archer 127 points128 points129 points 8 months ago\u00a0(16 children)\nhttps:\/\/stats.stackexchange.com\/questions\/185507\/what-happens-if-the-explanatory-and-response-variables-are-sorted-independently\n\nThis needs a trigger warning.\n\npermalinkembedsaveparentgive award[\u2013]wintermute93 51 points52 points53 points 8 months ago\u00a0(13 children)This has got to be one of the most egregious professional math fails ever. It's up there with that biomedical conference paper or whatever it was that \"invented\" the trapezoid method for approximating integrals.\n\npermalinkembedsaveparentgive award[\u2013]EngineeringNeverEnds 32 points33 points34 points 8 months ago\u00a0(6 children)No, this is 1000x worse.  At least the biomedical dude got it right.\nThis is just... Wow.  \"My manager says he gets better regressions when he does this.\"\nUhm holy shit I'd like to shake the hand of someone that was that stupid but managed to get into a managerial position in charge of processing data.  Mind blowing.\n\npermalinkembedsaveparentgive award[\u2013]VirtualRay 3 points4 points5 points 8 months ago\u00a0(5 children)Lol at the assumption that there's any sort of meritocracy in the real business world\n\npermalinkembedsaveparentgive award[\u2013]EngineeringNeverEnds 2 points3 points4 points 8 months ago\u00a0(4 children)In every environment I've ever worked, competency has been rewarded, albeit with some degree of error.\n\npermalinkembedsaveparentgive award[\u2013]VirtualRay 0 points1 point2 points 8 months ago\u00a0(3 children)You are adorable, my friend\nhttps:\/\/daedtech.com\/programmer-skill-fetish-contextualized\/ \n\npermalinkembedsaveparentgive award[\u2013]EngineeringNeverEnds 2 points3 points4 points 8 months ago\u00a0(2 children)Competency is not limited to technical competency.  You must also be helpful, communicative, enjoyable to be around, etc.  Do you bring your team up?  Those all factor into overall competency.  Competency as I use it has to do with your probability of success if I drop you into a random team.  Yes, your social skills matter. \nThink of it like the difference between a very good student that does well on a math test vs a good professor.  The professor also did well on the same test years ago, but they've got a lot of other skills that add to their overall competency. \n\npermalinkembedsaveparentgive award[\u2013]VirtualRay 0 points1 point2 points 8 months ago\u00a0(1 child)Yeah, for sure.  Although I think it's weird that men tend to exhibit more \"competency\" than women, and natives at a company tend to exhibit more \"competency\" than foreigners.\nAnd people who're really good at always keeping an eye on what the C-suite is prioritizing (and worm their way into projects in those areas) always seem to be more \"competent\" than the ones who just do what they're told and work hard every day.\n\npermalinkembedsaveparentgive award[\u2013]EngineeringNeverEnds 0 points1 point2 points 8 months ago\u00a0(0 children)I explicitly stated there was some degree of error which explains the 1st point.  (While biases exist, I guarantee you that an objective evaluation of competency will have a positive correlation with promotion probability among similar cohorts.)\nThe second point though is really the heart of my previous argument.  Someone that just keeps their head down, doesn't care to interact with other team members, employees on different teams, company leadership, etc. is in almost no way demonstrating leadership and teamwork competency which is an essential component of the value of an employee. \nWhy leadership though?  It's typically the single most valued and rewarded attribute, often for good reason.  Technical competency doesn't typically have as long of a path of advancement.  Both are often important for most practical advancement paths.  \n\npermalinkembedsaveparentgive award[\u2013]rpswanson3 7 points8 points9 points 8 months ago\u00a0(2 children)Do you have a link?\n\npermalinkembedsaveparentgive award[\u2013]i-heart-turtles 18 points19 points20 points 8 months ago\u00a0(1 child)I think this is it - almost 350 citations.\nhttp:\/\/care.diabetesjournals.org\/content\/17\/2\/152.abstract\n\npermalinkembedsaveparentgive award[\u2013]rpswanson3 2 points3 points4 points 8 months ago\u00a0(0 children)Thanks!\n\npermalinkembedsaveparentgive award[\u2013]deathacus12 2 points3 points4 points 8 months ago\u00a0(0 children)Simpson's method?\n\npermalinkembedsaveparentgive award[\u2013]zu7iv 1 point2 points3 points 8 months ago\u00a0(0 children)At least they were right\n\npermalinkembedsaveparentgive award[\u2013]venustrapsflies 20 points21 points22 points 8 months ago\u00a0(0 children)me going in: \"ha, how bad can it be?\"\noh.\n\npermalinkembedsaveparentgive award[\u2013]C-Hoppe-r 4 points5 points6 points 8 months ago\u00a0(0 children)I'm literally shaking. \n\npermalinkembedsaveparentgive award[\u2013]themiro 37 points38 points39 points 8 months ago\u00a0(0 children)Holy shit. \nThank you, this was a breath of fresh air - my standards for data illiteracy had gotten too snobbish. \n\npermalinkembedsaveparentgive award[\u2013]shaggorama 13 points14 points15 points 8 months ago*\u00a0(1 child)This exactly. With the democratization of ML techniques, there will be an increase in people with just enough knowledge to be really dangerous. There's a difference between finding a signal in data, finding a signal that is actually there (and knowing how how to demonstrate that), and even more so a signal that anyone gives a shit about.\n\npermalinkembedsaveparentgive award[\u2013]life2vec 7 points8 points9 points 8 months ago\u00a0(0 children)Yes this. My PhD work was full of: statistically significant but substantively irrelevant :')\n\npermalinkembedsaveparentgive award[\u2013]jeanduluoz 28 points29 points30 points 8 months ago\u00a0(3 children)Suggesting this false binary is misleading. It's not like it's AI or humans. AI will take over work on the margins, and humans will be freed to add more value on our margins.\nIt like saying computers will\/won't have a major impact on accounting jobs. Both are wrong - it's not like computers could replace accountants, but at the same time, accountant work and productivity is clearly impacted by new tools. \nCreating this false dichotomy is just misleading or misunderstanding fundamental economics. \n\npermalinkembedsaveparentgive award[\u2013]FrenchCuirassier 6 points7 points8 points 8 months ago*\u00a0(1 child)Data is also growing at an exponential rate. There will be more jobs in the future but most of it will be analyzing data, understanding, interpreting and explaining.\nWould some magical AI be able to interpret everything and understand it and then do everything? Sure, except, access-to-data is important, convincing the humans is important, and it would be like having that one genius academic who can't explain anything and can only accomplish so much without someone running out of funding. Not saying a singularity won't come in the future but it will likely be a lot of years later and much later than expected. There are other technologies that might be a closer-threat to existence, the economy, or humanity.\n\npermalinkembedsaveparentgive award[\u2013]jeanduluoz 1 point2 points3 points 8 months ago\u00a0(0 children)Agreed for sure. Matrix network is an interesting application of the concept \n\npermalinkembedsaveparentgive award[\u2013]chatterbox272 3 points4 points5 points 8 months ago\u00a0(0 children)I'm not sure the will\/won't have a major impact dichotomy is what you actually mean to talk about. AI\/Computing is and will have a major impact on jobs like accounting, it will fairly significantly change what that job entails. Accountants will still exist, but probably fewer and doing different tasks to what accountants are doing right now. The end result is the same but the process will change drastically.\nSuch is likely to be the result of applying AI to most fields as AI becomes more powerful. The lower skilled components of jobs will go away allowing many people to be replaced by an AI tool plus a smaller number of people with higher skill levels to do the high-skill components more effectively.\n\npermalinkembedsaveparentgive award[\u2013]MTMD36 4 points5 points6 points 8 months ago\u00a0(0 children)This is my favourite link of all time\n\npermalinkembedsaveparentgive award[\u2013]dafaq1112 4 points5 points6 points 8 months ago\u00a0(2 children)I don't know man. You'd be hard pressed to find examples of such exquisite stupidity. \n\npermalinkembedsaveparentgive award[\u2013]EatsAssOnFirstDates 11 points12 points13 points 8 months ago\u00a0(1 child)80% of data science is dealing with these situations. It's entirely commonplace.  If a company harmonizes their data and gets a workflow going that allows it to be automated then good for them,  they don't need data scientists,  but it took a lot of data scientists to get there and will be short lived without a few around.\n\npermalinkembedsaveparentgive award[\u2013]IanCal 4 points5 points6 points 8 months ago\u00a0(0 children)And even if you've got all your data sorted, then you start looking at integrating other data from outside and these problems come up again and again.\n\npermalinkembedsaveparentgive award[\u2013][deleted] 1 point2 points3 points 8 months ago\u00a0(0 children)I had to read it twice to understand this. Next time, If I have a unsolvable problem and want to show some progress, I will try this :-D\n\npermalinkembedsaveparent[\u2013]EatsAssOnFirstDates 0 points1 point2 points 8 months ago\u00a0(0 children)I think this is true but it depends on companies understanding this issue. I do biotech and the amount of underestimating PhD level scientists make around transforming an unlabeled excel sheets data into results is astounding. \n\npermalinkembedsaveparentgive award[\u2013]BeneficialArcher 45 points46 points47 points 8 months ago*\u00a0(4 children)I think it's unlikely that most data science roles will be automated. The thing is that the bit that's feasible to automate with current technology (i.e. feed in well prepared data and get output) is already automated (e.g. If I have a data array X, I can already easily pass those to scikit learn or something and get some output). The hard bit is stuff like interpreting results, using appropriate methods, knowing what to with messy data, knowing what data to use, and as far I know there's no software that's anywhere near being able to take a vague problem and use all available data to solve it (e.g. here's all the data that our hospital has, use it to automatically classify diseases). Adding a nice GUI to the bit that's already automated isn't gonna change things.\nIt wouldn't surprise me if a lot of companies try to automate data science by getting people who don't know much about statistics (and possibly combined with offshoring) to use automated tools in order to cut costs. But I suspect that they'll go back to hiring people who know more about machine learning after getting disastrous results for a few years (I've actually seen a couple of companies do this already).\nAs a side note, I think it's plausible that salaries will fall a bit over the next few years, but I think this will be due to hype dying down and more people graduating with stats degrees, not automation.\n\npermalinkembedsavegive award[\u2013]uber_neutrino 12 points13 points14 points 8 months ago\u00a0(1 child)\nAs a side note, I think it's plausible that salaries will fall a bit over the next few years, but I think this will be due to hype dying down and more people graduating with stats degrees, not automation.\n\nMy bet would be that salaries rise as the use of ML opens up positions in other areas that put pressure on people with data science knowledge.\n\npermalinkembedsaveparentgive award[\u2013]Aaraeus 2 points3 points4 points 8 months ago*\u00a0(0 children)Agreed. The number of people with maths and stats degrees in the UK hasn\u2019t increased by much. \n\npermalinkembedsaveparentgive award[\u2013]killver 90 points91 points92 points 8 months ago\u00a0(18 children)I have not seen a single case where AutoML outperforms a skilled data scientist. Otherwise all Kaggle competitions would be won by an algo. Specifically, domain knowledge will always be important. I have tried several AutoML tools a few times and never could achieve results that satisfied me. So I strongly disagree.\n\npermalinkembedsavegive award[\u2013]sid__ 49 points50 points51 points 8 months ago\u00a0(5 children)I tend to agree with this statement regarding highly specialized applications of ML, but consider a normal company that does not wish to hire a 150k data scientist. If they can still get average prediction results from a normal software engineer who threw some data into an autoML engine, and called it using an api, I think that is good enough in a lot of cases. Especially if it is not some mission critical application. At the end of the day, I think software engineering as a discipline will be much harder to automate than data science.\n\npermalinkembedsaveparentgive award[\u2013]Gabe_Isko 6 points7 points8 points 8 months ago\u00a0(0 children)They do wish to hire a 150K data scientist if they provide a suitable return on the investment for that salary. Making more powerful tools for datascience should only increase the demand for people who are skilled at using them. It is up to people practicing data science to not get stuck in one set of tools or one one framework, but to embrace change.\n\npermalinkembedsaveparentgive award[\u2013]killver 24 points25 points26 points 8 months ago\u00a0(0 children)It depends of course on your definition of a data scientist and on the use case. But maybe let's put it like that: highly skilled data scientists can not be replaced, but mediocre ones that just apply their stack of 5 algos anyways can be replaced\n\npermalinkembedsaveparentgive award[\u2013]killver 2 points3 points4 points 8 months ago\u00a0(0 children)You still need to know what you are doing also. I have seen people using SAS or other click modelers in ways not imaginable...\n\npermalinkembedsaveparentgive award[\u2013]ValiantlyShy 2 points3 points4 points 8 months ago\u00a0(0 children)Hand crafted rules will be cheaper and more effective in these cases \n\npermalinkembedsaveparentgive award[\u2013]Nazka231 0 points1 point2 points 8 months ago*\u00a0(0 children)If they don't wish to hire a 150k data scientist because it will be too expensive than it means they have a small business and simple math and stats on an excel spreadsheet will be well enough. Else they are just being blinded by money for not paying someone that can give them way much more than 150k and they will be the next dinosaures of their industry.\nEither way they are responsible for where their business goes.\n\npermalinkembedsaveparentgive award[\u2013]Refefer 11 points12 points13 points 8 months ago\u00a0(7 children)I tend to disagree with this premise.  Kaggle is not real life: the overt goal is rarely to maximize\/minimize some metric at the expense of all other things such as complexity, productionization, etc.  Most problems are, in fact, simple and can be solved with simple models which is where automl is very successful.\n\npermalinkembedsaveparentgive award[\u2013]killver 7 points8 points9 points 8 months ago\u00a0(6 children)And you think AutoML produces \"simple\" model structures? If you want simple you can just go for linear regression.\n\npermalinkembedsaveparentgive award[\u2013]Refefer 4 points5 points6 points 8 months ago\u00a0(5 children)They generally do, yes.  Most Automl solutions are searches over simple models such as GLMs that have hp tuning and some feature selection.  Folks often forget that Google basically stole the term AutoML to push their deep learning initiatives and crazy network searches and thus has become synonymous with complexity, whereas the field of AutoML is actually quite a bit larger (though not that much older). I'd recommend reading some of the actual papers on libraries like auto-sklearn to provide a bit more context if you haven't already.\n\npermalinkembedsaveparentgive award[\u2013]killver 0 points1 point2 points 8 months ago\u00a0(4 children)I have already used auto-sklearn. Any recommendations for good papers in the field? As said, I have not seen any application that results in \"simple\" models with good accuracy. Also curious if you know of some applications where it really worked.\n\npermalinkembedsaveparentgive award[\u2013]Refefer 1 point2 points3 points 8 months ago*\u00a0(3 children)Edit: Let me dig up some stuff for you.\n\"Efficient and Robust Automated Machine Learning\" from nips 2015 would probably serve as good background for problem setup.\nHere is an updated paper from icml 2018: https:\/\/ml.informatik.uni-freiburg.de\/papers\/18-AUTOML-AutoChallenge.pdf\nhttp:\/\/automl.chalearn.org is a great place for tracking current SOTA in Automl (last one was nips 2018)\n\npermalinkembedsaveparentgive award[\u2013]killver 2 points3 points4 points 8 months ago\u00a0(2 children)I just don't like black boxes where I have little control over what is happening. To me it is just some hyperparameter tuning with Bayesian optimization or genetic programming. As said I have tried it a few times, results were usually lackluster and runtimes long.\n\npermalinkembedsaveparentgive award[\u2013]Refefer 0 points1 point2 points 8 months ago\u00a0(1 child)Sure, I understand.  What you're feeling is incredibly common.  I fight this battle all the time in the data science community and at my daily job.\n\npermalinkembedsaveparentgive award[\u2013]killver 0 points1 point2 points 8 months ago\u00a0(0 children)It's a bit different though. I also encounter this regularly that business units do not trust the AI predictions, but what I am referring to more is that I as a data scientist have more trust in algos that I design and understand. But yeah, it's kinda a mixture from both ends. Thanks for the links, will look into it.\n\npermalinkembedsaveparentgive award[\u2013]seanv507 2 points3 points4 points 8 months ago\u00a0(3 children)I think kaggle competitions is precisely what could be one with an algorithm. If you look at the winning solutions it really is run lots of models and then ensemble the results \ud83d\ude00\n\npermalinkembedsaveparentgive award[\u2013]killver 4 points5 points6 points 8 months ago\u00a0(2 children)You need always something clever though to win.\n\npermalinkembedsaveparentgive award[\u2013]nikitau 0 points1 point2 points 8 months ago\u00a0(1 child)Yeah, but creme-de-la-creme SOTA performance is probably not needed most of the time. Those usually go beyond the breakeven point as far as man-hours are concerned for most companies.\n\npermalinkembedsaveparentgive award[\u2013]killver 0 points1 point2 points 8 months ago\u00a0(0 children)I agree on that.\n\npermalinkembedsaveparentgive award[\u2013]addys 24 points25 points26 points 8 months ago\u00a0(1 child)The level of abstraction is increasing, with more and more of the \"grunt\" work being automated.   But the productivity is also rising.   \nA similar thing occurred with statistics and \"number crunching\" when spreadsheets arrived - what was once a career-making study became a one-weekend assignment for an intern.  (such as the famous fish oil study91658-8\/fulltext) from the 70s).  I don't think anyone would argue that statisticians disappeared, but their jobs certainly did \"undergo radical change with automated software\", all for the better....\n\npermalinkembedsavegive award[\u2013]Refefer 1 point2 points3 points 8 months ago\u00a0(0 children)I also made the connection to spreadsheets and fully agree.  The nature of the job will change as well as the number of practitioners, but it will largely be in the form of doing \"more with less\"\n\npermalinkembedsaveparentgive award[\u2013]MLTyrunt 19 points20 points21 points 8 months ago*\u00a0(1 child)The less domain knowledge is needed to engineer valid, strong features, the higher the chance of automation. Think of computer vision, speech, and text mining (for some general corpora and tasks).\nThe more domain specific and more important checking data quality (beyond trivial stuff), the lower the chance of automation. So  yes, I think some things will be automated, whilst other, where the problem is not so standardized, the  need for a data scientist will remain for a while.\nMore practically speaking, I think the demand for data science savy professionals will not  peak for quite some time. The need for a specialist, predictive analytics-data scientist will however peak due to these incremental successes in automation, in maybe  5 or 10 years. The data savy domain specialists will then take over again, which quite frankly, will properly quite often be former specialist data scientists being busy in one area over a longer time. And no: a phd in neural networks implies no long term job security, at all. Data science, for automatable standardized problems, will become a software engineering subfield. When the strong research \/eda and domain knowledge component is an integral necessity to build the model, it will become a skill of the data savy domain specialist. \nManaging and creating self-learning AI systems, as reinforcement learning based ones, may however also be a technical specialists field for quite some time. This is part due to the state of usability in the tooling now, but also because they require the user to think of the design problem more like an educated engineer.\n\npermalinkembedsavegive award[\u2013]Code_star 0 points1 point2 points 8 months ago\u00a0(0 children)Damn I need to rethink my PhD then if no one needs an expert in neural networks\n\npermalinkembedsaveparentgive award[\u2013]scottishbee 16 points17 points18 points 8 months ago\u00a0(0 children)I don't 100% agree with the article, but directionally I do see a shift coming.  \n\u200b\nWill an experienced data scientist always beat a standardized tool?  Sure.  But if the tool can get to 80% of the value at 20% of the cost, it'll open up a lot of problems to \"easy\" ML solutions.  For example, a company I used to work for wanted to build a document classification product.  There were two separate work streams: in one a data scientist went to work iterating on models, starting with simple TF-IDF and getting up to image classification and neural nets.  In the other, engineers just threw documents against Google Cloud OCR to generate text, and then text and manual labels into AWS ML for bag-of-words classification.  The data scientist ended up making the better model...9 months later.  So for the main product, the team just used the out of the box solution, built the rest of the product (UX, labeling team, sales team, etc) and then swapped in the better model to go from 90 -> 95% accuracy.  Not every company is going to be able to hire a data scientist and wait almost a year for them to produce.\n\u200b\nI think the change is going to be very much like running servers or even databases.  In the \"old\" days, every company needed to own and maintain servers.  Every company needed database experts to set up, manage, and run queries.  Map\/reduce was custom built at many places.  Now, no one does that except the infra companies (AWS, MS, Google, Oracle, Snowflake, etc).  For 99% of the rest of us, that's a commodity and not a differentiator in our business.   \n\u200b\nTech is littered with careers of people who though their field was \"too complex\" to be automated.  I think in ~10 years there will be about the same number Machine Learning jobs as today, but 1000x more ML implementations.  The only ones left doing this full time will be hard score specialists researching advances, the actual implementation will be through standardized packages that regular back-end engineers will be expected to set up.\n\npermalinkembedsavegive award[\u2013]Screye 13 points14 points15 points 8 months ago\u00a0(5 children)It is the same argument that I heard when Wordpress websites would put web developers out of the job.\nSuch automated solutions will always be inferior to whatever the less mature, but better recent solution is. \nData Science is 10% algorithms, and the other 90% is everything around it. Data collection, Data set preparation, balancing biases, interpreting results and a lot more.\nI do think that low skilled jobs are going to get automated increasingly in every field, across the board, in the next few decades.\nThis will apply to the lowest skill data science and software jobs too. But overall, the field should be fine. If anything, it would be doing great.\n\npermalinkembedsavegive award[\u2013]bhindblueyes430 3 points4 points5 points 8 months ago\u00a0(0 children)10% algorithms but Data Scientists sell themselves like it\u2019s 75% of their effort and value. \n\npermalinkembedsaveparentgive award[\u2013]flextrek_whipsnake 1 point2 points3 points 8 months ago\u00a0(3 children)10% is pushing it lol, at least in my experience.\n\npermalinkembedsaveparentgive award[\u2013]Screye -1 points0 points1 point 8 months ago\u00a0(2 children)ofc, I am exaggerating. The point itself stands tho.\n\npermalinkembedsaveparentgive award[\u2013]flextrek_whipsnake 2 points3 points4 points 8 months ago\u00a0(1 child)No, I mean your number should be lower than 10%, not higher.\n\npermalinkembedsaveparentgive award[\u2013]Screye 0 points1 point2 points 8 months ago\u00a0(0 children):| \nlol. Don't even know what to say to that.\n\npermalinkembedsaveparentgive award[\u2013]wolfpack_charlie 11 points12 points13 points 8 months ago\u00a0(0 children)Didn't people say the same thing about web developer jobs in response to languages and libraries like javascript? \nSeems like better accessibility only bolstered that job market, if anything\n\npermalinkembedsavegive award[\u2013]Gabe_Isko 9 points10 points11 points 8 months ago\u00a0(0 children)A data scientists job is less about applying matches to data, and more about communicating what the results of algorithms and maths mean when applied to a direct set of data. That is why everyone stresses a background knowledge of statistics - you can feed a bunch data into a neural net and get an answer but you get it I what are ultimately probabilistic terms.\nPeople are always predicting the death of coders and engineering due to automation, but I really disagree with that. If we create more valuable and powerful methods of automating data calculations, then a fundamental understanding of what is going on will be much more valuable and in demand. Even if the day to day work looks completely different.\n\npermalinkembedsavegive award[\u2013]seraschka 7 points8 points9 points 8 months ago\u00a0(0 children)This is B\/S. We developed statistics software in the last century and yet it hasn't replaced statisticians. We have developed machine learning to automatically derive knowledge from data and yet we haven't replaced data analysts ...\n\npermalinkembedsavegive award[\u2013]random_forester 7 points8 points9 points 8 months ago\u00a0(0 children)I don't anticipate any radical change, at least in the next 5 to 10 years. I do anticipate some gradual changes.\nThe radical change will be self-improving algorithms. And it'll be abrupt - once you have the ball rolling, software will keep improving by itself, with no human interaction. I have not seen much work being done in this direction.\n\npermalinkembedsavegive award[\u2013]donuon 6 points7 points8 points 8 months ago\u00a0(0 children)At the end of the day business lines only care about making the best possible decision given the information available. The trade off will be on how much are they paying a resource per increase in predictive performance and how much profit does it drive. It will be much harder to automate top notch data scientists in areas where large profits can be driven off small increases in predictive performance. The smaller that gap is the less incentive there is to pay for top data science talent when a developer for much cheaper could just run the data through an autoML stack and give the business line information that is \"good enough\" to make a profitable business decision. I don't think the radical shift is going to come from automation, its going to come when business lines realize they don't need cutting edge to improve their operations.\n\npermalinkembedsavegive award[\u2013]newjeison 5 points6 points7 points 8 months ago\u00a0(3 children)I'm fairly new to machine learning.  Can someone explain to me the difference between a machine learning engineer and a data scientist? I see the terms get thrown around a lot and assume that people use them interchangeably.\nedit: fixed typo\n\npermalinkembedsavegive award[\u2013]gamerx88 2 points3 points4 points 8 months ago*\u00a0(0 children)Both are very overloaded terms but I'll give you my best shot as a data scientist with experience in the military industrial complex and now the financial industry.\nML engineers are basically software engineers who have some knowledge of ML algorithms and libraries. Primarily they deal with integrating models from researchers\/data scientists into production systems.\nData scientists are basically the people who come up with the solution or models for some business problems. And no,we do not necessarily come up with novel algorithms in our work. That sounds more like fundamental research which is usually done by researchers. Most data scientists that I know (including myself) are basically doing applied research, i.e we make use of those algorithms you see in your textbooks and papers to try to solve real world business problems. This is the core work for us, and not things like coming up with novel algorithms that can be published to NIPS, ICML, KDD, etc. \nFrom time to time we do need to make incremental changes to existing algorithms to get them to work well on real world problems, and sometimes these are worthy and do get published at top conferences, but that's usually not the main priority. \n\npermalinkembedsaveparentgive award[+]brereddit comment score below threshold-6 points-5 points-4 points 8 months ago\u00a0(0 children)They tend to be the same person but some ML engineers don\u2019t have PHD\u2019s in data science. \n\npermalinkembedsaveparentgive award[\u2013]hadaev 3 points4 points5 points 8 months ago\u00a0(0 children)Maybe, but cant we say same for all other jobs?\n\npermalinkembedsavegive award[\u2013]c0cky_ 3 points4 points5 points 8 months ago\u00a0(0 children)I think that with any major advances in technology it's not X being replaced by technology. It's X being complimented by technology. In many cases where society has predicted that humans will be completely removed from the equation they still exist at that current role but are augmented with advanced technology.\n\u200b\nA good example of this is the automotive industry where (yes many jobs have been cut) but there are still humans working on the assembly line. Even with the most recent production issues at Tesla it's because in Elon's words \"the process was too automated\" which resulted in faulty engineering constraints.\n\npermalinkembedsavegive award[\u2013]remimorin 4 points5 points6 points 8 months ago\u00a0(0 children)Software developer (not data scientist) here. This kind of thing is like saying \"web developer will disappear with WordPress because anyone can now do a website\".  \nAlthough it's true anyone can now do a 2008 like website we now expect more.  \nAutomating data science... Maybe but this will be tools for the data scientist to do better, for more usage. I would not sweat a second. Software have automated and open-sourced more than ever and they need us more than ever to use it.\n\npermalinkembedsavegive award[\u2013]TexasWes1212 2 points3 points4 points 8 months ago\u00a0(0 children)If you work in a regulated industry (like Financial Services), until the automated solution can explain every step of the building process to an auditor - you are safe.  \n\npermalinkembedsavegive award[\u2013]dbspeakers 3 points4 points5 points 8 months ago\u00a0(0 children)Automation is already here... If you use any of the premade models in keras for classification, you've \"automated\" part of your job.  Look for frameworks and auto ml to do more lifting on training models, but there will always be an engineering need to define the problem and understand the data and how he relates to the problem.\nI personally think the role will be filled more by software developers than specialized data scientists.  It's less work to get good production code from a developer cross trained into data science than the other way around.  Of course, I feel that most of the code I see in data science isn't very good, but I work at a company that is all about clean code and test driving.\n\npermalinkembedsavegive award[\u2013]ucbmckee 16 points17 points18 points 8 months ago\u00a0(1 child)It's already happening. Many companies now hire 'clever' engineers who can use off the shelf libraries and tools instead of mathematicians or pure scientists who often can't code or engineer well and create significant production delays. Most use cases for machine learning are fairly standard. It's not about  getting the best possible results, it's getting within 80% with 20% of the effort, certainly at first. If I were building a \"DS\" team today, which I am, I'd skew far more toward engineers than five years ago.\n\npermalinkembedsavegive award[\u2013]bhindblueyes430 6 points7 points8 points 8 months ago\u00a0(0 children)This. I\u2019ve helped interns be more productive than PHD\u2019s just by focusing on solutions and not getting lost in the \u201cscience\u201d weeds\n\npermalinkembedsaveparentgive award[\u2013]leviathanxs 2 points3 points4 points 8 months ago\u00a0(0 children)It can take days for a manager to even be able to express which problem they want to solve when they say they want X. I don't think an AI will be able to figure out what managers want to verify... You need data scientists to translate managers desires into specific concrete problems that can be framed into a math equation and then there is the whole data cleaning and interpretation issue that others have mentioned. Dumb AI can only automatize the model training\/fitting and some of the model selection, not the job of a data scientist.\n\npermalinkembedsavegive award[\u2013]torpedoshit 2 points3 points4 points 8 months ago\u00a0(0 children)Yes, most likely. What took a PhD to do 5 years ago is a high school project now. Frameworks, libraries, and open datasets will make things easier and faster with time. \nThere will be a need for human workers for the foreseeable future, but the numbers will continue to fall. Science is no exception.\n\npermalinkembedsavegive award[\u2013]FullSharkAlligator 1 point2 points3 points 8 months ago\u00a0(0 children)Data scientists will be more like technicians using automated tools properly instead of having to do a lot of things from scratch\n\npermalinkembedsavegive award[\u2013]codeslingingslave 1 point2 points3 points 8 months ago\u00a0(0 children)I think the future of work for machine learning practitioners will quickly separate into two groups: a very small and elite group that performs research and a much larger groups that use AutoML but whose jobs also deal more with data preparation (which gets automated also) and ML devops, supporting models in production.\n\npermalinkembedsavegive award[\u2013]bobbruno 1 point2 points3 points 8 months ago\u00a0(0 children)The way I see it, the bar for newcomers will be higher. Just knowing how to run models won't create more value than autoML (especially when considering time to value). Basic data cleaning can also be automated.\nWhat is nowhere near to be automated is:\n1) Framing a business item as an optimization problem. AutoML has nothing so far before this happens. \n2) Knowing how to design a proper experiment. No autoML here either. \n3) Setting up such experiment. Same as above. \n4) Preparing and cleaning data in a way suitable for the problem. General filling nulls and discarding outliers is easy, handling those and creating good features is not. \n5) Knowing what to do after you get the autoML result to have an edge over everyone else who can also get the autoML result. And this is what gives companies the advantage. \n6) Having\/coming up with the right data to apply ML. Sometimes it's about finding the source, sometimes it's about creating the source. Mostly it's about getting creative with the data you have and how you frame the problem, and autoML doesn't help you here. \n4 can reap somebenefits from deep learning, but figuring out what the right kind of network to build is still very much an open research thing. Copying architectures or using pretrained models does not give you an edge over competition. #6 can benefit a bit from DL, too - but it becomes  really hard if you just throw raw data there and hope something comes out after running long enough.\nSo, I see DS being replaced with autoML in non - core areas, where companies just want to not fall behind. That means juniors will have less opportunities. Companies will try to blindly apply autoML to core problems (especially if they don't understand why it does not work), and they will fail. That can either create jobs for skilled data scientists or it can create disappointment and canceled initiatives. I think it will be a bit of both. \n\npermalinkembedsavegive award[\u2013]lightofaman 1 point2 points3 points 8 months ago\u00a0(0 children)I tend to agree with you. Being a data sci demands a bunch of effort and analysis, which I believe cannot be automated\n\npermalinkembedsavegive award[\u2013]caedin8 5 points6 points7 points 8 months ago\u00a0(16 children)I think most of the people in here are living in a bubble.\nThis has already happened. My company licenses  an autoML solution and it produces better models than our data scientists in about 10 minutes.\nThere is still plenty of work around feature engineering, cleansing, deploying, and testing but the actual data science specialization isn\u2019t really needed as much going forward. Our software engineers can do it.\nI\u2019m training my currently employed data scientists to learn a full suite of software engineering skills along side their job to increase their probability of staying around.\nCutting edge and research will of course need specialists, but that\u2019s not what most companies do \n\npermalinkembedsavegive award[\u2013]Screye 13 points14 points15 points 8 months ago\u00a0(1 child)\nMy company licenses an autoML solution and it produces better models than our data scientists in about 10 minutes.\n\nMaybe your team needs to hire better data scientist.\nYMMV, but time series data in the non-NLP domain is one of the harder tasks in ML. Constructing a well informed domain specific PGM or finding a good graph structure for your LSTM make massive differences to the quality of a time series ML model.\nI can't imagine an auto-ML model out-performing either. If your Data Scientists were just cycling through every algo in sk-learn then I can see how Auto-ML can outperform them.\nTalking machines has a great podcast with Claudia Perlich - NYU\/2Sigma about how a lot of problems can be solved by just simply using Logistic Regression.\nBut, the amount of time that they spend with preparing the data, feature engineering and deciding how to stage it makes for an extremely interesting Data Science problem. Just because the model isn't interesting, doesn't make it an easy or uninteresting Data Science problem.\n\npermalinkembedsaveparentgive award[\u2013]azraelxii 0 points1 point2 points 8 months ago\u00a0(0 children)H20.ai has timeseries in driverless ai\n\npermalinkembedsaveparentgive award[\u2013][deleted] 5 points6 points7 points 8 months ago\u00a0(2 children)\u201cThis has already happened. My company licenses  an autoML solution and it produces better models than our data scientists in about 10 minutes.\u201d\nWhat\u2019s the context of these solutions? Is this AutoML being used on \u201ceasy\u201d datasets (e.g. excel dataframe with response data) or is it being used on more challenging datatype problems that deal with image recognition or language sequence prediction? \n\npermalinkembedsaveparent[\u2013]caedin8 8 points9 points10 points 8 months ago\u00a0(1 child)Our use cases vary, but most common is time series based problems.\nPredicting demand, supply, prices, trends. We have a few production applications that determine some sort of classification. For example, based on the load shape for a customer determine if they use gas or electric heating. \nWe also have some clustering work with saying \u201cis new customer x most like which segment of the customers we already serve?\u201d\nWe have some models based on customer turn over, \u201chow likely is this particular customer to leave us in x months if we let his contract roll over to market prices\u201d\nWe have very few image and language prediction problems, but we do use NLP as features to the above problems and the autoML is much better than our resident data scientists at handling these features (n gram and covariance and collocations  are determined automatically and fed into the model)\nSome of our upcoming work for image analysis involves maintenance for energy producing assets like solar farms using drone footage. But it\u2019s all in a proof of concept phase. We still manually do the image work as the autoML doesn\u2019t support image processing yet, but they plan on adding it soon.\n\npermalinkembedsaveparentgive award[\u2013]alexmlamb 0 points1 point2 points 8 months ago\u00a0(0 children)Are the solutions that you're using built around generic AI types of problems like time series prediction, regression, classification, etc. - or are they designed around specific applications like customer turn-over prediction, demand forecasting, price forecasting, etc?  \nIf their solutions are built around specific types of problems, then I could see this working.  Otherwise I'd be concerned that you're just assuming your problem is a classification\/regression problem, when the nature of the actual problem is more subtle (which has been the case for every problem I've seen in industry, including all of the problems that you mentioned).  \n\npermalinkembedsaveparentgive award[\u2013]MrTwiggy 3 points4 points5 points 8 months ago\u00a0(9 children)> There is still plenty of work around feature engineering, cleansing, deploying, and testing but the actual data science specialization isn\u2019t really needed as much going forward.  \nWhat exactly do you consider to be part of the data science specialization if not feature engineering, cleansing, deploying\/validating\/monitoring\/testing? Data science isn't exclusively about running experiments with different models and picking the highest scoring ones. Someone has to formulate the problem, engineer the features, define the training\/validation\/test objectives & methodologies so they align with the business goal, develop a solution for monitoring\/maintaining\/testing the product after deployment, etc.\n\u200b\nSure, you can try and take a software engineer and stick an autoML solution in his hands, but I doubt he will be able to reliably accomplish the above without the experience and knowledge of a data scientist.\n\npermalinkembedsaveparentgive award[\u2013]caedin8 1 point2 points3 points 8 months ago\u00a0(8 children)I disagree. It takes a smart software engineer about a month to learn all of the best practices around building machine learning products.\nIt takes a data scientist about a year to learn all of the best practices and skills around building successful software. It\u2019s just easier to train our software engineers to do data science work than it is to train our data scientists to do software engineering most of the time.\nBecause the autoML does most of the hard work (chunking up data into different validation and train sets, runs hundreds of models and hyper parameters, surfaces good quality metrics about which models do well and which don\u2019t, provides an easy deployment framework and provides alerts monitoring and model drift metrics for deployed solutions) there is literally nothing the software engineer needs to do that he can\u2019t figure out in a trivial amount of time.\n\npermalinkembedsaveparentgive award[\u2013]BeneficialArcher 6 points7 points8 points 8 months ago\u00a0(4 children)\nBecause the autoML does most of the hard work (chunking up data into  different validation and train sets, runs hundreds of models and hyper  parameters, surfaces good quality metrics about which models do well and  which don\u2019t, provides an easy deployment framework and provides alerts  monitoring and model drift metrics for deployed solutions)\n\nI don't know about your company in particular, but at the places I've worked at this is the easy stuff and data scientists spend very little time doing it. Stuff like training hyperparameters has been feasible to automate since the 1990s (you don't need advanced software to do this, a place I worked at just wrote a python program to try every scikit learn classifier\/tune hyperparameters with validation sets).\nI've discussed this in a comment elsewhere, but data scientists where I've worked spent much more of their time interpreting results, doing feature engineering, working out how to deal with messy data, working out what data to use etc, and as far I know there's no software that's anywhere near being able to do this. If this stuff is what your software engineers do, then I'm pretty sure that what they're doing is what most other companies call data science.\n\npermalinkembedsaveparentgive award[\u2013]caedin8 6 points7 points8 points 8 months ago\u00a0(3 children)We use DataRobot. Created by a swath of top kagglers. \nIt costs about the same as one full time data scientist but it is much more valuable. The entire team is more productive, and yes it does a decent job at most of those tasks you listed, and does them better than our DS would.\n\npermalinkembedsaveparentgive award[\u2013]BeneficialArcher 2 points3 points4 points 8 months ago\u00a0(2 children)Based off of this:\n\nWe use DataRobot.  \n\nAnd this reply to made to someone else:\n\nYou are also forgetting that software engineers require a heavy math background and are well versed in statistical and probability theory.\n\nI'm pretty sure now that the people working at your company that you call software engineers are what most companies call data scientists (the stuff that datarobot does is exactly the kind of stuff that our data scientists have already automated). In that case we're actually in agreement in that the kind of people who have the title \"software engineer\" at your company are unlikely to be automated soon. \n\u200b\n\u200b\n\npermalinkembedsaveparentgive award[\u2013][deleted] 8 months ago\u00a0(1 child)[deleted]\n\n[\u2013]BeneficialArcher 0 points1 point2 points 8 months ago\u00a0(0 children)At the company I worked at where we built\/used quite a large number of automated ML tools, I generally found that the tools helped people get stuff done more quickly, but didn't help them correctly do anything that they couldn't already do (more slowly) without these tools. i.e. they didn't let the people at our company who didn't know much about math\/stats do some of the complicated stuff that needed advanced stats knowledge.\nOne thing we found though was that the tools often let our data analysts get into the \"danger zone\" without realizing it. i.e. they'd get some data, feed it into the computer, and the computer would dutifully process the input (regardless of what it was) and output some nice numbers, but on closer inspection they'd often made very basic statistical mistakes that invalidated all their results (e.g. p-value hacking).\nIt's hard for me to make any specific comment on your BI analysts since I don't know exactly how much math\/stats they know.\n\npermalinkembedsavegive award[\u2013]Zankoqt 6 points7 points8 points 8 months ago\u00a0(2 children)You make it sound like all statistical reasoning ever can be learned in a month by a SE. \n\npermalinkembedsaveparentgive award[\u2013]caedin8 2 points3 points4 points 8 months ago\u00a0(1 child)No, just saying that all the hard work on statistical reasoning is automated. They really need to just learn what the metrics mean and how they are calculated.\nYou are also forgetting that software engineers require a heavy math background and are well versed in statistical and probability theory.\nThey may have never used ROC AUC before but they\u2019ll know it tomorrow if you ask them to go figure it out. They have the background.\n\npermalinkembedsaveparentgive award[\u2013]Zankoqt 1 point2 points3 points 8 months ago\u00a0(0 children)Interpreting ROCAUC is a thing, understanding the role of ties in data while doing survival analysis (just to give an easy but not trivial example) is another in my experience. It's an easy thing to understand if someone says to you that it's a problem but it's not the first thing that come to mind to a SE.\nIn my albeit limited industry experience (we teach and do some prototypical work for companies in fields like data science, optimization, CFD and automation) I've found way harder to teach SE of some intricacies of statistical reasoning than say functional programming to data scientists. And statistical failures are, usually, harder to spot, so I had quite a few example of software people thinking everything it's fine while the models they deployed or the data they were collecting was not. But ofc it's really anecdotal.\nI would really love to teach to a bunch of SEs so gifted that they get at the first try everything from the exponential family in MLE to bayesian non parametrics :) I'm jealous!\n\npermalinkembedsaveparentgive award[\u2013]ednaiss 0 points1 point2 points 8 months ago\u00a0(0 children)Can you share what AutoML platform worked for you? or suggest what good AutoML platforms are out there? Thanks\n\npermalinkembedsaveparentgive award[\u2013]nxpnsv 0 points1 point2 points 8 months ago\u00a0(0 children)In my experience, stating the problem then formulating an objective function that solves the problem and finding relevant data is not easily automated... nor is presenting a relevant interpretation of the results. ML just a small part of DS, but even the ML part is hard to automate, perhaps for simple problems...\n\npermalinkembedsavegive award[\u2013]vzq 0 points1 point2 points 8 months ago*\u00a0(2 children)Considering like 80% is data massaging, I seriously doubt it. \n\npermalinkembedsavegive award[\u2013]NaBrO-Barium 4 points5 points6 points 8 months ago\u00a0(1 child)Date massaging, this guy gets it.\n\npermalinkembedsaveparentgive award[\u2013]vzq 0 points1 point2 points 8 months ago\u00a0(0 children)Lol thanks, awkward typo. \n\npermalinkembedsaveparentgive award[\u2013]uber_neutrino 0 points1 point2 points 8 months ago\u00a0(0 children)Machine learning is a new tool.  If anything the number of people employed in this area will go up, possibly a lot, to use this new tool.\n\npermalinkembedsavegive award[\u2013]Thalesian 0 points1 point2 points 8 months ago\u00a0(0 children)If machine learning reaches the level where it can automate the coding process, then the revolutions in the economy at that point will be much larger than the concern for data scientists posited here. \n\npermalinkembedsavegive award[\u2013]oarabbus 0 points1 point2 points 8 months ago\u00a0(0 children)As a data analyst\/scientist one of the most important things is to understand the nature of the tables\/data model. Is this a snapshot\/fact table? Does it hold only the most recent status?  I think it will be quite some time until AI can actually understand your data model and write SQL queries, do feature engineering, etc for you.\n\npermalinkembedsavegive award[\u2013]Ikuyas 0 points1 point2 points 8 months ago\u00a0(0 children)You would still need to learn software development while doing the data science things. But if you are already in the industry,  it will be a lot easier to have many software engineer people\/experts around you anyway. You just need to learn how to make API and so on. Right now the data scientists just make a report.\n\npermalinkembedsavegive award[\u2013]ditomax 0 points1 point2 points 8 months ago\u00a0(0 children)Possibly depends on the domain. In some domains AutoML like solutions will soon dominate. That is simply the way we develop our technology. But abstraction over abstraction...\n\npermalinkembedsavegive award[\u2013]ProfessorPhi 0 points1 point2 points 8 months ago\u00a0(0 children)I think data science roles won't be automated, but as productivity goes up with autoML, you'll find far smaller DS teams required. There'll be no place for average data scientists in the next few years and DS teams will become more software focussed with technical and mathy leads.\n\npermalinkembedsavegive award[\u2013]kivo360 0 points1 point2 points 8 months ago\u00a0(0 children)Use a little creativity and you'll find that any job can be automated. In fact, will probably be automated. \n\npermalinkembedsavegive award[\u2013]azraelxii 0 points1 point2 points 8 months ago\u00a0(0 children)Disagree for a few different reasons. Main reason being that issues at least where I work are getting the model engineered, deployed, and well specified from users. So sure you can automatically generated the algorithm but all the work is in explaining it, documenting it, proving it works, and getting into use. Then on top of that you need to have ways to automatically test it in prod and retrain. \nSince systems and requirements change all the time these problems are evergreen.\nAutomated software at best simply reduces demand for data scientists but since their developers know this they charge a rather large amount. The decision to have 5 data scientists or 2 and a automated licence are going to depend on a lot of things- it's not a either or.\n\npermalinkembedsavegive award[\u2013]Captain_Flashheart 0 points1 point2 points 8 months ago\u00a0(0 children)Yes and no. Yes, you can definitely automate some of it, and yes - a good part of DS jobs now can be moved to analytics developers. Which is not a new problem, seeing it gets mentioned here a lot as well as on r\/datascience. \nBut no, these are still small ideas, and to see industry-wide adaption of highly efficient automation tools for ML it will take a couple of years more. It's not going to come from a start-up either. Google, MS, or the like - perhaps one of the old companies like IBM as well, will commercialize it with a second-to-market. \nThe core of the article forgets one thing. Machine power still takes time and money. Honestly - the limiting factor for a lot of our work, and I'm sure people here will agree - is computing time. Analyzing a problem and defining an approach does not take a lot of time in the grand process. \n\npermalinkembedsavegive award[\u2013]victor_knight 0 points1 point2 points 8 months ago\u00a0(0 children)Partially agreed. However, I also believe human plumbers will still be around for centuries.\n\npermalinkembedsavegive award[\u2013]Jollyhrothgar 0 points1 point2 points 8 months ago\u00a0(0 children)Tech jobs will always be undergoing radical change. Data science as a field, like all fields, will put the human where they do the most good. We have to adapt and change, or risk irrelevance.\n\npermalinkembedsavegive award[\u2013]nnexx_ 0 points1 point2 points 8 months ago\u00a0(0 children)If you think autoML is going to replace your job as a DS, you are doing it wrong. A DS is much much more than fitting and hyper parameter tuning...\n\npermalinkembedsavegive award[\u2013]fiddlewin 0 points1 point2 points 8 months ago\u00a0(0 children)To some extent, I agree with the original article but not your comment about autoML.\nNone of the current autoML tools works very well to the point that someone without a deep understanding of ML can simply build a model by clicking some buttons, and I don't think they ever will. The autoML tools would only help someone who knows ML to quickly bootstrap a model and manullay finetune later.\nBut I do agree the emerging mature libraries on all kinds of common ML tasks will eliminate  some of the needs for really hard-core math and stats people. That being said, you do need someone who understand the models rather than those who only completed MOOC courses. This is similar to the case of software developers, where you would have all the modern frameworks like angular and react, which some beginners can pick up by completing a one week online course, but you still need senior devs who understand the nifty details and can tune performance and fix problems.\n\u200b\nThis brings me back to the 90s or early 2000s when people were scared that the RAD tools like Delphi and VB would make 'everyone a programmer' and less need for devs. But guess what happened then. :)\n\npermalinkembedsavegive award[\u2013]chinri1 0 points1 point2 points 8 months ago\u00a0(0 children)It depends - a lot of the data science work in the world is the kind where you win just for showing up, because literally no one has ever tried data science or machine learning on X. In most cases there's a huge amount of low-hanging fruit that linear or logistic regressions can pick up on, and an automated system can easily get you that far, or most of the way there. For many business cases that's good enough, and a trained data scientist may not add enough value to justify the cost. However, once the easy fruit is picked, you need someone who knows what they're doing to decide what comes next. This is all assuming you can trust your data.\nThe other side of data science is about finding problems hidden in plain sight. The real science work is about holding your imagination accountable to your statistics, and exercising deep skepticism of anything that looks like signal. There absolutely will be a machine learning tab in Excel some day, but it won't make any difference if nobody understands that e. g. sometimes artifacts generalize just as well as signal, or that there is no single right way to fill in missing data.\nI think the part that this article gets right is that the field of \"data science\" won't go away, but it will be replaced by sub-specializations, just as \"computer science\" broke into programming languages, operating systems, networks, theory, databases, and computer vision \/ machine learning.\n\npermalinkembedsavegive award[\u2013]Retrodeathrow 0 points1 point2 points 8 months ago\u00a0(0 children)I call BS. Its a puff piece about how one day AI will be intuitive.\n\npermalinkembedsavegive award[\u2013]mimighost -1 points0 points1 point 8 months ago\u00a0(0 children)There is, IMO, a much better article about this topic, as linked below:\nhttps:\/\/veekaybee.github.io\/2019\/02\/13\/data-science-is-different\/\nHere is my observations:\n\nData Scientist is a vaguely defined role as comparing to Software Engineer. Some DS works as data engineers; some works as Data Analyst. Their skill set vary in great degree, so do their responsibility. IMO, it will be less and less useful for company to host a generic Data Science job family, instead it will be replaced with several more focused and clearly defined sub categories. \nThe current data science training offered by either universities or other job training institutions aren't very useful in tackling real world business problem. You can say that is true for almost all professions,  but in case of Data Science, it is particularly severe. The courses are about algorithms\/models\/fancy visualizations, but in reality it is probably more about SQLs\/finding problem in your dataset\/story telling, etc. Simply put, the gap is HUGE. Thus there is now a Junior saturation in this industry.\nBut I don't think people need to panic about job prosperity if you are already under the DS umbrella. There is plenty of chances to further your career, just as those 5 categories this article listed.\n\n\npermalinkembedsavegive award[\u2013]tataiermail -2 points-1 points0 points 8 months ago\u00a0(0 children)Agree\n\npermalinkembedsavegive awardaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 26734 on  r2-app-00adc56719ff32c7b  at 2019-11-18 13:18:04.749216+00:00 running 85b1b7a country code: US."
  },
  "18":{
    "title":"[D] Positional Encoding in Transformer : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-funny-pics-aww-worldnews-gaming-todayilearned-television-gifs-Showerthoughts-Jokes-videos-tifu-mildlyinteresting-TwoXChromosomes-OldSchoolCool-space-creepy-nottheonion-books-movies-personalfinance-LifeProTips-IAmA-explainlikeimfive-dataisbeautiful-Futurology-science-gadgets-askscience-food-sports-nosleep-Music-Art-WritingPrompts-EarthPorn-history-DIY-photoshopbattles-Documentaries-UpliftingNews-GetMotivated-listentothis-philosophy-announcements-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  22 Aug 201918 points (88% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave819,147 readers2,035 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X128  \u00b7 6 comments [N] French BERT (CamemBERT) now available in Transformers library[P] Cortex: Deploy models from any framework as production APIs76  \u00b7 81 comments [D] An Interesting (in my opinion) Observation While Messing With the Full GPT-26 [P] Autopilot in keras for self-driving cars[N] Pre-trained knowledge graph embedding models are available in GraphVite!7 [R] A New Deterministic Technique for Symbolic Regression2 [D] History of NLP: People projected intelligence and humanity onto the world's first chatbot, Eliza[D] For NLP, how to generate cluster labels from cluster ids?103  \u00b7 24 comments [D] Is the inception architecture\/block a failure?2  \u00b7 4 comments [Discussion]System that constantly learnsWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7171819Discussion[D] Positional Encoding in Transformer (self.MachineLearning)submitted 2 months ago * by amil123123Hey all,\nI was reading up the transformer paper https:\/\/arxiv.org\/abs\/1706.03762. This architecture uses positional encoding which the attention layers ignore.\nI don't understand two things -\n\nWhy use Sin & Cos as positional embeddings , why not any other function?\nThey also talk about training these positional embeddings, how do you go about training such embeddings. As in how do you let the model know that these embeddings are for the position\n\nThanks !\n\n15 commentssharesavehidereportall 15 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]mikeross0 9 points10 points11 points 2 months ago\u00a0(6 children)The thing that always gets me with positional embeddings is that it is preferable to add them to the word embeddings instead of concatenating them. We already know the dimensions of the word embeddings are related to semantics. So why embed position into the semantic space instead of adding additional dimensions to represent position? If someone can provide a good intuitive explanation for that, you will get all my internet points for the day!\n\npermalinkembedsavereportgive awardreply[\u2013]pappypapaya 12 points13 points14 points 2 months ago*\u00a0(2 children)In attention, we basically take two word embeddings (x and y), pass one through a Query transformation matrix (Q) and the second through a Key transformation matrix (K), and compare how similar the resulting query and key vectors are by their dot product. So, basically, we want the dot product between Qx and Ky, which we write as:\n(Qx)'(Ky) = x' (Q'Ky). So equivalently we just need to learn one joint Query-Key transformation (Q'K) that transform the secondary inputs y into a new space in which we can compare x.\nBy adding positional encodings e and f to x and y, respectively, we essentially change the dot product to\n(Q(x+e))' (K(y+f)) = (Qx+Qe)' (Ky+Kf) = (Qx)' Ky + (Qx)' Kf + (Qe)' Ky + (Qe)' Kf = x' (Q'Ky) + x' (Q'Kf) + e' (Q'Ky) + e' (Q'K f), where in addition to the original x' (Q'Ky) term, which asks the question \"how much attention should we pay to word x given word y\", we also have x' (Q'Kf) + e' (Q'Ky) + e' (Q'K f), which ask the additional questions, \"how much attention should we pay to word x given the position f of word y\", \"how much attention should we pay to y given the position e of word x\", and \"how much attention should we pay to the position e of word x given the position f of word y\".\nEssentially, the learned transformation matrix Q'K with positional encodings has to do all four of these tasks simultaneously. This is the part that may appear inefficient, since intuitively, there should be a trade-off in the ability of Q'K to do four tasks simultaneously and well.\nHOWEVER, MY GUESS is that there isn't actually a trade-off when we force Q'K to do all four of these tasks, because of some approximate orthogonality condition that is satisfied of in high dimensions. The intuition for this is that randomly chosen vectors in high dimensions are almost always approximately orthogonal. There's no reason to think that the word vectors and position encoding vectors are related in any way. If the word embeddings form a smaller dimensional subspace and the positional encodings form another smaller dimensional subspace, then perhaps the two subspaces themselves are approximately orthogonal, so presumably these subspaces can be transformed approx. independently through the same learned Q'K transformation (since they basically exist on different axes in high dimensional space). I don't know if this is true, but it seems intuitively possible.\nIf true, this would explain why adding positional encodings, instead of concatenation, is essentially fine. Concatenation would ensure that the positional dimensions are orthogonal to the word dimensions, but my guess is that, because these embedding spaces are so high dimensional, you can get approximate orthogonality for free even when adding, without the costs of concatenation (many more parameters to learn). Adding layers would only help with this, by allowing for nonlinearities.\nWe also ultimately want e and f to behave in some nice ways, so that there's some kind of \"closeness\" in the vector representation with respect to small changes in positions. The sin and cos representation is nice since nearby positions have high similarity in their positional encodings, which may make it easier to learn transformations that \"preserve\" this desired closeness.\n(Maybe I'm wrong, and the approximate orthogonality arises from stacking multiple layers or non-linearities in the fully-connected parts of the transformer).\ntl;dr: It is intuitively possible that, in high dimensions, the word vectors form a smaller dimensional subspace within the full embedding space, and the positional vectors form a different smaller dimensional subspace approximately orthogonal to the one spanned by word vectors. Thus despite vector addition, the two subspaces can be manipulated essentially independently of each other by some single learned transformation. Thus, concatenation doesn't add much, but greatly increases cost in terms of parameters to learn.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]amil123123[S] 0 points1 point2 points 2 months ago\u00a0(0 children)Wow , that's one hell of an amazing explanation :)\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Sinkencronge 1 point2 points3 points 2 months ago\u00a0(0 children)It may have been already done for sure, but I haven't seen any paper about superiority of this approach to cross my scope  yet. \nI assume, in general you would probably don't want to blow up the dimensions of your word embedding even more than it has been already done in current SOTAs.\nOne could take a dataset of utterances like\"Dog ate a cat\", \"Cat ate a dog\" etc. and play around with addition, multiplication, convolution, concatenation and God knows what for the sake of comparison.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Sinkencronge 3 points4 points5 points 2 months ago*\u00a0(3 children)\nTo build up the intuition about it you may want to look how the proposed function and pairwise distance between position-vectors  behave.\n\nhttps:\/\/imgur.com\/kpW5n4p\nhttps:\/\/imgur.com\/kaADdQB\n\nBackpropagation.\n\n\npermalinkembedsavereportgive awardreply[\u2013]amil123123[S] 1 point2 points3 points 2 months ago\u00a0(2 children)Thanks for the response. I still have difficulty understanding about 1.\nSo the first image seems good in explaining the position however what does the second image denote.\nIs it just because this function seemed to work well , that we went with it ?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Sinkencronge 2 points3 points4 points 2 months ago\u00a0(1 child)The second image just shows Euclidean distances between the added embedding for a given position. \nThe thing is that their choice of positional encoding function reflects not only absolute, but also the relative distance among tokens in sequences.\nIn the paper they write:\n\nWe chose this function because we hypothesized it would allow the model to easily learn to attend by relative positions, since for any fixed off set k,PE_pos+k can be represented as a linear function of PE_pos.\n\nUnfortunately, I don't really wave a better way to elaborate it further in my mind at the moment. I'm sorry for that. \n\u200b\nAnswering your question, I personally think that they seem to simply pick up the first elegant solution to solve this problem.\n\u200b\nHowever, I believe that there are a lot of more interesting ways to take advantage of positional encoding trick. I'm currently working on it for my own dataset.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]amil123123[S] 0 points1 point2 points 2 months ago\u00a0(0 children)Thanks for the explanation, it was good !\n\npermalinkembedsaveparentreportgive awardreply[\u2013]InsideAndOut 1 point2 points3 points 2 months ago\u00a0(4 children)\nBecause the distances between the neighboring values of the sine\/cosine positional embeddings are \"nice\" (symmetrical, and decay sensibly with distance). You could come up with another function that does something similar.\nFor trained positional embeddings, you simply have another embedding matrix (one is for words, the other is for positions). For each position (up to `max_length`), you learn an embedding of the same dimension as the word embedding.\n\n\npermalinkembedsavereportgive awardreply[\u2013]amil123123[S] 1 point2 points3 points 2 months ago\u00a0(3 children)Thanks for the response! \nWhat do you mean by symmetrical and decay sensibly ?\n( Sorry , but I am still a newbie in this )\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Sinkencronge 0 points1 point2 points 2 months ago\u00a0(2 children)\"Symmetrical\" - see image 2. \n\"Decay sensibly with distance\" - In this gif you can see entries in the distance matrix which have similar value [https:\/\/imgur.com\/a\/p7NcUm1] \nWhite dots are points (corresponding to different pairwise positions) which lay in some epsilon neighborhood from some threshold tau which changes over time from 0 to maximum distance.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]imguralbumbot 0 points1 point2 points 2 months ago\u00a0(0 children)Hi, I'm a bot for linking direct images of albums with only 1 image\nhttps:\/\/i.imgur.com\/1jwYWbG.gifv\nSource | Why? | Creator | ignoreme | deletthis\n\npermalinkembedsaveparentreportgive awardreply[\u2013]amil123123[S] 0 points1 point2 points 2 months ago\u00a0(0 children)Ahh understood, thanks for the explanation!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]gdiamos 1 point2 points3 points 2 months ago\u00a0(0 children)Papers usually post their final solution, not the path they took to get there.  The sin\/cos positional embeddings often seem unintuitive for this reason.\nI find it helps to try to reconstruct the path.  \n1) Why do transformers need positional embeddings at all?  What would happen if you removed them completely?  Why?  \n2) Why not use simpler and more obvious positional embeddings like literally the position index?\n\npermalinkembedsavereportgive awardreply[\u2013]Jean-Porte 0 points1 point2 points 2 months ago\u00a0(0 children)Regarding to sin and cos representation, my hypothesis is that together, they fully characterize a position\nAlso, the weights that are learned over this input might be analogous to weights of a Fourier transform and have nice theoratical properties but I have seen no formal work on this\n\npermalinkembedsavereportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 15082 on  r2-app-0201aba5cd0b54af7  at 2019-11-18 21:09:28.648649+00:00 running 160a165 country code: US."
  },
  "19":{
    "title":"pappypapaya comments on [D] Positional Encoding in Transformer",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-funny-pics-aww-worldnews-gaming-todayilearned-television-gifs-Showerthoughts-Jokes-videos-tifu-mildlyinteresting-TwoXChromosomes-OldSchoolCool-space-creepy-nottheonion-books-movies-personalfinance-LifeProTips-IAmA-explainlikeimfive-dataisbeautiful-Futurology-science-gadgets-askscience-food-sports-nosleep-Music-Art-WritingPrompts-EarthPorn-history-DIY-photoshopbattles-Documentaries-UpliftingNews-GetMotivated-listentothis-philosophy-announcements-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  22 Aug 201920 points (92% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave819,188 readers2,227 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X135  \u00b7 6 comments [N] French BERT (CamemBERT) now available in Transformers library[P] Cortex: Deploy models from any framework as production APIs72  \u00b7 82 comments [D] An Interesting (in my opinion) Observation While Messing With the Full GPT-25 [N] Pre-trained knowledge graph embedding models are available in GraphVite!6 [P] Autopilot in keras for self-driving cars7 [R] A New Deterministic Technique for Symbolic Regression2  \u00b7 1 comment [D] History of NLP: People projected intelligence and humanity onto the world's first chatbot, Eliza[P] Open source library to perform entity embeddings on categorical variables using Convolutional Neural Networks [+ Unit Tests, Code Coverage and Continuous Integration][D] For NLP, how to generate cluster labels from cluster ids?101  \u00b7 24 comments [D] Is the inception architecture\/block a failure?Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7192021Discussion[D] Positional Encoding in Transformer (self.MachineLearning)submitted 2 months ago * by amil12312315 commentssharesavehidereportloading...sorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an accountyou are viewing a single comment's thread.view the rest of the comments\u00a0\u2192[\u2013]pappypapaya 12 points13 points14 points 2 months ago*\u00a0(2 children)In attention, we basically take two word embeddings (x and y), pass one through a Query transformation matrix (Q) and the second through a Key transformation matrix (K), and compare how similar the resulting query and key vectors are by their dot product. So, basically, we want the dot product between Qx and Ky, which we write as:\n(Qx)'(Ky) = x' (Q'Ky). So equivalently we just need to learn one joint Query-Key transformation (Q'K) that transform the secondary inputs y into a new space in which we can compare x.\nBy adding positional encodings e and f to x and y, respectively, we essentially change the dot product to\n(Q(x+e))' (K(y+f)) = (Qx+Qe)' (Ky+Kf) = (Qx)' Ky + (Qx)' Kf + (Qe)' Ky + (Qe)' Kf = x' (Q'Ky) + x' (Q'Kf) + e' (Q'Ky) + e' (Q'K f), where in addition to the original x' (Q'Ky) term, which asks the question \"how much attention should we pay to word x given word y\", we also have x' (Q'Kf) + e' (Q'Ky) + e' (Q'K f), which ask the additional questions, \"how much attention should we pay to word x given the position f of word y\", \"how much attention should we pay to y given the position e of word x\", and \"how much attention should we pay to the position e of word x given the position f of word y\".\nEssentially, the learned transformation matrix Q'K with positional encodings has to do all four of these tasks simultaneously. This is the part that may appear inefficient, since intuitively, there should be a trade-off in the ability of Q'K to do four tasks simultaneously and well.\nHOWEVER, MY GUESS is that there isn't actually a trade-off when we force Q'K to do all four of these tasks, because of some approximate orthogonality condition that is satisfied of in high dimensions. The intuition for this is that randomly chosen vectors in high dimensions are almost always approximately orthogonal. There's no reason to think that the word vectors and position encoding vectors are related in any way. If the word embeddings form a smaller dimensional subspace and the positional encodings form another smaller dimensional subspace, then perhaps the two subspaces themselves are approximately orthogonal, so presumably these subspaces can be transformed approx. independently through the same learned Q'K transformation (since they basically exist on different axes in high dimensional space). I don't know if this is true, but it seems intuitively possible.\nIf true, this would explain why adding positional encodings, instead of concatenation, is essentially fine. Concatenation would ensure that the positional dimensions are orthogonal to the word dimensions, but my guess is that, because these embedding spaces are so high dimensional, you can get approximate orthogonality for free even when adding, without the costs of concatenation (many more parameters to learn). Adding layers would only help with this, by allowing for nonlinearities.\nWe also ultimately want e and f to behave in some nice ways, so that there's some kind of \"closeness\" in the vector representation with respect to small changes in positions. The sin and cos representation is nice since nearby positions have high similarity in their positional encodings, which may make it easier to learn transformations that \"preserve\" this desired closeness.\n(Maybe I'm wrong, and the approximate orthogonality arises from stacking multiple layers or non-linearities in the fully-connected parts of the transformer).\ntl;dr: It is intuitively possible that, in high dimensions, the word vectors form a smaller dimensional subspace within the full embedding space, and the positional vectors form a different smaller dimensional subspace approximately orthogonal to the one spanned by word vectors. Thus despite vector addition, the two subspaces can be manipulated essentially independently of each other by some single learned transformation. Thus, concatenation doesn't add much, but greatly increases cost in terms of parameters to learn.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]amil123123[S] 0 points1 point2 points 2 months ago\u00a0(0 children)Wow , that's one hell of an amazing explanation :)\n\npermalinkembedsaveparentreportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 11998 on  r2-app-064214287fe441450  at 2019-11-18 21:57:36.385882+00:00 running 160a165 country code: US."
  },
  "20":{
    "title":"What is your opinion : Why is the concept of Renormalization Group Transformation and Phase Transitions not so popular in ML ? : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-funny-pics-aww-worldnews-gaming-todayilearned-television-gifs-Showerthoughts-Jokes-videos-tifu-mildlyinteresting-TwoXChromosomes-OldSchoolCool-space-creepy-nottheonion-books-movies-personalfinance-LifeProTips-IAmA-explainlikeimfive-dataisbeautiful-Futurology-science-gadgets-askscience-food-sports-nosleep-Music-Art-WritingPrompts-EarthPorn-history-DIY-photoshopbattles-Documentaries-UpliftingNews-GetMotivated-listentothis-philosophy-announcements-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  24 Aug 201617 points (79% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave819,551 readers2,394 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X128  \u00b7 5 comments [P] Cortex: Deploy models from any framework as production APIs203  \u00b7 10 comments [N] French BERT (CamemBERT) now available in Transformers library25  \u00b7 1 comment [R] All The Ways You Can Compress BERT11  \u00b7 8 comments [D] Non-Academic Attendance at NeurIPS6  \u00b7 15 comments [D] Machine Learning vs Statistics3  \u00b7 1 comment RandAugment: Practical automated data augmentation with a reduced search space10 [N] Pre-trained knowledge graph embedding models are available in GraphVite!5  \u00b7 4 comments [P] MLP output of first layer is zero after one epoch13  \u00b7 1 comment [P] Autopilot in keras for self-driving cars75  \u00b7 87 comments [D] An Interesting (in my opinion) Observation While Messing With the Full GPT-2Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7161718What is your opinion : Why is the concept of Renormalization Group Transformation and Phase Transitions not so popular in ML ? (self.MachineLearning)submitted 3 years ago by jocomocoThis paper shows a connection (Renormalization Group Transformation) between physics and ML : http:\/\/arxiv.org\/abs\/1410.3831 \nI have post-grad educational background in physics and ML, and I am really fascinated by this connection (between physics and ML). Is it only me ? \nWhat are your opinions about this paper ? \nWhat is your opinion about the idea that phase transitions are important for brain functioning and also for deep learning? \nThis blog post goes into this topic too : https:\/\/charlesmartin14.wordpress.com\/2015\/04\/01\/why-deep-learning-works-ii-the-renormalization-group\/ \nI am kinda surprised that this connection does not get bigger attention. Why not ? I wonder. Opinions ?\n\n15 commentssharesavehidereportall 15 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]NichG 14 points15 points16 points 3 years ago\u00a0(1 child)I'm a soft-condensed-matter physicist who transitioned over into ML. I've worked with algorithms based on insights from RG, and I've worked with people who do analytical RG.\nMy take on RG is that, unfortunately, while it's a great source of insight into thinking about asymptotic behaviors, infinities, emergence, etc - actually doing anything with RG takes a lot of time, a lot of paper, and is extremely hard to automate algorithmically. In particular, figuring out the right way to make secular terms go away and figuring out the right parameterization so that the number of parameters remains bounded as you perform the coarse-graining both seem to just require really good mathematical intuition unique to each case. If you back off from doing full RG and just talk about scaling methods like method of multiple scales or power-counting, its more amenable to automation, but its still a method that requires you to have a prescribed model for your system. \nSo I'd say, its one of those things that's potentially really useful to know about in terms of developing intuitions, but hard to actually directly use to obtain results. \nI've tried to turn some of the underlying ideas into e.g. inspiration for loss functions and network architectures, and there's definitely something to be gained there, but I can't see myself sitting down and trying to literally work out the RG for a given network architecture or data set.\n\npermalinkembedsavegive award[\u2013]jocomoco[S] 1 point2 points3 points 3 years ago\u00a0(0 children)Interesting, thanks for the input, NichG.\n\npermalinkembedsaveparentgive award[\u2013]tscohen 7 points8 points9 points 3 years ago\u00a0(1 child)I find this connection intriguing as well, but what is lacking is either an empirical prediction about neural representations, learning, etc., that we can test, or a new architecture \/ learning algorithm that improves results on an actual learning problem. Until then it's just a mathematical analogy, and most ML researchers will (rightly) say \"meh\" to that.\nWhen this paper was released, it actually got quite a lot of attention, including popular media articles about it. It's a fascinating idea that somehow the \"abstraction\" that neural nets are thought to achieve is obtained by the same method physicists use to derive \"abstract\" or \"large scale\" variables of a physical system. But right now its not even clear how this could be tested. \nIt is also a reasonable idea that mathematical tools developed by physicists can be used in ML, and this has happened many times already (e.g. mean-field approximations, Bethe approximation, etc.). The fact that RG hasn't proven itself yet in this regard can mean that either it actually isn't all that useful for ML, or that we haven't tried hard enough (there's only a limited number of researchers with physics + ML skills, and the paper is only 2 years old...)\nSo if you have any ideas on how to actually do something useful with RG theory, by all means work on it. I think at the very least the growing theoretical DL community would be interested.\n\npermalinkembedsavegive award[\u2013]jocomoco[S] 1 point2 points3 points 3 years ago\u00a0(0 children)\nBut right now its not even clear how this could be tested.\n\nHmm... what do you mean tested ? What needs to be tested here ?\n\npermalinkembedsaveparentgive award[\u2013]schmook 7 points8 points9 points 3 years ago*\u00a0(1 child)There are some works in Statistical Physics concepts applied to ML. I don't remember any particular application of the renormalization group besides the one you linked, but there surely are analysis of the phase diagram of ML algorithms from the point of view of stat-phys and LOTS of phase transitions and critical phenomena.\nTake a look at works by Yoshiyuki  Kabashima, Hidetoshi Nishimori, Manfred Opper, David Saad, etc. \nNishimori has a book called \"Statistical Physics of Spin Glasses and Information Processing\" in which he teaches how the statistical physics of disordered systems can be applied to understanding different kinds of algorithms: error-correcting codes, associative memories and shallow neural networks (it was written some time ago...). The same kind of reasoning could be applied and has been applied to other algorithms, though it gets tougher as the algorithms get more complicated.\nMy PhD advisor worked with David Saad deriving the phase diagram of error correcting codes in the late 90s. There's a critical phase transition there and it can be shown that the fact that close to the transition line the complexity of the algorithms jumps from polynomial to exponential is related to the physical phenomenon known as \"critical slowing down\".\nRecently Kabashima derived new learning algorithms for the Compressed Sensing problem and used statistical physics techniques to analyse it's phase diagram, showing that the frontier between the area where the solution is unique and the area where the solution is not unique is a actually a phase transition line.\nOpper and Nishimori both has a bunch of work on neural networks from the quenched disordered system point of view, including analysis on how fast does it learn for many algorithms.\nThis work on neural networks was done in the late 90's and I don't know if it continued. It seems very difficult to apply to deep neural networks but someone must have tried.\nThe work in Compressed Sensing is pretty hot and very active. \nTake a look on Nishimori's book and Manfred Opper's \"Advanced Mean Field Methods\". \nAlso Marc Mezard's \"Information, Physics and Computation\".\nThis work you linked I still consider a theoretical curiosity which still doesn't elucidate much. But it should be explored further.\nThere's also a cultural divide where people from Physics like us frequently feel satisfied in deriving a phase diagram, looking at it and saying \"oh look, isn't it neat? I understand better this problem now\". And the ML researcher will turn at you and ask \"oh, you do?? How does that help me build better models and better learning algorithms? It doesn't? Then it isn't useful, don't waste my time.\". Which is a fair point of view. Physicists and ML researchers often have different stakes in this and some things that are central for one are not important for the other.\nFor the physicist sometimes the mere analogy is a deep realization worth exploring, because it gives new meaning and understanding even to physical problems. For the ML researcher the mere analogy is too little, there has to be a consequence on the application side. They are in this ride not for neat theoretical puzzles but for actually building algorithms that can advance how machines can actually learn. We have to recognize this sometimes and try a little bit harder to provide actual results for them, not just for us.\n\npermalinkembedsavegive award[\u2013]jocomoco[S] 0 points1 point2 points 3 years ago\u00a0(0 children)\nThere's a critical phase transition there and it can be shown that the fact that close to the transition line the complexity of the algorithms jumps from polynomial to exponential is related to the physical phenomenon known as \"critical slowing down\".\n\nYeah, somehow this is what I was thinking about, thanks for pointing it out, and thanks for the detailed answer !\n\npermalinkembedsaveparentgive award[\u2013]CultOfLamb 4 points5 points6 points 3 years ago\u00a0(1 child)Keep an eye out for Santa Fe's Complexity Explorer. It will feature a course on renormalization soon and may touch on the connection between renormalization and machine learning.\nThe course is by Simon DeDeo.\nhttp:\/\/www.santafe.edu\/media\/workingpapers\/15-06-017.pdf\n\nOptimal high-level descriptions of dynamical systems\nTo analyze high-dimensional systems, many fields in science and engineering rely on highlevel descriptions, sometimes called \u201cmacrostates,\u201d \u201ccoarse-grainings,\u201d or \u201ceffective theories\u201d. Examples of such descriptions include the thermodynamic properties of a large collection of point particles undergoing reversible dynamics, the variables in a macroeconomic model describing the individuals that participate in an economy, and the summary state of a cell composed of a large set of biochemical networks. Often these high-level descriptions are constructed without considering the ultimate reason for needing them in the first place. Here, we formalize and quantify one such purpose: the need to predict observables of interest concerning the high-dimensional system with as high accuracy as possible, while minimizing the computational cost of doing so. The resulting State Space Compression (SSC) framework provides a guide for how to solve for the optimal high-level description of a given dynamical system, rather than constructing it based on human intuition alone. In this preliminary report, we introduce SSC, and illustrate it with several information-theoretic quantifications of \u201caccuracy\u201d, all with different implications for the optimal compression. We also discuss some other possible applications of SSC beyond the goal of accurate prediction. These include SSC as a measure of the complexity of a dynamical system, and as a way to quantify information flow between the scales of a system.\n\n\npermalinkembedsavegive award[\u2013]jocomoco[S] 2 points3 points4 points 3 years ago\u00a0(0 children)This is gold : https:\/\/twitter.com\/ComplexExplorer thanks for pointing this out ! I found there for exemple this : https:\/\/youtu.be\/asw9M8RBcsU a 1 hour video about the StatPhys-ML connection\n\npermalinkembedsaveparentgive award[\u2013][deleted] 2 points3 points4 points 3 years ago\u00a0(2 children)I used fermionic Renormalization Group (quantum field theory) to study phase transitions in Hubbard-like systems. I applied to a ton of data science\/machine learning positions, mentioned the parallels between the fields and how ML might benefit from RG analysis, and didn't hear shit. Despite the high horses data people seem to sit on, I think RG is too complex an idea for them to grasp.\n\npermalinkembedsave[\u2013]serge_cell 1 point2 points3 points 3 years ago\u00a0(1 child)That is strange. May be you didn't want to do coding? Most of ML industry require implementation of methods working with \"real\" data, not just theoretical analysis.\nThen both of my last  workplaces were hiring the was a problem to find ppl who are both fluent in coding (at least python) and can do basic matrix\/tensor analysis. The latter was biggest problem.\n\npermalinkembedsaveparentgive award[\u2013]jocomoco[S] 0 points1 point2 points 3 years ago\u00a0(0 children)Yeah, I heard this too, the combo of coding skills + math skills is hard to find.\n\npermalinkembedsaveparentgive award[\u2013]WormRabbit 1 point2 points3 points 3 years ago\u00a0(1 child)What are the theoretical models and nontrivial implications driven from that assumption?\n\npermalinkembedsavegive award[\u2013]jocomoco[S] -1 points0 points1 point 3 years ago*\u00a0(0 children)You mean by the exact mapping ? I don't know but maybe it means that one can use RG theory in ML . Perhaps ? They got nobel prize for RG : http:\/\/www.nobelprize.org\/nobel_prizes\/physics\/laureates\/1982\/wilson-lecture. So it might be useful to reuse something from 50 years of research on this topic.\nWhat kinda surprises me is that I spent 3 years studying ML (post-grad) and I never heard about this connection in any of the courses I took and that kinda shows how unpopular this connection is. I don't know why ?\n\npermalinkembedsaveparentgive award[\u2013]bluecoffee 1 point2 points3 points 3 years ago\u00a0(1 child)\nBecause to my knowledge, the theory has not yet been used to build better models. \nBecause 'traditional' RBMs have largely been abandoned. \n\n\npermalinkembedsavegive award[\u2013]jocomoco[S] 0 points1 point2 points 3 years ago\u00a0(0 children)Interesting to hear that.\n\npermalinkembedsaveparentgive awardaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 10093 on  r2-app-030c3614bd34d7a45  at 2019-11-19 10:05:36.923004+00:00 running 55775d0 country code: US."
  },
  "21":{
    "title":"[D] Discussion on Pytorch vs TensorFlow : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-gaming-pics-worldnews-funny-todayilearned-tifu-aww-movies-videos-Jokes-gifs-science-mildlyinteresting-Showerthoughts-nottheonion-television-UpliftingNews-OldSchoolCool-dataisbeautiful-sports-personalfinance-explainlikeimfive-GetMotivated-TwoXChromosomes-askscience-nosleep-IAmA-space-LifeProTips-Futurology-gadgets-books-food-Art-Music-WritingPrompts-photoshopbattles-EarthPorn-DIY-Documentaries-history-creepy-listentothis-philosophy-announcements-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  22 Feb 201833 points (79% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave820,743 readers2,132 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X189  \u00b7 38 comments How to detect AI Snake oil177  \u00b7 41 comments [D] Early coauthorship with top scientists predicts success in academic careers4  \u00b7 2 comments [Discussion] Advice needed: Feeling trapped by lack of management\/strategy, no implemented models.20  \u00b7 7 comments [D] Regarding the ability of neural networks to learn \"simple\" examples first3  \u00b7 1 comment [P] Machine Learning Flight Rules6  \u00b7 1 comment [Research] Announcing Kaolin - PyTorch Library for Accelerating 3D Deep Learning Research219  \u00b7 13 comments [P] How to apply machine learning and deep learning methods to audio analysis4  \u00b7 1 comment [D] Is it ill-advised to perform transfer learning with generalized linear models?20  \u00b7 15 comments [P] askgpt.com I built a simple ui to converse with gpt-2222  \u00b7 15 comments [R] How Machine Learning Can Help Unlock the World of Ancient Japan (by Alex Lamb)Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7323334Discussion[D] Discussion on Pytorch vs TensorFlow (self.MachineLearning)submitted 1 year ago by ButthurtFeministsHi,\nI've been using TensorFlow for a couple of months now, but after watching a quick Pytorch tutorial I feel that Pytorch is actually so much easier to use over TF.\nAnyone have strong reasons why you use one over the other? Interested in the different sides of the argument.\n\n69 commentssharesavehidereportall 69 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]ephemeraI 68 points69 points70 points 1 year ago\u00a0(3 children)Using Pytorch makes me happy, using Tensorflow makes me sad. Therefore, I use Pytorch. It's also not too bad to convert models between Pytorch\/Tensorflow\/Caffe.\n\npermalinkembedsavegive award[\u2013]harponen 10 points11 points12 points 1 year ago\u00a0(1 child)Haha I have to agree! I've been working with PyTorch for a couple of months now, and was just looking back at my older TF code yesterday. Despite the nice Estimator and Dataset classes, it just seemed overly complicated when compared to PyTorch... why does Google want to cram everything into the compute graph?!?\n\npermalinkembedsaveparentgive award[\u2013]cjalmeida 6 points7 points8 points 1 year ago\u00a0(0 children)Forget TF Estimator API - maybe because it's new but but it's a one trick pony. Try to do anything different from what it was designed for and you're in for a lot of hooks.\nDataset is fine though. Shameless plug, I just wrote a blog post with a simple tutorial on it: http:\/\/cjalmeida.net\/post\/tensorflow-mnist\/\n\npermalinkembedsaveparentgive award[\u2013]ButthurtFeminists[S] 1 point2 points3 points 1 year ago\u00a0(0 children)Hahahahaa just go by the gut feeling :)\n\npermalinkembedsaveparentgive award[\u2013]netheril96 33 points34 points35 points 1 year ago\u00a0(16 children)After hearing all praises about PyTorch, I tried it and initially loved it. Reasons:\n\nIt is faster than TF on default settings. It is mostly attributed to TF defaulting to data format NHWC, which is slower on CUDA GPUs than NCHW. Although TF can be told to use NCHW too, that is additional trouble.\nGenerally more Pythonic. No more globally mutable states everywhere.\n\nBut after a month, I switched back to TensorFlow.\nThe biggest downside of PyTorch is that I have to track what gradients are needed and set requires_grad or volatile appropriately, or I will waste time doing unneeded computation. TF does not have the same problem. It is more elaborated here.\nThe core part like convolution, batch norm in PyTorch is easier to use than TensorFlow, but the auxiliary part is much harder. \n\nSaving and loading model: it requires to you write many things yourself to bundle the model, optimizer, global step etc. And what if I change part of the optimizer parameters (learning rate, beta1) but want the variable states to be the same? In addition, you cannot evaluate an old checkpoint when your codes have changed, and I frequently alter my model.\nVisualization: PyTorch has third party bindings to tensorboard, but it frequently crashes my program with SIGKILL. \n\nAnd some less critical issues:\n\nIt has no scalar.\nI have to do a lot of manual calculation for shapes, like how much padding to preserve width and height, or remember what channels the last module outputs, whereas in TF, I can let the library do most of the heavylifting.\nSupposedly it interacts well with numpy. But you can multiple a torch.FloatTensor with float, yet not np.float32. And the naming of PyTorch differs wildly from numpy. Like numpy.reshape and tf.reshape, but torch.Tensor.view. Or the axis vs dim in function arguments.\nNo negative step in indexing. So much easier to flip an image in TF.\nMost people just want to do almost all their computation on GPUs, but PyTorch forces you to litter everywhere if ENABLE_CUDA: XX = XX.cuda(). Oh, and all those tensor creating functions like torch.zeros, torch.ones, torch.randn only create CPU tensors.\n\nMaybe I'll revisit once PyTorch hits 1.0.\n\npermalinkembedsavegive award[\u2013]p-morais 8 points9 points10 points 1 year ago\u00a0(1 child)\nLike numpy.reshape and tf.reshape, but torch.Tensor.view.\n\nIf someone started a petition to rename Tensor.view I would sign it in a heartbeat\n\npermalinkembedsaveparentgive award[\u2013]cjalmeida 3 points4 points5 points 1 year ago\u00a0(0 children)TBF, \"view\" is a more appropriate name for the operation. What you get with view and reshape is actually a view on the underlying data without actually reshaping it - unless you do copy or contiguous.\n\npermalinkembedsaveparentgive award[\u2013]brombaer3000 1 point2 points3 points 1 year ago*\u00a0(2 children)\nScalar support is available in the unreleased master branch of PyTorch now.\nWhat do you use for tensorboard integration? tensorboardX works in my code and has never lead to crashes. \nYou can save and restore the parameter state separately with torch.save(model.state_dict(), PATH) and reload it on another model instance (also works after code changes and with changed training hyperparameters): http:\/\/pytorch.org\/docs\/0.3.1\/notes\/serialization.html\nEdit: It also looks like you will be able to create tensors directly on GPU with the new Tensor factories, which use NumPy-style dtypes:  https:\/\/github.com\/pytorch\/pytorch\/pull\/5384\n\n\npermalinkembedsaveparentgive award[\u2013]netheril96 0 points1 point2 points 1 year ago\u00a0(1 child)Yes, I am using tensorboardX. The SIGKILL issue is not easy to reproduce, so I never bother filing a bug report.\nYou cannot load a state dict into a model if it has a different number of convolutional layers, or different num_featuers of linear layers, etc. In TF, by contrast, I export the graph along with the checkpoint, so I can evaluate it whenever I like, even I change the codes constructing the model in the first place.\n\npermalinkembedsaveparentgive award[\u2013]cjalmeida 0 points1 point2 points 1 year ago\u00a0(0 children)That's part of eager evaluation feature of PyTorch so it's not \"fixable\". I have the habit of Git versioning your experiments (and tagging appropriately). Otherwise, you can set to export the graph using ONNX now to load it later in similar fashion to TF.\n\npermalinkembedsaveparentgive award[\u2013]bdol 2 points3 points4 points 1 year ago\u00a0(5 children)\nThe biggest downside of PyTorch is that I have to track what gradients are needed and set requires_grad or volatile appropriately, or I will waste time doing unneeded computation. TF does not have the same problem. It is more elaborated here.\n\nFYI you can use detach to decouple the output of the generator from G's computation graph when updating D's parameters. No mucking about with requires_grad!\n\npermalinkembedsaveparentgive award[\u2013]netheril96 1 point2 points3 points 1 year ago\u00a0(4 children)You still need to muck around with requires_grad of D's parameters to avoid all unnecessary computation. Not only is that tedious, it is highly non-obvious as well.\n\npermalinkembedsaveparentgive award[\u2013]bdol 0 points1 point2 points 1 year ago\u00a0(3 children)I'm not sure what you mean about unnecessary computation. Let's take a vanilla GAN, which requires 3 gradient computations:\n\nCompute the gradient wrt the parameters of D for a real image (gradient wrt parameters of G is not computed by default, as the variable representing the real data is detached from the graph)\nCompute the gradient wrt the parameters of D for a \"fake\" generated image (gradient wrt parameters of G is not computed because we can use G(z).detach())\nCompute the gradient wrt the parameters of G for the \"fool\" loss. You cannot simply flip the label of the gradient computed through D in step 2, as D contains non-linearities. Therefore you must backprop through D and G fully for this step. However, we can reuse G(z) in this step.\n\nEach step here is required, no? And we only perform one full forward pass (to generate a fake example), and one half-forward pass through D with real data.\n\npermalinkembedsaveparentgive award[\u2013]netheril96 0 points1 point2 points 1 year ago\u00a0(2 children)The GitHub issue elaborates it fully.\n\npermalinkembedsaveparentgive award[\u2013]Bargh_Joul 0 points1 point2 points 1 year ago\u00a0(1 child)But a solution is coming right? How good that will be? \n\npermalinkembedsaveparentgive award[\u2013]netheril96 0 points1 point2 points 1 year ago\u00a0(0 children)No solutions are in sight. The discussions on the issue seem to have lead to nowhere.\n\npermalinkembedsaveparentgive award[\u2013]bradyzhou 1 point2 points3 points 1 year ago\u00a0(0 children)For visualizations, check out https:\/\/github.com\/facebookresearch\/visdom. It's still in early phases so you'll have to roll your own smoothed scalar graphs, but it's still awesome.\n\npermalinkembedsaveparentgive award[\u2013]SomeoneInTheComments 0 points1 point2 points 1 year ago\u00a0(3 children)\nNHWC, which is slower on CUDA GPUs than NCHW\n\nHow big is the difference typically in %?\n\npermalinkembedsaveparentgive award[\u2013]netheril96 0 points1 point2 points 1 year ago\u00a0(2 children)In my rough benchmark, 20% ~ 30% in training, so I always force TF to use NCHW these days.\n\npermalinkembedsaveparentgive award[\u2013]cjalmeida 0 points1 point2 points 1 year ago\u00a0(1 child)One issue is that pre-trained models for TF are usually in NHWC. I don't know an easy way to convert between formats.\n\npermalinkembedsaveparentgive award[\u2013]netheril96 1 point2 points3 points 1 year ago\u00a0(0 children)The TF developers promised a way to convert graphs between NHWC and NCHW, but never realized that promise. For now, I only use pretrained models to extract features, but never fine tune over them, so I am not concerned, yet.\n\npermalinkembedsaveparentgive award[\u2013]Kaixhin 18 points19 points20 points 1 year ago\u00a0(0 children)When I started looking at frameworks the main ones were Torch, Caffe and Theano. I ruled out Caffe for lack of flexibility and found Torch had the right level of abstraction for me (e.g. layers, training loops), plus wasn't a fan of Theano's compilation step. Switched to PyTorch not because of Python (was happy enough with Lua) but primarily because it made dynamic stuff (e.g. variable length sequences for RNNs) much nicer than any of the others (including TensorFlow, released at this point). In general I like how quickly I can whip up even complex architectures in PyTorch, and no need to wait for compilation. Easy debugging. Fast. I've seen it in use at Facebook, Microsoft and Twitter (so there are big companies using it, with more listed at the bottom of the website). If I knew about Chainer a long time ago I might have gone for that, but I'm now settled with PyTorch and the awesome community that comes with it.\n\npermalinkembedsavegive award[\u2013]ImpossiblePressure 4 points5 points6 points 1 year ago\u00a0(3 children)Is Pytorch worth using if you have windows? I don't see an official download for windows, although there seem to be some unofficial ways to download it \n\npermalinkembedsavegive award[\u2013]hapemask 4 points5 points6 points 1 year ago\u00a0(0 children)There's an anaconda package for it: https:\/\/anaconda.org\/peterjc123\/pytorch\nIt's been updated fairly quickly in the past as new pytorch versions come out.\n\npermalinkembedsaveparentgive award[\u2013]DaLameLama 1 point2 points3 points 1 year ago\u00a0(0 children)The package from peterjc123 is fantastic. Works flawless on my Windows machine. Easy to install too.\nIf you wanna use CUDA, see chapter \"Easy Installation\" here: https:\/\/github.com\/peterjc123\/pytorch-scripts\n\npermalinkembedsaveparentgive award[\u2013]ButthurtFeminists[S] 0 points1 point2 points 1 year ago\u00a0(0 children)I think theres a way to install it using anaconda. If you're comfortable with TF, then you might as well save the effort.\n\npermalinkembedsaveparentgive award[\u2013]melgor89 5 points6 points7 points 1 year ago*\u00a0(0 children)Currently I'm using both framework, depending on task. I will write down advantages of one framework, which are disadvantage of second one ( I could be biased as I was using Torch-Lua earlier)\nTensorFlow:\n\nI love idea of computation graph and getting access to any variable I want in any time\nComputation are controlled by software, so unnecessary stuff \nReally cool for deploying (TfLite, freezing-graph)\nTensorboard\nGreat support for RNN (Attention models are super easy to use). The only drawback is CuDNN, which I;m not able to get properly (same model structure have much lower accuracy)\nVery easy adding new function to already created NN (In PyTorch need to write separate class)\n\nPyTorch:\n\neasy creation of input pipeline, data loader.  I can use any library here (so very crazy idea are welcome) and still multi-thread (TfRecord are not so nice)\neasy creation of new layers, even when the function which I need is not implemented in API (http:\/\/pytorch.org\/tutorials\/advanced\/numpy_extensions_tutorial.html)\nsuper-easy debugging\nData-Parallel is just one line!\n(Plus-Minus) I feel like I control many things by creation the computation by myself. So in one hand, I can do crazy\/research stuff easy, in the other I could waste time for unnecessary computation\n\nIn general:\n\nTensorFlow for RNN models and if you are planning standard model with little bit of research\nPyTorch for Conv models and for research stuff\n\n\npermalinkembedsavegive award[\u2013]fly200 5 points6 points7 points 1 year ago\u00a0(9 children)I heard many \"Pytorch for research and TensorFlow for production\". I want to know why the Pytorth is NOT suitable for production. Does anybody have some hints? \n\npermalinkembedsavegive award[\u2013]cjalmeida 4 points5 points6 points 1 year ago\u00a0(3 children)With TF you can deploy where deploying Python is a pain - ie. mobile.\nOtherwise, this makes little sense. Just wrap the inference code in a thin REST library and call it a day - your code will spend 99.999% of the time in GPU\/CPU processing anyway.\nWith the ONNX support, you can export (most) PyTorch models to Caffe2 and even ditch Python altogether.\n\npermalinkembedsaveparentgive award[\u2013]fly200 0 points1 point2 points 1 year ago\u00a0(2 children)Thanks for your kind comments. It seems the core of PyTorch is from the THC library based on C\/C++ language. Why not directly convert the PyTorch code into C\/C++ codes based on the efficient THC library?\n\npermalinkembedsaveparentgive award[\u2013]cjalmeida 0 points1 point2 points 1 year ago\u00a0(1 child)While it's THC underneath, you still define the network in Python. And automated conversion yo C++ is not straightforward. IMO, using ONNX or just keeping Python  sees a lot simpler than rewriting code.\n\npermalinkembedsaveparentgive award[\u2013]fly200 0 points1 point2 points 1 year ago\u00a0(0 children)Yeah, got it. Thanks!\n\npermalinkembedsaveparentgive award[\u2013]poez 0 points1 point2 points 1 year ago\u00a0(4 children)Safety critical applications. Python doesn\u2019t have any type checking and doesn\u2019t have to build. Much easier to send malicious messages by getting into the python interpreter than finding a way to build C++ code on the platform. Also, most backend applications are written in a compiled language like C++, Java, Go, etc. It\u2019s a short sighted idea to change your production environment. Causes headaches in a large code base and reduces the ability for teams to share code. That\u2019s also two production environments you have to support. \nFor small personal applications or start ups who use python anyway for backend, it\u2019s probably fine. But there\u2019s a reason why large companies eventually bite the bullet and move to a compiled language for production. \n\npermalinkembedsaveparentgive award[\u2013]----_____--------- 5 points6 points7 points 1 year ago\u00a0(0 children)\nMuch easier to send malicious messages by getting into the python interpreter than finding a way to build C++ code on the platform.\n\nuhhhhh no, you'll get like 5x more security risk in C or C++ because of the possibility of buffer overflows and similar vulnerabilities, where other languages, compiled or not, would just crash.\nI kinda agree that statically typed languages can be more predictable, assuming you write a similar amount of tests in them, but it's mostly in terms of plain bugs rather than vulnerabilities.\n\npermalinkembedsaveparentgive award[\u2013]fly200 0 points1 point2 points 1 year ago\u00a0(2 children)Thanks a lot for your kind comments! \n\npermalinkembedsaveparentgive award[\u2013]fly200 0 points1 point2 points 1 year ago\u00a0(1 child)In fact, I'm not sure what it is like when you say the production environment. In my opinion, after the network was trained, the pretrained weights may saved into the web server and the webserver just run the forward procedure to get the result and return to the users\/clients. \n\npermalinkembedsaveparentgive award[\u2013]poez 0 points1 point2 points 1 year ago\u00a0(0 children)Yeah that\u2019s what happens in tensorflow. There\u2019s support to take the weights trained in python and deploy it with a full frozen computation graph in C++, Java, Go, etc. So the C++ code is minimal. Can\u2019t do that in pytorch. Can only run in python.  \n\npermalinkembedsaveparentgive award[\u2013]lalaland11256 12 points13 points14 points 1 year ago*\u00a0(2 children)TensorFlow has much better and easier support for saving and loading models across different environments and even programming languages. If loading and saving models is a priority, then you should strongly consider TensorFlow.\nFor instance, I recently worked on a project where it was a hard requirement that our model be able to run inside a Java application. TensorFlow made this quite easy because we could train our model in Python and then load it in Java without any trouble.\n\npermalinkembedsavegive award[\u2013]ButthurtFeminists[S] 3 points4 points5 points 1 year ago\u00a0(1 child)Yeah, it seems like a major plus for TF. Plus, they even have TFLite to reduce model size for mobile uses, which seems great (although the same effect is achievalbe through pytorch, its just not the same - doing it yourself vs letting the program do it for you). Thanks for sharing your experience!\n\npermalinkembedsaveparentgive award[\u2013]jinchuika 0 points1 point2 points 1 year ago\u00a0(0 children)\nsame effect is achievalbe through pytorch\n\nDo you have more info on this? I'm starting a project that has to run on mobile, so I was planning to use TF because of that. I'd love to use PyTorch instead, but didn't know this was possible\n\npermalinkembedsaveparentgive award[\u2013]engharat 3 points4 points5 points 1 year ago\u00a0(0 children)I have TF as much as I love Pytorch. I worked with caffe and keras, and when I tried to switch to TF I found the framework ugly designed, mostly verbose and generally unreadable. Looking at other people TF-based source codes, it was like reading a completely foreign spoken language.\nWhen I tried to read pytorch code for the first time, I understood easily most of the content: it was like listening a dialect of my own language. Pytorch is SO pythonic, so polite, so easy to debug ( in TF it was a nightmare...) , and in those days I found every important academic paper implemented in pytorch as well as TF. All my colleagues are jumping on pytorch wagon: I hope it will spread more and more. On the other side, I think TF would never been so much used if there wasn't Google behind it..\n\npermalinkembedsavegive award[\u2013]shchur 2 points3 points4 points 1 year ago\u00a0(0 children)The main reason that stops me from switching from Tensorflow to Pytorch is the lack of support for sparse variables by the latter. In most graph-related settings storing the adjacency matrix as a dense tensor is simply infeasible, which means that TF is the only option available to researchers working with graph\/network data.\n\npermalinkembedsavegive award[\u2013]bbsome 11 points12 points13 points 1 year ago\u00a0(23 children)Around September last year, I was switching away from Theano. I chose back then Tensorflow over Pytorch (and stay for pretty much all of the same reasons):\n\nThe similarity to Theano and using symbolic graphs. This has several advantages - it is very straightforward to do higher order directional derivatives (e.g. Hessian-vector products). I think this has been done as well in Pytorch, but it remains ad-hoc in the sense that I don't think you can do any higher orders (for instance differentiate the Hessian norm). \nNot bad debugging. I know people complain and I know Pytorch is bound to be better in this. However, most of the actual \"mistakes\" that you get are due to shape inconsistencies. With the automatic shape inference of thensorflow, it is quite difficult to complain about debugging these. \nTensorboard\nScopes - this and 3 are the two really, really great features which distinguish Tensorflow from any other. Scopes are so nicer for allowing reuses etc... that it's just a no-brainer why other frameworks did not do this in the same way. \nTensorflow eager is coming slowly in and with that the issues of not having dynamic graphs will be gone.\nSignificantly wider adoption - both in industry and research. Big labs like DeepMind and OpenAI use Tensorflow. Additionally, in the industry, I have not spotted anyone using Pytorch. There are significantly more resources on Tensorflow than Pytorch. This has also the ramification of much well-polished API.\nTPU's. If you plan to use some time in the future these, their support in Tensorflow is going to always be significantly better than Pytorch. \n\n\npermalinkembedsavegive award[\u2013]alexmlamb 17 points18 points19 points 1 year ago\u00a0(6 children)It's just my personal experience - but I've had a lot of problems with \"silent\" errors occurring in TensorFlow.  I.e. if I scope something wrong, some of the parameters end up getting reset rather then reused, which makes model performance bad without any errors.  \n\npermalinkembedsaveparentgive award[\u2013]ppwwyyxx 5 points6 points7 points 1 year ago\u00a0(1 child)All my training scripts print parameters after building the graph with some nice formatting so this kind of error will immediately be spotted. \n\npermalinkembedsaveparentgive award[\u2013]geomtry 5 points6 points7 points 1 year ago\u00a0(0 children)Mind sharing this? Sounds so useful!\n\npermalinkembedsaveparentgive award[\u2013]bbsome 0 points1 point2 points 1 year ago\u00a0(3 children)I agree that can happen. But then you can have the opposite of being very hard to share parameters around. I think scopes are as close as you can get to good abstraction for variable pools. Ofc that is just my opinion on the topic but I really love them. \n\npermalinkembedsaveparentgive award[\u2013]alexmlamb 2 points3 points4 points 1 year ago\u00a0(2 children)So in Pytorch, you can create the module once and then pass it into all of the places where it (along with its parameters need to be used).  \nIs there a place where the tensorflow way is a lot easier than this (this isn't a rhetorical question, I'm actually curious).  \n\npermalinkembedsaveparentgive award[\u2013]bbsome 1 point2 points3 points 1 year ago\u00a0(1 child)Well, basically you don't need to pass anything around. With scopes, you have like a global store accessible from anywhere in your code. So as long as you do at least a bit sane naming its very nice.\n\npermalinkembedsaveparentgive award[\u2013]alexmlamb 0 points1 point2 points 1 year ago\u00a0(0 children)So it might just be that I'm not very good with it - but I've had some difficulties where I use a library such that a method which I didn't write is calling my network - and if it explicitly tries to look for specific scopes, those need to be consistent with how I defined my network.  Does that make sense?  \n\npermalinkembedsaveparentgive award[\u2013]bitcure 8 points9 points10 points 1 year ago\u00a0(7 children)\nTensorboard\n\nPytorch has a tensorboard plugin that works quite as well\n\n. Additionally, in the industry, I have not spotted anyone using Pytorch. \n\nFacebook depends significantly on pytorch.\nThe advantage in pytorch is that the paradigm is simple enough for you to create your own operation at the lower level. The same is a headache I.e to write c level code in tensorflow especially with its poorer documentation.\nOverall, I use pytorch to prototype research experiments quickly and tensorflow when I've to deploy it on a website  or android . \nTensorflow also has the backing of a  strong community so you have easy access to a lot more Byzantine models than pytorch, at least for now.\n\npermalinkembedsaveparentgive award[\u2013]bbsome -1 points0 points1 point 1 year ago\u00a0(2 children)Well, September 2017 Pytorch did not have Tensorboard. However, note that eventually, they will all converge to 99% the same thing so it won't even matter. Like whether you drive a BMW or a Mercedes - 99% of the driving is the same and the difference is more or less in people's mind. \nAlso except Facebook (as they are the main maintainers) I'm aware of only Uber to partially use Pytorch and no other lab.  \n\npermalinkembedsaveparentgive award[\u2013]programmerChilli 8 points9 points10 points 1 year ago*\u00a0(0 children)Nvidia? Salesforce too, I seem to remember? In academia, plenty of labs use pytorch. For example, speaking only of a lab I'm very familiar with, pretty much everybody @ Cornell's vision lab uses Pytorch.\n\npermalinkembedsaveparentgive award[\u2013]goldsborough 7 points8 points9 points 1 year ago\u00a0(0 children)There\u2019s a long list right at the bottom of http:\/\/pytorch.org\n\npermalinkembedsaveparentgive award[+]poez comment score below threshold-7 points-6 points-5 points 1 year ago\u00a0(3 children)\nFacebook depends significantly on pytorch.\n\nThey use it for research and then tensorflow for production. \n\npermalinkembedsaveparentgive award[\u2013]netheril96 2 points3 points4 points 1 year ago\u00a0(1 child)Do they? It is my understanding that they deploy with Caffe2.\n\npermalinkembedsaveparentgive award[\u2013]poez 2 points3 points4 points 1 year ago\u00a0(0 children)You are right. They use Caffe2. I\u2019m mistaking them with another big tech company that uses pytorch for research and tensorflow for production (can\u2019t remember, saw a tech talk a few months ago).\nMy bigger point though is that not many companies deploy pytorch for production. It\u2019s not really made for that. \n\npermalinkembedsaveparentgive award[\u2013]JustFinishedBSG 2 points3 points4 points 1 year ago\u00a0(0 children)\ntensorflow for production. \n\nNo they don't...\n\npermalinkembedsaveparentgive award[\u2013]ButthurtFeminists[S] 2 points3 points4 points 1 year ago\u00a0(0 children)Thanks for your answer! \nSo far it seems like the general trend in responses has been: Pytorch is easier to use (and debug) while TF is better suited for \"more serious\" uses. I put quoted because what I mean by that is a lot of different factors, such as availability of expensive hardware, need to use it in another language other than python, etc.\nI have a few friends in industry who have actually completely switched over to pytorch. It seems like their main reason was that it's much easier to test out new things with Pytorch to optimize the model before finalizing it. It seems like they then rewrite the code using C or whatever is supported by the platform (usually mobile).\n\npermalinkembedsaveparentgive award[\u2013]Xirious 1 point2 points3 points 1 year ago\u00a0(1 child)\nWith the automatic shape inference of thensorflow\n\nIf it's automatic why are there issues? The fact that you have to define tensor sizes is precisely why it's not automatic and error prone?\n\npermalinkembedsaveparentgive award[\u2013]bbsome 0 points1 point2 points 1 year ago\u00a0(0 children)You define shapes only of the inputs. The issue happens before you start running the graph wherever is the mistake, the same way it will happen in Pytorch... I'm not sure what are you on about?\n\npermalinkembedsaveparentgive award[\u2013][deleted] 1 point2 points3 points 1 year ago\u00a0(2 children)\nI think this has been done as well in Pytorch, but it remains ad-hoc in the sense that I don't think you can do any higher orders (for instance differentiate the Hessian norm). \n\nOne can do this in PyT too: \n- For Frobenius: run H-v product over all e_i, compute norm. \n- For spectral (-2): run power iteration with H-v products.\nAD techniques for computing the Hessian more-or-less rely on H-v products, so I can't imagine anything fundamentally different b\/w the two frameworks, algorithmically. \n\nThe similarity to Theano and using symbolic graphs. \n\nThe AD tape is the symbolic graph. One can always use it to play games similar to what Theano\/Tensorflow do (assuming a stationary graph). This is what the jit-compiler, memory optimizers for PyT do.\n\nNot bad debugging. I know people complain and I know Pytorch is bound to be better in this. However, most of the actual \"mistakes\" that you get are due to shape inconsistencies. With the automatic shape inference of thensorflow, it is quite difficult to complain about debugging these. \n\nI do miss shape inferencing, but Tensorflow doesn't really implement this well either.\nI miss being able to dump\/load computational graphs more. PyTorch models are a pain to 'transport'.\n\npermalinkembedsaveparent[\u2013]bbsome 0 points1 point2 points 1 year ago\u00a0(1 child)\nOne can do this in PyT too: - For Frobenius: run H-v product over all e_i, compute norm. - For spectral (-2): run power iteration with H-v products.\n\nThe Hessian-vector product was added a few months ago and I'm aware of them, but I'm not sure you can differentiate that over. Might be wrong.\n\nOne can do this in PyT too: - For Frobenius: run H-v product overall e_i, compute norm. - For spectral (-2): run power iteration with H-v products.\n\nThis is obvious and is same for Autograd. However, the fact that you are doing it dynamically means that for complicated optimizations you need very smart JITs. Additionally, as far as I remember for higher derivatives you had to manually tell PyTorch to created the derivative graph and not store gradients in the param.gradient or smth like that.\n\npermalinkembedsaveparentgive award[\u2013][deleted] 0 points1 point2 points 1 year ago\u00a0(0 children)\nThe Hessian-vector product was added a few months ago and I'm aware of them, but I'm not sure you can differentiate that over. Might be wrong.\n\nThis was done by adding taping support for reverse-mode AD, so that gradient computation becomes another graph you can differentiate over (and over and over). Ditto with Chainer, Autograd.\n\nThis is obvious and is same for Autograd.\n\nIt also means it's more general. \nYou may need 'a sufficiently smart compiler' for the dynamic stuff, but for static ones, you can just run the model once, get the graph, and then do similar optimizations as Tensorflow.\n\npermalinkembedsaveparent[\u2013]__Julia 0 points1 point2 points 1 year ago\u00a0(1 child)Do you recommend any tutorials for advanced and effective use of Tensorflow \n\npermalinkembedsaveparentgive award[\u2013]bbsome 1 point2 points3 points 1 year ago\u00a0(0 children)Usually advanced and effective means highly non-general or reusable. So I'm not sure there are, but more or less the only \"special\" care needed is how to handle the dataset loading IFF you have a very very large dataset or a distributed setup. Otherwise its all quite straightforward with the Dataset API. \n\npermalinkembedsaveparentgive award[\u2013]fly200 0 points1 point2 points 1 year ago\u00a0(0 children)I like simple, efficient and reliable Caffe.\n\npermalinkembedsavegive award[\u2013]rdfar 0 points1 point2 points 1 year ago\u00a0(1 child)Slightly unrelated, but what are the best resources to learn pytorch?\n\npermalinkembedsavegive award[\u2013]Atupis 1 point2 points3 points 1 year ago\u00a0(0 children)Pytorch documentation is pretty good and github has good examples https:\/\/github.com\/pytorch\/examples\/\n\npermalinkembedsaveparentgive awardaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 6215 on  r2-app-00c1e7e3b6ef84d9b  at 2019-11-20 21:35:34.383034+00:00 running a5676e6 country code: US."
  },
  "22":{
    "title":"[Discussion] Exfiltrating copyright notices, news articles, and IRC conversations from the 774M parameter GPT-2 data set : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0AskReddit-news-funny-pics-aww-worldnews-gaming-todayilearned-television-gifs-Showerthoughts-Jokes-videos-tifu-mildlyinteresting-TwoXChromosomes-OldSchoolCool-space-creepy-nottheonion-books-movies-personalfinance-LifeProTips-IAmA-explainlikeimfive-dataisbeautiful-Futurology-science-gadgets-askscience-food-sports-nosleep-Music-Art-WritingPrompts-EarthPorn-history-DIY-photoshopbattles-Documentaries-UpliftingNews-GetMotivated-listentothis-philosophy-announcements-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsother discussions (1)Want to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  09 Oct 2019245 points (96% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave819,876 readers2,103 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X136  \u00b7 6 comments [R] How Machine Learning Can Help Unlock the World of Ancient Japan (by Alex Lamb)29  \u00b7 5 comments [D] ICML 2019 Machine Learning Talks15  \u00b7 20 comments [N] Cerebras claims that the CS-1 delivers the performance of more than 1,000 leading GPUs combined9  \u00b7 3 comments [D] what are the current production and SOTA algorithms behind chatbots?2 [D] Michael Kearns: Algorithmic Fairness, Bias, Privacy, and Ethics in Machine Learning | Artificial Intelligence Podcast[D] Over\/Under\/SMOTE sampling for EXTREMELY imbalanced data without getting data?146  \u00b7 15 comments [P] Cortex: Deploy models from any framework as production APIs3  \u00b7 4 comments [D] What is the state-of-the-art implementation for style transfer?2  \u00b7 3 comments [D] Which ML task(s) would you use to solve this problem?226  \u00b7 10 comments [N] French BERT (CamemBERT) now available in Transformers libraryWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7244245246Discussion[Discussion] Exfiltrating copyright notices, news articles, and IRC conversations from the 774M parameter GPT-2 data set (self.MachineLearning)submitted 1 month ago by madokamadokamadokaConcerns around abuse of AI text generation have been widely discussed. In the original GPT-2 blog post from OpenAI, the team wrote:\n\nDue to concerns about large language models being used to generate deceptive, biased, or abusive language at scale, we are only releasing a much smaller version of GPT-2 along with sampling code. We are not releasing the dataset, training code, or GPT-2 model weights. \n\nThese concerns about mass generation of plausible-looking text are valid. However, there have been fewer conversations around the GPT-2 data sets themselves. Google searches such as \"GPT-2 privacy\" and \"GPT-2 copyright\" consist substantially of spurious results. Believing that these topics are poorly explored, and need further exploration, I relate some concerns here.\n\u200b\nInspired by this delightful post about TalkTalk's Untitled Goose Game, I used Adam Daniel King's Talk to Transformer web site to run queries against the GPT-2 774M data set. I was distracted from my mission of levity (pasting in snippets of notoriously awful Harry Potter fan fiction and like ephemera) when I ran into a link to a real Twitter post. It soon became obvious that the model contained more than just abstract data about the relationship of words to each other. Training data, rather, comes from a variety of sources, and with a sufficiently generic prompt, fragments consisting substantially of text from these sources can be extracted.\nA few starting points I used to troll the dataset for reconstructions of the training material:\n\nAdvertisement\nRAW PASTE DATA\n[Image: Shutterstock]\n[Reuters\nhttps:\/\/\nAbout the Author\n\nI soon realized that there was surprisingly specific data in here. After catching a specific timestamp in output, I queried the data for it, and was able to locate a conversation which I presume appeared in the training data. In the interest of privacy, I have anonymized the usernames and Twitter links in the below output, because GPT-2 did not. \n[DD\/MM\/YYYY, 2:29:08 AM] <USER1>: XD [DD\/MM\/YYYY, 2:29:25 AM] <USER1>: I don't know what to think of their \"sting\" though [DD\/MM\/YYYY, 2:29:46 AM] <USER1>: I honestly don't know how to feel about it, or why I'm feeling it. [DD\/MM\/YYYY, 2:30:00 AM] <USER1> (<@USER1>): \"We just want to be left alone. We can do what we want. We will not allow GG to get to our families, and their families, and their lives.\" (not just for their families, by the way) [DD\/MM\/YYYY, 2:30:13 AM] <USER1> (<@USER1>): <real twitter link deleted> [DD\/MM\/YYYY, 2:30:23 AM] <@USER2> : it's just something that doesn't surprise me [DD\/MM\/YYYY, 2:\nWhile the output is fragmentary and should not be relied on, general features persist across multiple searches, strongly suggesting that GPT-2 is regurgitating fragments of a real conversation on IRC or a similar medium. The general topic of conversation seems to cover Gamergate, and individual usernames recur, along with real Twitter links. I assume this conversation was loaded off of Pastebin, or a similar service, where it was publicly posted along with other ephemera such as Minecraft initialization logs. Regardless of the source, this conversation is now shipped as part of the 774M parameter GPT-data set. \nThis is a matter of grave concern. Unless better care is taken of neural network training data, we should expect scandals, lawsuits, and regulatory action to be taken against authors and users of GPT-2 or successor data sets, particularly in jurisdictions with stronger privacy laws. For instance, use of the GPT-2 training data set as it stands may very well be in violation of the European Union's GDPR regulations, insofar as it contains data generated by European users, and I shudder to think of the difficulties in effecting a takedown request under that regulation \u2014 or a legal order under the DMCA. \n\u200b\nHere are some further prompts to try on Talk to Transformer, or your own local GPT-2 instance, which may help identify more exciting privacy concerns!\n\nMy mailing address is\nMy phone number is\nEmail me at\nMy paypal account is\nFollow me on Twitter:\n\nDid I mention the DMCA already? This is because my exploration also suggests that GPT-2 has been trained on copyrighted data, raising further legal implications. Here are a few fun prompts to try:\n\nCopyright\nThis material copyright\nAll rights reserved\nThis article originally appeared\nDo not reproduce without permission\n\n\n61 commentssharesavehidereportall 61 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]jmmcd 51 points52 points53 points 1 month ago\u00a0(22 children)Great work and very important, and there is wider relevance too eg in generative image models trained on copyrighted artworks, and similar. \nA user can naturally plead that the original data was open on the internet, therefore having it in GPT-2 doesn't change anything, but the law won't care about that (perhaps yes when it comes to deciding level of damages but that is after the fact). \nConcerning GDPR - it would be good to be specific about how\/why\/which clauses it contravenes,  because it can be confusing. I don't doubt that there is a problem though.\n\npermalinkembedsavereportgive awardreply[\u2013]wyldphyre 8 points9 points10 points 1 month ago\u00a0(0 children)\nand there is wider relevance too eg in generative image models trained on copyrighted artworks, and similar.\n\nBoy, this seems like a really interesting question.  When those copyrighted artworks go through human intelligence, we often describe resulting art as inspired or influenced by predecessors.  But with an artificial intelligence, should we consider all of the outputs to be derived works?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]farmingvillein 11 points12 points13 points 1 month ago\u00a0(0 children)\nA user can naturally plead that the original data was open on the internet, therefore having it in GPT-2 doesn't change anything, but the law won't care about that (perhaps yes when it comes to deciding level of damages but that is after the fact).\n\nThe law (in the U.S., at least) most certainly will care about it--\"fair use\" is a thing. \nNow, does this usage and re-distribution count as \"fair use\"?  That is a grey area.  But there are large-scale data mining and sharing examples that are currently permitted (cf. web search engines, ability to access cached pages because google\/bing\/etc. have logged them, etc.).\nThis issue invariably won't be resolved until it rolls through the courts, but there is substantial real-world precedence to suggest that this isn't automatically not OK (in the US).\n\npermalinkembedsaveparentreportgive awardreply[\u2013]madokamadokamadoka[S] 5 points6 points7 points 1 month ago*\u00a0(19 children)The GDPR is onerous, and aims to be somewhat extraterritorial, directing the EU and member states to exact compliance from even fully offshore actors through a variety of means, demanding compliance measures as part of the treaties comprising future trade deals. A full analysis cannot fit in this post.\nPersons and organisations subject to the GDPR should regard this data set as utterly accursed.\nTo begin, it seems obvious that some of the text in the training set of GPT-2 qualifies as \"personal data\" under the GDPR:\n\n(1) 'personal data' means any information relating to an identified or identifiable natural person ('data subject'); an identifiable natural person is one who can be identified, directly or indirectly, in particular by reference to an identifier such as a name, an identification number, location data, an online identifier or to one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person;\n\nThere are real names and usernames in this data set. There are links to Twitter posts.\nUnder the GDPR, processing of personal data is forbidden except insofar as it qualifies under a specific set of exemptions:\n\n(a) the data subject has given consent to the processing of his or her personal data for one or more specific purpose;(b) processing is necessary for the performance of a contract to which the data subject is party or in order to take steps at the request of the data subject prior to entering into a contract;(c) processing is necessary for compliance with a legal obligation to which the controller is subject;(d) processing is necessary in order to protect the vital interests of the data subject or of another natural person;(e) processing is necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller;(f) processing is necessary for the purposes of the legitimate interests pursued by the controller or by a third party, except where such interests are overridden by the interests or fundamental rights and freedoms of the data subject which require protection of personal data, in particular where the data subject is a child.\n\nIt is probable that there is data in this dataset which qualifies as \"personal data\" of EU citizens and residents. It is fairly safe to assume that it has been added without consent, that the processing is not necessary for a contract or legal obligation, and that it does not support the vital interests of that person. The lawfulness of this processing is thus very doubtful except insofar as this qualifies as the public interest or a \"legitimate interest\" of the data controller, as defined by the GDPR and interpreted by its regulators. Academic research qualifies, but with caveats, as identified in Article 89.1:\n\n1. Processing for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes, shall be subject to appropriate safeguards, in accordance with this Regulation, for the rights and freedoms of the data subject. Those safeguards shall ensure that technical and organisational measures are in place in particular in order to ensure respect for the principle of data minimisation. Those measures may include pseudonymisation provided that those purposes can be fulfilled in that manner. Where those purposes can be fulfilled by further processing which does not permit or no longer permits the identification of data subjects, those purposes shall be fulfilled in that manner.\n\nI have no reason to believe that GPT-2's training even attempts to meets these safeguards.\nMoreover, even insofar as such processing is lawful, there are a variety of legal obligations which proceed from the processing of these data subjects. For instance, Article 14.1:\n\nWhere personal data have not been obtained from the data subject, the controller shall provide the data subject with the following information:(a) the identity and the contact details of the controller and, where applicable, of the controller's representative;(b) the contact details of the data protection officer, where applicable;(c) the purposes of the processing for which the personal data are intended as well as the legal basis for the processing;(d) the categories of personal data concerned;(e) the recipients or categories of recipients of the personal data, if any;(f) where applicable, that the controller intends to transfer personal data to a recipient in a third country or international organisation and the existence or absence of an adequacy decision by the Commission, or in the case of transfers referred to in Article 46 or 47, or the second subparagraph of Article 49(1), reference to the appropriate or suitable safeguards and the means to obtain a copy of them or where they have been made available.\n\nAnd some of the data above is marked particularly dangerous, as per Article 9.1:\n\nProcessing of personal data revealing racial or ethnic origin, political opinions, religious or philosophical beliefs, or trade union membership, and the processing of genetic data, biometric data for the purpose of uniquely identifying a natural person, data concerning health or data concerning a natural person's sex life or sexual orientation shall be prohibited.\n\n... except as given in very particular circumstances enumerated in Article 9.2, and generally by an organization that has a designated Article 37 data protection officer (part of the responsibilities of extensive processing of Article 9 sensitive data).\nI am confident that I could go on, but this is surely enough.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]HelveticaSanskrit 2 points3 points4 points 1 month ago\u00a0(12 children)I share your many of your concerns about using GPT-2, and this is absolutely a discussion that needs to be had. \nRegarding the GDPR, it seems to me that its intention is to regulate the collection and retention of structured personal data without explicit consent.\nI'm not sure that this includes regulating unstructured data from the web where individuals have publicly identify themselves (personal lifestyle blogs, or Reddit AMAs where the individual volunteers their identity, profession, employer etc. as part of some self promotion, for example).\nAnd what about when writers write about other people, for example when a news site publishes the name and home town of a suspect in crime, or shares the name and age of a recipient of an award?\nFrom what I understand, GPT-2 was collected by scraping web pages that were linked to from Reddit. From a legal standpoint, how is that different to the data storage in our collective browser cache?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]madokamadokamadoka[S] 2 points3 points4 points 1 month ago\u00a0(2 children)\/r\/gdpr may be a better venue for these questions\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sneakpeekbot 0 points1 point2 points 1 month ago\u00a0(0 children)Here's a sneak peek of \/r\/gdpr using the top posts of the year!\n#1: More GDPR humor | 14 comments\n#2: I have updated my #GDPR mindmap. Markers were reviewed, the map was optimized for A4 format, the legend of the map and information about fines (applicable articles was marked) were added. | 13 comments\n#3: Pre-checked cookie boxes don't count as valid consent, says adviser to top EU court | 15 comments\n\nI'm a bot, beep boop | Downvote to remove | Contact me | Info | Opt-out\n\npermalinkembedsaveparentreportgive awardreply[\u2013]HelveticaSanskrit 0 points1 point2 points 1 month ago\u00a0(0 children)Thanks, that sub looks like a great resource.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]imbaczek 1 point2 points3 points 1 month ago\u00a0(1 child)\nFrom what I understand, GPT-2 was collected by scraping web pages that  were linked to from Reddit. From a legal standpoint, how is that  different to the data storage in our collective browser cache?\n\nThe difference is in the purpose of your activities. If you're not doing business\/work, GDPR doesn't apply. There are a few other exemptions: https:\/\/ico.org.uk\/for-organisations\/guide-to-data-protection\/guide-to-the-general-data-protection-regulation-gdpr\/exemptions\/\n\npermalinkembedsaveparentreportgive awardreply[\u2013]HelveticaSanskrit 0 points1 point2 points 1 month ago\u00a0(0 children)Thank you, that looks really useful.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]fell_ratio 0 points1 point2 points 1 month ago\u00a0(5 children)\nI'm not sure that this includes regulating unstructured data from the web where individuals have publicly identify themselves (personal lifestyle blogs, or Reddit AMAs where the individual volunteers their identity, profession, employer etc. as part of some self promotion, for example).\n\nEven if that's true, GDPR has a 'right to be forgotten,' and I don't see how Google is complying with that.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]mniejiki -1 points0 points1 point 1 month ago\u00a0(4 children)Google has a process for de-listing (within the EU) search results that someone claims contain personal information they do not want to be searchable. So, yes, they are complying with it. Media companies, btw, have some sort of GDPR for publishing personal information although I don't know the restrictions and Google is not a media company (it said so itself).\n\npermalinkembedsaveparentreportgive awardreply[\u2013][deleted] 1 month ago\u00a0(3 children)[deleted]\n\n[\u2013]mniejiki 1 point2 points3 points 1 month ago\u00a0(1 child)Presumably, they get sued and fined a bunch of money by the EU. Just because you can't undo a crime doesn't mean you get to not be punished for it.\n\npermalinkembedsavereportgive awardreply[\u2013]fell_ratio 0 points1 point2 points 1 month ago\u00a0(0 children)Yes, that's what I meant.\n\npermalinkembedsavereportgive awardreply[\u2013]mniejiki 0 points1 point2 points 1 month ago\u00a0(0 children)\nAnd what about when writers write about other people, for example when a news site publishes the name and home town of a suspect in crime, or shares the name and age of a recipient of an award?\n\nGDPR has an exception for journalists and the media. Also, many countries actually prevent the media from naming suspects. Google has, themselves, said they are not a media company under GDPR. Furthermore, Google is required to de-link urls that someone tells Google contain their private information (right to be forgotten).\n\npermalinkembedsaveparentreportgive awardreply[\u2013]farmingvillein 3 points4 points5 points 1 month ago\u00a0(4 children)If you read GDPR as narrowly as you are, search engines--as they stand--become illegal.  \nRegardless of whether or not that is the EU's goal (maybe...), that is not reality.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]madokamadokamadoka[S] 0 points1 point2 points 1 month ago*\u00a0(3 children)I am confident that Google and other search engines have done extensive work on GDPR compliance. I presume they operate search-related processing as a \"legitimate interest\" standard (Item F above). For more guidance on legitimate interests available in English, consider the UK's Information Commissioner Office. This will give you some idea of what interests you must consider to lawfully process these data in the EU.\nThe ICO guidance notes that you should not use the legitimate interest standard if \"you intend to use the personal data in ways people are not aware of and do not expect (unless you have a more compelling reason that justifies the unexpected nature of the processing)\". It is reasonable to expect that information on a web page will be indexed by a search engine. It is of course less reasonable to expect that private information entered onto pastebin.com or a similar service will be regurgitated by a sentence-completion program.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]farmingvillein 4 points5 points6 points 1 month ago\u00a0(2 children)You clearly have not actually worked with lawyers to operationalize GDPR, because you're just copy-pasting lines without understanding it at all.\n\nIt is reasonable to expect that information on a web page will be indexed by a search engine. It is of course less reasonable to expect that private information entered onto pastebin.com or a similar service will be regurgitated by a sentence-completion program\n\nThis is not clear at all.  Both are the exact same activity, from a consumer's POV--someone else hoovering up your conversations and doing what they want with it.\nGoogle has no more \"legitimate interest\" than does OpenAI in leveraging this data.  \n\nI am confident that Google and other search engines have done extensive work on GDPR compliance\n\nGoogle, Facebook, and Microsoft have all done large-scale hoovering to train language models and then release their models.  All actions have legal risk, but if the mere \"processing\" of this data had meaningful risk, they wouldn't have done this.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]madokamadokamadoka[S] 1 point2 points3 points 1 month ago\u00a0(1 child)If you have worked with lawyers to operationalize GDPR, then for the purpose of making this conversation more useful to \/r\/machinelearning, I invite you to post a coherent description of the means by which the GDPR does not prohibit the processing of data, given the plain text of the statute.  (Postcript: There are of course means by which it might do so. They are, however, not always quite clear, and the regulators do seem to be of the opinion that you really should not rely on a reason for processing being legal happening to exist in the abstract, without a detailed understanding of what it is.)\nUntil such time I can provide no further input except that a machine learning researcher subject to the GDPR would be better served by consulting with lawyers and GDPR experts on the matter of compliance, rather than relying on Reddit-based analysis which backed only by the vague feeling that \"Google can't possibly be violating the GDPR.\"\n\npermalinkembedsaveparentreportgive awardreply[\u2013]farmingvillein 4 points5 points6 points 1 month ago\u00a0(0 children)\ntext of the statute. (Postcript: There are of course means by which it might do so. They are, however, not always quite clear, and the regulators do seem to be of the opinion that you really should not rely on a reason for processing being legal happening to exist in the abstract, without a detailed understanding of what it is.)\nUntil such time I can provide no further input except that a machine learning researcher subject to the GDPR would be better served by consulting with lawyers\n\nOf course go consult with lawyers.  I am not a lawyer, and neither are you.\nYour analysis, however, is much narrower and declarative than mine.  (Not to mention wrong, but, hey, go talk to lawyers.)\nYou're making a much stronger set of claims than I am.  Stronger claims require stronger evidence.\nRe:Google--of course you're going to take risk with your core products.  Roll the dice and see how close you can get to the fuzzy line.  \nResearch activities?  No.  You're not going to take a $50MM+ hit over some stupid language model.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Tenoke 0 points1 point2 points 1 month ago\u00a0(0 children)Your reading of GDPR Articles seems largely incorrect, though some of those are yet to be challenged in court and decided on what they mean.\n\nThere are real names and usernames in this data set. There are links to Twitter posts.\n\nElon Musk. Twitter.com. \nDo you think my comment is currently in violation of GDPR?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]nbriz 9 points10 points11 points 1 month ago\u00a0(0 children)A couple of years ago I gave a talk about this at a copyright conference. I had been working on some music generation AI software at my studio (based on RNNs) && the copyright questions became very clear to us immediately. Here\u2019s the talk https:\/\/youtu.be\/cSeOyFE9F2A\n\npermalinkembedsavereportgive awardreply[\u2013]MuonManLaserJab 19 points20 points21 points 1 month ago\u00a0(13 children)I was trained on copyrighted data, too. I'm pretty sure I could produce some of it if given a suitably generic prompt.\nI'm more concerned about the privacy implications. If publicly-available IRC conversations can't be trusted to be private, what can?\n\npermalinkembedsavereportgive awardreply[\u2013]APimpNamedAPimpNamed 8 points9 points10 points 1 month ago\u00a0(1 child)\nI was trained on copyrighted data, too. I'm pretty sure I could produce some of it if given a suitably generic prompt.\n\nAnd nobody cares because you don\u2019t scale.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]MuonManLaserJab 2 points3 points4 points 1 month ago\u00a0(0 children)Hey, baby, it scales when it needs to!\n\u200b\nBut seriously, BitTorrent exists. I scale just fine.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]madokamadokamadoka[S] 3 points4 points5 points 1 month ago\u00a0(10 children)\nI'm more concerned about the privacy implications. If publicly-available IRC conversations can't be trusted to be private, what can?\n\nIt is perhaps inevitable that private conversations may, from time to time, be made public in some limited form. It is not inevitable that these conversations are subsequently redistributed in a data set of this sort as part of a continued violation of privacy.\n\nI was trained on copyrighted data, too. I'm pretty sure I could produce some of it if given a suitably generic prompt.\n\nI suppose that this may present some concern at such time as you make yourself available to be copied and used by the machine learning community and by the general public.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]MuonManLaserJab 7 points8 points9 points 1 month ago\u00a0(9 children)\nIt is perhaps inevitable that private conversations may, from time to time, be made public in some limited form.\n\nI wasn't really talking about private conversations. I was talking about public IRC conversations, which are immediately made fully public, not \"in limited form\" \"from time to time.\"\n\nI suppose that this may present some concern at such time as you make yourself available to be copied and used by the machine learning community and by the general public.\n\nIt only has copyrighted material that was available freely on the internet. This is not making it any easier to access that information.\nIt would be pretty dumb if we hamstrung machine learning in the name of protecting publicly-available text from piracy.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]madokamadokamadoka[S] 2 points3 points4 points 1 month ago\u00a0(8 children)Most IRC conversations are made available only to a select group of people present at the time they occur. They are not \u201cfully public\u201d and there is not a reasonable expectation that they will become part of training data halfway across the Internet. (And rightly or wrongly, even \u201cfully public\u201d data \u2014 news reports printed in major newspapers, for example \u2014 can be restricted after the fact in many jurisdictions, especially Europe.)\n\nIt would be pretty dumb if we hamstrung machine learning in the name of protecting publicly-available text from piracy.\n\nAnd it would be pretty dumb if we hamstrung all expectations of privacy and of copyright for the sake of making it incrementally more convenient for machine learning researchers to train their data sets. \nDismissive blanket statements that say you are entitled to do whatever you feel like with stuff on the internet are a very shallow way to engage with the legal and ethical issues at stake here.\n\nIt only has copyrighted material that was available freely on the internet. This is not making it any easier to access that information.\n\nI don\u2019t know if you realize this, but people are allowed to place things on the Internet, without simultaneously giving you permission to do whatever you want with them. The presence of data on the Internet is not a legally binding disclaimer of all rights; nor are you morally entitled to use all public content for any purpose whatsoever. \nAs a researcher, you are broadly entitled to use a lot of publicly available things for research, but that entitlement does not automatically extend to re-releasing portions of the materials as part of a multi gigabyte data set. Encoding the work in an abstruse lossy compression format such as neural network weights does not automatically extend such entitlement, either.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]MuonManLaserJab 1 point2 points3 points 1 month ago*\u00a0(7 children)\nMost IRC conversations are made available only to a select group of people present at the time they occur. They are not \u201cfully public\u201d and there is not a reasonable expectation that they will become part of training data halfway across the Internet.\n\n\"Reasonable\"? If they're not fully public, how did they get into the training data? Did they hack in, or what?\n\nAnd it would be pretty dumb if we hamstrung all expectations of privacy and of copyright for the sake of making it incrementally more convenient for machine learning researchers to train their data sets. \n\nIf you expect privacy when you post stuff where literally the entire world can see it, I have some bad news about the site you're on.\n\nDismissive blanket statements that say you are entitled to do whatever you feel like with stuff on the internet are a very shallow way to engage with the legal and ethical issues at stake here.\n\nI said nothing of the sort. My argument is that you can't expect privacy if you're doing the equivalent of stapling your conversation to everyone's front door.\n\nI don\u2019t know if you realize this, but people are allowed to place things on the Internet, without simultaneously giving you permission to do whatever you want with them. \n\nIt's not \"whatever you want\". It's just, \"reading and learning from it\".\nThere is no downside to making this model available, in terms of making piracy easier. Again, it's all stuff available from links on reddit. The only effect will be on researchers.\nSeems reasonable to call this fair use.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]madokamadokamadoka[S] 4 points5 points6 points 1 month ago*\u00a0(6 children)\n\"Reasonable\"? If they're not fully public, how did they get into the training data? Did they hack in, or what?\n\nOkay, you know what? Fine. Let's work to figure out exactly how this not fully public material got in your training data. \nI have traced the conversation in question. It appears to be part of the Crash Override Network logs leak. I have identified what I presume is the original source of this chat transcript, a Pastebin dump which has since been removed from Pastebin:\nhttps:\/\/pastebin.com\/AvLCEYmc\nI infer that GPT-2 also got it from Pastebin because the material can be found by looking for RAW PASTE DATA. These data are now gone from Pastebin but live on in GPT-2, and I presume the Pastebin dump was the source of these data because I found it while searching for RAW PASTE DATA.\nAccording to Wikipedia,\n\nCrash Override Network was a support group for victims of large scale online abuse, including revenge porn and doxing... Crash Override was founded by game developers Zo\u00eb Quinn and Alex Lifschitz, and was staffed exclusively by victims of online abuse whose identities were kept anonymous outside the group. Quinn and Lifschitz were subjected to online abuse during the Gamergate controversy, having both received death threats and doxing attacks.\n\nOthers opine:\n\nCON is a Twitter trusted resource for dealing with offensive content. It was promoted by Twitter\u2019s @safety account.\n\nPlease, I beg of you, ask members of the Crash Override Network, and any victims of online abuse who they were supporting during these conversations, how they feel about you placing their conversations being in your machine learning model, and the extent to which they feel they have consented to having logs of their abuse available in your data set.\nI will tell you, however, my feelings should I find myself in a similar position. I would opine that that, when my privacy has been violated by someone posting my sensitive conversations it MOST DEFINITELY DOES NOT MEAN that I have given you, in your capacity as a machine learning researcher, permission to FURTHER VIOLATE my privacy by redistributing these conversations, and that redistributing them in a mangled form adds insult to the injury. I would thus be very offended that you feel you are entitled to them, and I would have choice words denouncing your behavior and attitudes as offensive.\nAs I am not a victim, however, I will instead suggest something that would be really nice, and could actively play a role in preventing future backlash against machine learning applications (and, as part of that backlash, possible new legal impairments to machine learning research). It is this. If you, in your capacity as machine learning researcher (or commentator) could work harder to have empathy to the people whose data you are bandying about. If you could assume the necessary degree of humility to countenance the idea that you or researchers in your field might possibly have fault. And if you would apply yourself to think about ways that your work and the work of others could hurt people, rather than just looking for excuses for you to do it anyway, or to excuse it as too much of an inconvenience for you to even begin to attempt. To the extent that all that, in synthesis, would be possible ... that would be really nice.\nI find it irresponsible and inappropriate that these chat data have been made a part of GPT-2, and I respectfully decline to engage with the rest of your posts at this time.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]MuonManLaserJab 3 points4 points5 points 1 month ago*\u00a0(5 children)\nOkay, you know what? Fine. Let's work to figure out exactly how this not fully public material got in your training data.\nI have traced the conversation in question appears to be part of Crash Override Network chat logs leak. I have identified what I presume is the original source of this chat transcript, a Pastebin dump which has since been removed from Pastebin:\n\nIn this case, it's \"public\" because someone already leaked it.\nA minute of googling shows that you can still find the stuff easily. (Obviously. Because it's the internet.)\nSo...what's your point? Yes, it's awful that these conversations were leaked, but what would it accomplish to prevent projects like GPT-2 from producing an incredibly annoying-to-unravel representation of them? Do you think GPT-2 is the easiest way for an internet troll to find these conversations?\n\nPlease, ask members of the Crash Override Network, and those who they were supporting, about how they feel about you placing their conversations being in your machine learning model, and the extent to which they feel they have consented to having logs of their abuse available in your data set.\n\nI'd be happy to ask how much they cared about the already-leaked data being accidently included in something in a form that is incredibly unlikely to cause them a billionth of the troubles they already have suffered from much simpler vectors, but I don't know any of them and don't really want to try bugging them.\nMaybe you could do it, and let me know if they think this matters at all?\n\nAnd if you would apply yourself to think about ways that your work and the work of others could hurt people, rather than just looking for excuses for you to do it anyway, or to excuse it as too much of an inconvenience for you to even begin to attempt. \n\nCould you explain how this would hurt those people? Because again, anyone who wants to find the conversations and harass them can do so.\nI'm not trying to be a shit; I legitimately want to know if I'm missing something.\nAs far as I can tell, none of this will actually matter in practice (as opposed to thought experiments) until we eliminate all of the much-easier ways to access this information. And that would require shutting down the internet, basically. It would be like killing parrots to avoid them telling children that the sky is blue.\nWhat matters, here? If people not being able to access the leaks is what matters, then GPT-2 doesn't make a difference. If what matters is not hurting people's feelings by reminding them how widely the leak has spread, then it might have been best for you to not have published this.\n\nI respectfully decline to engage with the rest of your post at this time.\n\nI respectfully acknowledge that you have respectfully declined.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]madokamadokamadoka[S] -3 points-2 points-1 points 1 month ago\u00a0(4 children)\nSo...what's your point? Yes, it's awful that these conversations were leaking, but what would it accomplish to prevent projects like GPT-2 from producing an incredibly annoying-to-unravel representation of them?\n\nYou are using a dispassionate, outcomes-oriented analysis. You are responding to a violation of rights with a further violation of rights. Because the violated person has already suffered injury, you deem your futher injury inconsequential.\nA few choice idioms to use here: \"adding insult to injury\", \"rubbing salt on the wound\".\nIn practice most people find that it is more appropriate to respond to a violation of rights with a heightened degree of sensitivity, rather than with a sense of opportunism; moreover the idea that you, rather than the person whose rights are violated, are the appropriate party to judge whether further damages are appropriate, further demonstrates disrespect their rights as humans.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]MuonManLaserJab 3 points4 points5 points 1 month ago*\u00a0(3 children)\nYou are using a dispassionate, outcomes-oriented analysis. \n\nYes, thank you. I try.\n\nyou deem your futher injury inconsequential.\n\nNo. What I asked was: what further injury? Is there any? Could you try to explain this in a way that doesn't simply assume that there is damage being done?\n\"Sorry we accidentally copied the leaked conversations. It was on a pastebin we scooped up.\"\n\"That's OK; it was already out there. Mostly I'm just annoyed that \/u\/madokamadokamadoka brought attention to it.\"\n\nrather than with a sense of opportunism\n\nThis is not \"opportunism\". OpenAI isn't laughing all the way to the bank: \"Thank Satan we got away with making all that money off of those Gamergate people! We couldn't have succeeded without rapaciously exploiting this opportunity!\"\nIt's slightly unfortunate that this information wound up there, but nobody did it on purpose to take advantage of anyone, and nobody is suffering for it.\nWhat we're basically doing here is comparing (1) inconvenience to researchers with (2) something that sounds like it might inconvenience a Gamergate victim, but actually won't do anything to them at all (as you seem to acknowledge when you managed to say \"dispassionate, outcomes-oriented analysis\" as though that were a bad thing). Protecting victims is more important, but that doesn't come into play if the victims suffer exactly the same amount regardless of how you train GPT-2 (and I don't see you disputing that).\nNote: I do consider the mental suffering of victims of harrassment to be a negative outcome, which should be taken into account in any dispassionate analysis. The only place we differ is in our estimate of how much suffering is likely to come from the release of an \"encrypted\" copy of text that is already widely available.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]madokamadokamadoka[S] -1 points0 points1 point 1 month ago\u00a0(2 children)Violation of a person\u2019s privacy interests is damage in and of itself! Even when further, future, material damages to reputation or to are probabilistic and uncertain!  \nIt is not your place to tell the person whose privacy you violate, \u201cthis is not harm\u201d! Usurping a person\u2019s role as the natural judge of what constitutes an acceptable privacy risk is further harm! Using past harm to excuse additional harm for the sake of a avoiding inconvenience in procuring training data is opportunism!\n\npermalinkembedsaveparentreportgive awardreplycontinue this thread[\u2013]vahbuna 3 points4 points5 points 1 month ago\u00a0(0 children)reminded me of this:\nhttps:\/\/xkcd.com\/2169\/\n\npermalinkembedsavereportgive awardreply[\u2013]Veedrac 6 points7 points8 points 1 month ago*\u00a0(3 children)\nI queried the data for it, and was able to locate a conversation which I presume appeared in the training data.\n\nWhy are you presuming this? Am I missing something?\nI agree that having recurring usernames talking about a specific topic suggests quite a lot of personal data is stored.\n\npermalinkembedsavereportgive awardreply[\u2013]madokamadokamadoka[S] 6 points7 points8 points 1 month ago\u00a0(2 children)The conversation is date- and time-stamped. It is possible to issue repeated queries for the same timestamps, and nearby timestamps, and fit together outlines of a conversation from the fragments thus presented. \nIf there is another mechanism which would plausibly produce the same effect, besides the original conversation\u2019s presence in the training set, I am not aware of it.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]gnramires 4 points5 points6 points 1 month ago\u00a0(1 child)I think it would be a great investigation to try and locate real (public) sources, and see how often prompts will reproduce them; or locate publicly available conversations it reproduces. Then we can better judge the ability of exact, reliable exfiltration of conversations, which could have privacy implications -- I think that could be quite significant as networks grow larger (and better able to store verbatim content). For small networks if reproduction varies too much (i.e. is not accurate, \"underfits\") then plausible deniability is a decent privacy cover.\nI also think approaches to defend against this should be researched, and they should be relatively easy to implement.\nFor example, during training it can be required that prompts of incomplete input texts should not reproduce the output exactly -- sort of the opposite of the usual training goal (but instead should have a significant probability P of semantic variation, P should be a function of the sample size I guess).\nApplications I have in mind are not only the ability to use non-public data (which is desirable in many cases) while preserving privacy, or for instance training on medical data. If you know a subset of data from a patient medical history that is uniquely identifiable, you don't want a model to reproduce the rest of its conditions reliably. If your model is predicting comorbid conditions (i.e. if you were indeed trying to predict other conditions from inputting a subset of medical history), then your accuracy clearly is must decline from this privacy condition, but I think again plausible deniability should be sufficient (a small impact in accuracy for slightly imperfect reconstruction).\n\npermalinkembedsaveparentreportgive awardreply[\u2013]austacious 2 points3 points4 points 1 month ago*\u00a0(0 children)I did some digging, trolling the network with @gmail frequently outputs github commits. The network output includes the commit checksum which is easily searchable, and could be compared with the rest of the network output to verify reproduction of training data. I'm not going to give up on it yet, but searching a dozen or so truncated checksums on github did not lead to any of the commits outputted by the the network. Neither did searching for the text content of the network output in the github repositories that the network output was pointing to, found via cross-referencing non-anonymized email addresses in the network output to custom author lists present in the repository.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]rmkn85 2 points3 points4 points 1 month ago\u00a0(2 children)Learning algorithms deserve an overview of legal classifications and copyright definition.\nIf a student reads a book so well that they can memorize and recite it, does it means they copied it?\n\npermalinkembedsavereportgive awardreply[\u2013]Veedrac 1 point2 points3 points 1 month ago\u00a0(1 child)https:\/\/en.wikipedia.org\/wiki\/Cryptomnesia\n\npermalinkembedsaveparentreportgive awardreply[\u2013]WikiTextBot 0 points1 point2 points 1 month ago\u00a0(0 children)Cryptomnesia\nCryptomnesia occurs when a forgotten memory returns without its being recognized as such by the subject, who believes it is something new and original. It is a memory bias whereby a person may falsely recall generating a thought, an idea, a tune, a name, or a joke, not deliberately engaging in plagiarism but rather experiencing a memory as if it were a new inspiration.\n\n[ PM | Exclude me | Exclude from subreddit | FAQ \/ Information | Source ]\nDownvote to remove | v0.28\n\npermalinkembedsaveparentreportgive awardreply[\u2013]reciprocal_banana 5 points6 points7 points 1 month ago\u00a0(0 children)Great post. I've also been unnerved at finding references to actual people in gpt-2's verbiage.\n\npermalinkembedsavereportgive awardreply[\u2013]probablyuntrue 4 points5 points6 points 1 month ago\u00a0(4 children)Pretty shocking that it looks like they didn't seem to scrub the dataset at all, especially in regards to copyrighted data\n\npermalinkembedsavereportgive awardreply[\u2013]suddencactus 11 points12 points13 points 1 month ago\u00a0(3 children)I think the point was proof of concept.  They knew the dataset had serious problems like sexism, copyright infringement, and subject matter predilection.  Given that a new state of the art language model appears every three years or so, I can see someone choosing time spent on architecture instead of time spent on a clean dataset.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]shaggorama 0 points1 point2 points 1 month ago\u00a0(2 children)clean that dataset once and you get to use it for all your future architectures\n\npermalinkembedsaveparentreportgive awardreply[\u2013]suddencactus 3 points4 points5 points 1 month ago\u00a0(1 child)Yes, but actually no. This model is fairly good at responding to prompts like \"Trump said \", \"Apple launched a new\", \"Djokovic scored\", \"the last horcrux was\".  \"The researchers used machine learning to\".  \nThere's so much domain knowledge in a language model like this that it starts to get outdated after only 3-4 years, and becomes problematically obsolete in 15 years.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]shaggorama 0 points1 point2 points 1 month ago\u00a0(0 children)Fair point, guess it depends on the anticipated use case.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Equivalent_Quantity 1 point2 points3 points 1 month ago\u00a0(0 children)If you prompt it with something that expects a random \"hash\" as a continuation (e.g. http:\/\/youtube.com\/watch?v=) it usually doesn't give out anything real. One obvious take at this issue is that for human-generated pseudonyms (twitter accounts, e-mail addresses) there is a big chance of stumbling upon an existing username randomly - its probably harder to generate \"username-like\" output and not come across an existing handle, especially when we talk about big platforms.\n\npermalinkembedsavereportgive awardreply[\u2013]cpjw 3 points4 points5 points 1 month ago\u00a0(5 children)Some interesting analysis. However, I think it is putting the concern in the wrong place.\nIf a student turns in an essay with parts of a book copied in, you don't tell them \"stop! You can't read books. Those are copyrighted!\", you teach them express new ideas, and how to properly attribute when they build on others.\nIn the same way we need to not constrain (or \"exfiltrate\") what ideas models can learn from, but instead work on better generative models which are less likely to copy direct quotes without attribution or warning to the user.\n(I said books in this example, but same analogy holds if a human student copies a news article, blog, quote from a tweet, etc)\n\npermalinkembedsavereportgive awardreply[\u2013]madokamadokamadoka[S] 3 points4 points5 points 1 month ago\u00a0(4 children)What I hope to identify is that it matters what the judge tells the plaintiff who pursues a copyright claim against the researchers for including their data in a published data set, or against another party who builds or uses a tool to generate content based on the data \u2014 or, perhaps, how the web host responds to the DMCA complaint. \nSpeaking as if there is a student may point the way to better approaches in ML, but obscures the reality of a reified data set being distributed.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]cpjw 2 points3 points4 points 1 month ago\u00a0(3 children)I agree that the law might have different interpretations and might differ from everyday uses of technology. This is something to keep in mind and maybe push for more up-to-date \/ realistic policy.\nOpenAI didn't distribute the WebText dataset so they couldn't directly be violating a copyright. One could say that GPT-2 is a distribution of the works just in a compressed form, but I find this rather unconvincing (I understand that \"I\" am not a person it matters at all to convince from a legal perspective, but I'll explain my reasoning anyways). \nAs a bad approximation the GPT-2 weights are compressing the dataset into 1\/13th the size (~40GB of text -> ~3GB of weights). However, neither the distributer (openAI) nor the reciever has a reliable way to get back the original works, and weights act more like an analysis\/distillation of things that could be learned from the original text.\nThis seems roughly analogous to if a human took the ~1300 pages in all of Shakespeare's works, and wrote a 100 page analysis of it. This analysis would likely be considered a new work. \nThere isn't any really a way to get back the 1300 pages verbatim. However, if you gave that analysis to a few hundred writers who had never heard of shakespeare, and asked them to write something that Shakespeare was most likely to have a written, at least some of the lines all the writers write might overlap verbatim with actual Shakespeare lines. (This is a flawed analogy, but might roughly get at the idea)\nIt's an interesting thing to think about. Thank you for posting about the issues you mentioned and for starting a discussion.\nHowever, from my (pretty limited) understanding of the law, I don't quite see how GPT-2 distribution or how its currently being used (excluding intentually malicious uses) is putting anyone in legal jeopardy or damaging anyone's privacy. But still interesting ideas to think about in future developments for what we expect of more powerful models.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]imbaczek 0 points1 point2 points 1 month ago\u00a0(0 children)\nThere isn't any really a way to get back the 1300 pages verbatim. \n\nCan you really guarantee that, though? If it becomes possible, does GPT-2 become illegal at that point? If yes, the risk is still there. There may be adversarial inputs that allow extraction of arbitrarily large training data if the model learned to compress input better than we think at this time.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]madokamadokamadoka[S] 0 points1 point2 points 1 month ago\u00a0(1 child)\nAs a bad approximation the GPT-2 weights are compressing the dataset into 1\/13th the size (~40GB of text -> ~3GB of weights). \n\nA quick Google search reveals that lossless compression programs, without external dictionaries, can achieve ~8:1 compression ratios on English text. Lossy compression on images like JPEG routinely achieves 10:1 compression with no noticeable loss in quality, and can be tuned for more.\nIf one is copying a copyrighted image, it is unlikely that using a 13:1 lossy-compression JPEG will be a defense itself.\n\nThis seems roughly analogous to if a human took the ~1300 pages in all of Shakespeare's works, and wrote a 100 page analysis of it.\n\nA typical human's 100-page analysis of Shakespeare looks very little like Shakespeare's works. A GPT-2 impersonation of a work may resemble that work substantially.\n\nThere isn't any really a way to get back the 1300 pages verbatim.\n\nThe inconvenience of retrieval may be a mitigating factor, limiting the actual damages suffered by the owner of a work, and thus the amount they might claim in a suit \u2014 but I'm not sure it would be sufficient by itself to defend against a copyright suit.\n\nI don't quite see how GPT-2 distribution or how its currently being used is putting anyone in legal jeopardy\n\nAt a minimum, I think that anyone whose material seems to appear in the GPT-2 data set has a reasonable case to issue a DMCA takedown notice against anyone hosting or using the data set \u2014 goodness knows spurious takedown notices have been issued on far flimsier grounds. \nSome GPT-2 copyright notice examples:\n\nCopyright 2014 by STATS LLC and Associated Press. Any commercial use or distribution without the express written consent of STATS LLC and Associated Press is strictly prohibited \nCopyright 2015 by CBS San Francisco and Bay City News Service. All rights reserved. This material may not be published, broadcast, rewritten or redistributed.\nCopyright 2015 ABC News\nCopyright 2015 WCSF\nCopyright 2016 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed.\nCopyright 2017 KXTV\nCopyright 2017 NPR. All rights reserved. Visit our website terms of use and permissions pages at www.npr.org for further information.\nNPR transcripts are created on a rush deadline by Verb8tm, Inc., an NPR contractor, and produced using a proprietary transcription process developed with NPR. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR's programming is the audio record.\nCopyright 2018 by KPRC Click2Houston - All rights reserved.\nCopyright 2000, The Washington Post Company (hereinafter the \"Company\"); the Post, Inc.; and Post Publishing Company (hereinafter the \"Publishing Company\").\n4\nIn addition to providing news and entertainment content, \"The Post\" and Post Publishing Company, Inc. publish periodicals (together with its affiliates, \"the Company's Periodicals\") in print and electronic formats. The Company publishes periodicals in four business units: The Washington Post Media Group, Inc., and its print, cable, and digital websites, The Washington Post.com and the \"D.C. Bureau\" of The Post newspaper, and its social media, search, and other features. The Post's social media, search, and other features, \"The D.C. Bureau,\" a joint venture of The Post and the Post's publishing, editorial, and advertising businesses, generate revenue primarily from advertising impressions, referring requests, and visits (\"ads\"), all of which will be included in the ad unit's cash flow statement, which consists of an operating income statement and a cash flow statement, including the component for interest expense payable. Advertising impressions include impressions from advertising services providers, search engine results, third-\nThese materials copyright the American Society of Mechanical Engineers.\nNote: This item has been cited by the following publications:\nH. J. P. Smith, \"The Effects of Fire on Machinery and its Mechanical Properties,\" American Journal of Industrial and Business Mechanics, Vol. 5, October 1905, pp. 693-696, 703-716, 724, 731.\nW. D. Lehn, \"The Effect of Fire Upon the Mechanical Properties of Metal,\" Proceedings of the Institute of Machinery, May 1883, pp. 453-457.\nThese materials copyright \u00a9 1999-2017 by Bantam Spectra, Inc. under license to Little, Brown and Company. The copyright for other materials appears after the excerpted passages.\nThese materials copyright \u00a9 1996 - 2018 by the University of Nottingham, all rights reserved.\nThese materials copyright \u00a9 2012 Robert Wood Johnson Foundation. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed)\nThese materials copyright 1995-2018 John Wiley & Sons, Ltd.\nThe material on this page is presented for general information purposes only to aid educators and others interested in the subject.\nThese sources are copyright and may not be used without permission from John Wiley & Sons, Ltd. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior permission of the publisher.\nDisclaimer: The information contained in this web site is provided as a general reference only and should not be considered an exhaustive or exclusive list of references. The information contains in this web site does not constitute legal or professional advice and should not be used as a substitute for expert advice.\nThese materials copyright the author or reprinted by permission of Hachette Book Group.\nThese materials are licensed under the Creative Commons Attribution-NonCommercial 3.0 Unported License. In accordance with their license, copyright holders may use the material only for noncommercial purposes, which may include but is not limited to display, online display, and distribution of material, for purposes of commentary, teaching or scholarship.\nThese materials are licensed under a Creative Commons Attribution-Noncommercial-Share Alike 3.0 License , which permits unrestricted non-commercial use, sharing, and reproduction in any medium, provided the original author(s) and source are credited in the text. You are only allowed to use, copy, modify and distribute the content of this guide for personal benefit and educational purposes.\nThese materials are licensed by the U.K.'s Advertising Standards Authority and may not be used without a licence.\nCopyright 20th Century Fox. Studio Fox TV.\nThis segment was produced by The Current's Melissa Korn. Follow The Current on Twitter @TheCurrentPolitic.\n\nIf you used or distributed the GPT-2 and received a takedown notice or a Cease and Desist letter or a Court Order from one of these parties demanding you remove content from your site or your software distribution, would you have the tools to comply?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Phantine 1 point2 points3 points 1 month ago\u00a0(0 children)\nNote: This item has been cited by the following publications:\nH. J. P. Smith, \"The Effects of Fire on Machinery and its Mechanical Properties,\" American Journal of Industrial and Business Mechanics, Vol. 5, October 1905, pp. 693-696, 703-716, 724, 731.\nW. D. Lehn, \"The Effect of Fire Upon the Mechanical Properties of Metal,\" Proceedings of the Institute of Machinery, May 1883, pp. 453-457.\n\nYou do realize that neither of those journals or articles exist, right?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]TotesMessenger 0 points1 point2 points 1 month ago\u00a0(0 children)I'm a bot, bleep, bloop. Someone has linked to this thread from another place on reddit:\n\n[\/r\/stallmanwasright] [Discussion] Exfiltrating copyright notices, news articles, and IRC conversations from the 774M parameter GPT-2 data set\n\n\u00a0If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads. (Info \/ Contact)\n\npermalinkembedsavereportgive awardreply[\u2013]zergling103 0 points1 point2 points 1 month ago\u00a0(0 children)I wonder if you could explicitly set a penalty in the loss function to not replicate the training data verbatim. Though that may be hard to pull off...\nYou'd probably just need to anonymize the training data and modify it just enough to avoid copyright issues.\n\npermalinkembedsavereportgive awardreply[\u2013]Phantine 0 points1 point2 points 1 month ago\u00a0(0 children)\nWhile the output is fragmentary and should not be relied on, general features persist across multiple searches, strongly suggesting that GPT-2 is regurgitating fragments of a real conversation on IRC or a similar medium. The general topic of conversation seems to cover Gamergate, and individual usernames recur, along with real Twitter links. I assume this conversation was loaded off of Pastebin, or a similar service, where it was publicly posted along with other ephemera such as Minecraft initialization logs. Regardless of the source, this conversation is now shipped as part of the 774M parameter GPT-data set. \n\nIf you can't trace down the original conversation, what evidence do you have that you didn't just get Turing-tested?\nThe excerpt you gave has the same weird cadence that most GPT text does.\n\npermalinkembedsavereportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 17088 on  r2-app-065a69a536c4a013c  at 2019-11-19 20:44:48.114082+00:00 running 2367a59 country code: US."
  },
  "23":{
    "title":"[D] what are you using? tensorflow vs pytorch : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-gaming-pics-worldnews-funny-todayilearned-tifu-aww-movies-videos-Jokes-gifs-science-mildlyinteresting-Showerthoughts-nottheonion-television-UpliftingNews-OldSchoolCool-dataisbeautiful-sports-personalfinance-explainlikeimfive-GetMotivated-TwoXChromosomes-askscience-nosleep-IAmA-space-LifeProTips-Futurology-gadgets-books-food-Art-Music-WritingPrompts-photoshopbattles-EarthPorn-DIY-Documentaries-history-creepy-listentothis-philosophy-announcements-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  13 May 201996 points (96% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave820,746 readers2,021 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X185  \u00b7 38 comments How to detect AI Snake oil177  \u00b7 41 comments [D] Early coauthorship with top scientists predicts success in academic careers5  \u00b7 2 comments [Discussion] Advice needed: Feeling trapped by lack of management\/strategy, no implemented models.20  \u00b7 7 comments [D] Regarding the ability of neural networks to learn \"simple\" examples first3  \u00b7 1 comment [P] Machine Learning Flight Rules5  \u00b7 1 comment [Research] Announcing Kaolin - PyTorch Library for Accelerating 3D Deep Learning Research218  \u00b7 13 comments [P] How to apply machine learning and deep learning methods to audio analysis5  \u00b7 1 comment [D] Is it ill-advised to perform transfer learning with generalized linear models?18  \u00b7 15 comments [P] askgpt.com I built a simple ui to converse with gpt-2222  \u00b7 15 comments [R] How Machine Learning Can Help Unlock the World of Ancient Japan (by Alex Lamb)Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7959697Discussion[D] what are you using? tensorflow vs pytorch (self.MachineLearning)submitted 6 months ago by mesmer_adamaJust want to take the temperature of the community at this point in time. What are you using for research and production right now, tensorflow or pytorch? What is your experiences with speed of development for writing papers, code quality and eventual release to a production environment?\nAnd if you want to elaborate what more do you use in conjunction, git for versioning, tensorboard for monitoring and docker for environment or something completely different?\nPersonally I've been using pytorch for smaller experiments and my local environment but will start doing larger experiments and want to learn from you all.\n\n86 commentssharesavehidereportall 86 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]BeatLeJuce 124 points125 points126 points 6 months ago\u00a0(19 children)PyTorch. I have used TF extensively before (by now I have over 2 years experience in each of these frameworks), so I think I can give an educated opinion. TF is severely less usable in my view, but unfortunately has some \"enterprise\" features (e.g. easy deployment in browsers or phones, integrated dashboards, more included support for scaling to several servers) that make it attractive from a business perspective. But from a purely development perspective (and definitely from a research perspective), PyTorch is much nicer to work with -- easier to debug, no need to learn convoluted APIs (that constantly keep changing\/being deprecated from under you), directer (no reasoning about graphs), easier to access (no fiddling with graph APIs), much nicer C++ interface, and overall more pythonic. And TF 2.0 will only solve some of these problems, but is (in my opinion) still inferior to PyTorch in many ways.\n\npermalinkembedsavegive award[\u2013]Lietadlo5 25 points26 points27 points 6 months ago\u00a0(8 children)which of the problems is not addressed by TF2.0 in your opinion?\n\npermalinkembedsaveparentgive award[\u2013]BeatLeJuce 44 points45 points46 points 6 months ago*\u00a0(7 children)\nthe data pipeline: it's still encouraged to re-package my data into a tfrecords file. For no other reason than \"because that's just how we suggest you do things\".\nthe API explosion: there is no reason to believe that the deprecation of old APIs over new ones and the introduction of more and more APIs will stop. That's how Google operates.\n\"enterprise-y\"-ness: this is both a blessing and a curse: TF offers you more, but that also makes the API larger and more complex. Can you guess what tf.distribute.experimental.MultiWorkerMirroredStrategy does? Neither can I, but I'm guessing it has little to do with deep learning. Don't get me wrong: There's probably some corner-usecase where it will be nice that this thing exists, and for the most part its nicely capsulated and moved into sub-sub-packages I don't care about. But I prefer KISSS over large public APIs. There is lots of functionality that most people will just never use, and lots of subtle differences that are very hard to tease out -- e.g. have fun figuring out the difference between a \"Training Checkpoint\" and a \"Saved Model\" (both are commonly used in TF 2.0, and no, they are not the same thing).\n\n\npermalinkembedsaveparentgive award[\u2013]Lietadlo5 2 points3 points4 points 6 months ago\u00a0(6 children)I get the convoluted API, but there is a lot of reasons for tfrecords:\n\nperformance - binary format is smaller and faster to read.\nconvenience - you don't have to deal with batches, shuffling etc, especially useful for datasets that are too big to fit into memory.\nready-to-use - you can very easily connect the TFR file into your model.\nunified interface across data modalities - you work the same way with images, text, vectors etc.\n\nIt might be overkill for smaller projects, but I would not want to go back to other formats. Especially with bigger projects, when you work in teams and you need to keep versioning your dataset. I remember when I was manually coding all of the data processing infrastructure and I am glad I don't have to do it  anymore.\n\npermalinkembedsaveparentgive award[\u2013]BeatLeJuce 31 points32 points33 points 6 months ago*\u00a0(5 children)None of your points are inherent to (or necessarily require) TFRecords. PyTorch's API allows you all of these points without forcing you to convert your data.\n1: performance: JPEG, PNG, MP3, MPEG4, etc. are already binary, and are, in fact, stored in TFRecords exactly as-is. Most text-formats come as gzipped, so they're efficiently stored, too (and can be unpacked on the fly). In my own benchmarks, PyTorch's data loader was as efficient as reading from TFRecords, even on large data sets.\n2-4: Every decent data loader in every other API also offers this.\nI'm not sure what you mean with \"versioning\", as TFRecords itself (as far as I know, please correct me) does not directly support this. It's essentially the difference between \"copy the TFRecords file\" and \"copy the data directory\", or am I missing something?\nThe only advantage TFRecords has over normal data is that it's better supported in Google's internal services (where Protobuf backed things are the norm). So e.g. accesses across networked storage is more efficient, at least within Google (AFAIK). However, for users outside Google (i.e., the rest of us), this is not a plus (it might be on GCP, I wouldn't know).\nHowever, what you lose is some flexibility: It's easier to add intermediate steps in PyTorch (e.g. some intensive data-augmentation, or stuff like this ), because in TF, you never have the \"raw data\" in an accessible way.\nEDIT: with that said: I really like the tf.data pipeline overall. It's a big improvement over what TF had before, and there are usecases where it allows for more elegant code than the equivalent in PyTorch. My main beef is with having to rewrite all my images\/videos\/audio\/... into a new, inacessible storage format first. If I then stumble upon a bug\/surprising result, and then want to check that my raw data was ok, I can't just open the input file in my file browser. I first have to write some code to parse a TFRecords file first. That's annoying.\n\npermalinkembedsaveparentgive award[\u2013]ppwwyyxx 2 points3 points4 points 6 months ago\u00a0(0 children)In addition to what you said, `tf.data` (or using graph to read data) does not make a lot of sense to me either.\nWhy would you ever want to use a graph to describe your work? I can see the following benefits:\n\nauto diff\nexecution on different devices\nserialization of your work\nauto performance optimization\n\n1 is not needed in data processing.\n2 is officially not recommended (the official guide recommend doing data processing on CPU for best performance)\n3 is rarely needed, IMHO, for data processing. Perhaps only needed for inference\n4 is true. But in a training, as long as the data pipeline is fast enough (to keep the GPU full util), getting faster does not bring more benefits.\n\npermalinkembedsaveparentgive award[\u2013]danijar 0 points1 point2 points 6 months ago\u00a0(1 child)You can create a data pipeline from a Python generator that yields dicts of numpy arrays. For example, it can read or generate data in any way and do some cheap preprocessing. Then you can add more preprocessing (shuffling, batching, data augmentation) that should run in parallel as additional steps to the pipeline. Best of both worlds :)\n\npermalinkembedsaveparentgive award[\u2013]logicchains 5 points6 points7 points 6 months ago\u00a0(0 children)Creating a tf.Dataset from a generator won't work properly if you try to distribute the training on GCP, losing one of the biggest advantages of Tensorflow.\n\npermalinkembedsaveparentgive award[\u2013]BatmantoshReturns 0 points1 point2 points 6 months ago\u00a0(1 child)\nThe only advantage TFRecords has over normal data is that it's better supported in Google's internal services (where Protobuf backed things are the norm). So e.g. accesses across networked storage is more efficient, at least within Google (AFAIK). However, for users outside Google (i.e., the rest of us), this is not a plus (it might be on GCP, I wouldn't know).\n\neli20?\n\npermalinkembedsaveparentgive award[\u2013]BeatLeJuce 1 point2 points3 points 6 months ago\u00a0(0 children)TFRecords is based on Protobufs. Within google (who is the main user of Tensorflow), protobufs are super-easy and normal to use. Outside of google, they don't bring any benefit. So while TRecords might be great for internal use at google, everyone else doesn't get the same benefits.\n\npermalinkembedsaveparentgive award[\u2013]DataScienceUTA 6 points7 points8 points 6 months ago\u00a0(0 children)I see pytorch being preferred by academics from here on out\n\npermalinkembedsaveparentgive award[\u2013]mesmer_adama[S] 4 points5 points6 points 6 months ago\u00a0(0 children)Awesome, thanks for your input! One more point goes to PyTorch then :)\n\npermalinkembedsaveparentgive award[\u2013]Naunauyoh 4 points5 points6 points 6 months ago\u00a0(4 children)Did you observe any difference in the training time? Because, while I agree that PyTorch is much nicer to use, it seems to be a bit slower than TF in certain task (in our case it was variational auto-encoders).\n\npermalinkembedsaveparentgive award[\u2013]BeatLeJuce 18 points19 points20 points 6 months ago\u00a0(1 child)To be honest, it's been a long time since I benchmarked -- these days, I care more about my productivity than 10% execution speed difference. If a training run takes more than 1 day (which is typical for most of my research), then I don't care if I have to wait a few hours more or less, I have context-switched to some other task in the meantime anyways. With that said: I'd be interested in a recent benchmark, if anyone has one to offer. But I'd be surprised if there are significant differences, given that in the end most runtime boils down to the same calls in cuDNN.\n\npermalinkembedsaveparentgive award[\u2013]Karyo_Ten 14 points15 points16 points 6 months ago\u00a0(0 children)I'm sure you didn't try Tensorflow\/Keras RNNs :P\nHint: use the CudnnLSTM\/CudnnGRU instead as TF RNNs are a disaster speedwise.\n\npermalinkembedsaveparentgive award[\u2013]WolfThawra 2 points3 points4 points 6 months ago*\u00a0(2 children)\nBut from a purely development perspective (and definitely from a research perspective), PyTorch is much nicer to work with\n\nTell me about it.... I'm using TF (for research, well, that's what I tell myself).\n\nconvoluted APIs (that constantly keep changing\/being deprecated from under you)\n\nOh I don't have to worry about that, we're not updating the NVIDIA driver on our server, so we can't update CUDA, so I can't update TensorFlow. TF 1.9 it is, I suppose.\nEDIT: slightly confused about the downvotes? As in, I genuinely would like to know what people are unhappy about.\n\npermalinkembedsaveparentgive award[\u2013][deleted] 6 months ago*\u00a0(1 child)[deleted]\n\n[\u2013]WolfThawra 1 point2 points3 points 6 months ago\u00a0(0 children)Yeah I mean I'd love to upgrade but floating the idea of maaaaaybe updating the NVIDIA driver on the server was not received particularly well.\n\npermalinkembedsavegive award[\u2013]logicchains 15 points16 points17 points 6 months ago\u00a0(4 children)Using Julia's Flux. Was previously using Tensorflow, with a C++ pipeline doing some heavy data preprocessing. Moving to Julia meant I could move that pipeline into pure Julia (it's nearly as fast as C++), and turns out preprocessing on the fly and reading the results from RAM is faster than TF reading the (dense) preprocessed data from disk. Flux is also way faster for custom recurrent architectures than tf.while_loop (and will be orders of magnitude faster once Zygote is complete https:\/\/github.com\/FluxML\/Zygote.jl). \nSome of my colleagues still have to use Tensorflow, as they're working with larger datasets and models so need the excellent distributed training support that Google Cloud Platform has for Tensorflow. The TF API (and regular deprecations) is a constant source of complaints, so much so that \"Google\" has even taken on another meaning for us. \"What, you mean Estimators are being deprecated? Oh man, that really Googled my shit right up, so much stuff to rewrite!\" \u201cYou lost half a day before you realised they'd mixed the loss(labels, predictions) and loss(predictions, labels) conventions? Man, they really Googled you good!\" \nTensorflow API design seems motivated to some degree by the needs of Google employees to get promoted by releasing new features, whereas Pytorch in contrast seems much more stable (although its 1.0 was much more recent). Tensorflow managed to go through three higher-level neural net APIs in as many years (tf.nn, tf.layers, tf.estimator), and is now on yet another, tf.keras.\n\npermalinkembedsavegive award[\u2013]CampfireHeadphase 1 point2 points3 points 4 months ago\u00a0(1 child)A bit late, but: How does flux compare to tf performance-wise? Couldn't find andy good benchmarks..\n\npermalinkembedsaveparentgive award[\u2013]logicchains 0 points1 point2 points 4 months ago\u00a0(0 children)I haven't used Flux for traditional architectures, but for custom recurrent architectures it's much faster as the framework overhead is significantly less. You can also build recurrent structures naturally, whereas in TF you have to use TF.while_loop as if you just build an unrolled graph directly it can take over a minute to construct the graph (at least in TF 1, haven't tried TF 2). https:\/\/arxiv.org\/abs\/1810.07951 has some benchmarks of Flux's next gen backprop approach against Pytorch, and Pytorch perf is generally similar to TensorFlow's for stuff that involves lots of ops on large matrices.\n\npermalinkembedsaveparentgive award[\u2013]FlynnClubbaire 0 points1 point2 points 6 months ago\u00a0(1 child)Uuughhh.\nI'm just getting into machine learning, and let me tell you, pre-processing is taking literally 90% of my compute time.\nIn theory, everything I'm doing should be doable on the fly, but numpy is just terrible at it. How good do you reckon Julia would be at transposing data a few times, basic normalization, and reshaping?\n\npermalinkembedsaveparentgive award[\u2013]logicchains 0 points1 point2 points 6 months ago\u00a0(0 children)With a little work Julia can get within 70-80% of optimal C++ speed. But if everything you're doing fits into Numpy, have you tried Numba (http:\/\/numba.pydata.org\/)? Just a single annotation can optimise a pure Numpy-using function into something pretty fast, even if it uses iteration. Where Julia really helps performance is when you want to do anything that doesn't fit well into Numpy, e.g. fancy IO, or using a dictionary, class or dataframe, as Numba can't help with that. But if Numba supports what you're doing, it shouldn't be significantly slower than the same thing in Julia (and much easier to use if you've already written the Numpy code).\nIf you want to work on actual streaming data, then Julia would be much faster as Numpy arrays don't really support streaming.\n\npermalinkembedsaveparentgive award[\u2013]Rezo-Acken 15 points16 points17 points 6 months ago\u00a0(1 child)I learned DL through Keras and use Pytorch nowadays. I have limited experience with TF but always hated it. \nI'm happy with Pytorch. It's simple to use and still gives good control of your models.\n\npermalinkembedsavegive award[\u2013]Overload175 0 points1 point2 points 6 months ago\u00a0(0 children)If you\u2019re experienced with Keras, the TensorFlow 2.0 api should feel natural. It allows specification of models that are essentially stacked tf.keras layers.\n\npermalinkembedsaveparentgive award[\u2013]marmakoide 13 points14 points15 points 6 months ago\u00a0(0 children)I use Pytorch because I found the API easier to learn. When I first used it to experiment ideas with, figuring out how to do things was intuitive and didn't took a lot of searching to get from A to B. I used only to test ideas, never used in a production application running 24\/24 7\/7 over many servers.\n\npermalinkembedsavegive award[\u2013]soft-error 18 points19 points20 points 6 months ago\u00a0(3 children)I use Flux, for Julia, purely for academic purposes. But I've been thinking about learning PyTorch on the side for a while, just by seeing how popular it's on academia.\n\npermalinkembedsavegive award[\u2013][deleted] 1 point2 points3 points 6 months ago\u00a0(2 children)Do you know what the GC situation is in Flux ? Last I checked they were having OOM errors while doing AD.\n\npermalinkembedsaveparent[\u2013]soft-error 0 points1 point2 points 6 months ago\u00a0(1 child)Frankly, I never experienced it, but my problems all fit into memory. Which version were you running? \nGoogling around got me this: https:\/\/discourse.julialang.org\/t\/how-do-i-release-flux-tracker-allocated-memory\/14663\/4\n\npermalinkembedsaveparentgive award[\u2013][deleted] 0 points1 point2 points 6 months ago\u00a0(0 children)I haven't personally run it, but there was a bug report earlier which reported being limited to miniscule batch-sizes on Inception because of the lack of a memory-pool based management. I should give it another try.\n\npermalinkembedsaveparent[\u2013]yaroslavvb 10 points11 points12 points 6 months ago*\u00a0(1 child)I've been using PyTorch for larger experiments, mostly because a few PyTorch implementations were easy to get working on multiple machines. Initially I started with multi-machine TensorFlow by following the High-Performance Models guide and it ended up being too much work to get decent performance.\n\u200b\nOther details:\n- no docker, startup\/pull time was too slow. Just put things in requirements.txt  and pip install that inside conda env.\n- for reruns, edit things locally, use syncing script to keep local folder in sync with remote machines,  mosh+tmux on remote machine\n- no Kubernetes, pod allocation was too slow, raw AWS instead\n- git\/github for version control\n- Tensorboard to monitor runs and make different collections of runs by manually symlinking folders, plan on trying Weights&Biases to simplify\n\npermalinkembedsavegive award[\u2013]ceceshao1 0 points1 point2 points 6 months ago\u00a0(0 children)Would also suggest Comet.ml\n\npermalinkembedsaveparentgive award[\u2013]seraschka 9 points10 points11 points 6 months ago\u00a0(0 children)Personally, I prefer PyTorch because it's easier to use when experimenting with custom stuff. I still use Tf occasionally in collaborations, and it's okay too, not as terrible as it sometimes sounds like. Tf has a few usability trade-offs though due to also having the multi-cluster setups at Google and deployment in mind. I don't need these features, which is why it doesn't really make sense for me to use Tf for my research projects over PyTorch, but like I said, Tf is still a solid, and usable framework.\n\u200b\nIt's like using a good pocket knife for eating your steak at lunch. It works well if it's a good knife, but there is no reason to use it over a regular steak knife if you don't need all the extra features.\n\npermalinkembedsavegive award[\u2013]approximately_wrong 8 points9 points10 points 6 months ago\u00a0(0 children)Sometime earlier last year, almost everyone in my lab was using TensorFlow. Then, by sheer coincidence, everyone in my lab independently made the switch to PyTorch. I still use tensorboard though.\n\npermalinkembedsavegive award[\u2013]Made-ix 6 points7 points8 points 6 months ago\u00a0(4 children)For those in the pytorch camp, how are you deploying your models? I\u2019m not in love with tensorflow, but the deployment story is pretty smooth and well integrated.\n\npermalinkembedsavegive award[\u2013]dhruvdh 11 points12 points13 points 6 months ago\u00a0(2 children)There's a number of ways. But if you like the way tensorflow does it you can just export PyTorch models as ONNX and then load it up in TF and do whatever you want.\n\npermalinkembedsaveparentgive award[\u2013]realhamster 0 points1 point2 points 5 months ago\u00a0(1 child)Have you tried the ONNX -> TF thing? I've heard there are some operations not supported, and that in general you'll usually find some corner case which will slow you down.\n\npermalinkembedsaveparentgive award[\u2013]dhruvdh 1 point2 points3 points 5 months ago\u00a0(0 children)No I've never really come across operations that don't work. I've never needed to port anything that uses any fancy operations, so maybe that's why.\nIf you care about performance, and mostly are looking into using the network for inference, I would say also look at TVM. They're doing some great, underappreciated work.\n\npermalinkembedsaveparentgive award[\u2013]Brudaks 26 points27 points28 points 6 months ago\u00a0(5 children)Keras has a nice API which is the key weak point of TF 1.x, so I've been using that. With TF 2.0 I'll keep using the same Keras API, so I'll get \"merged back\" in to TF fold which is kind of nice as it'll be more integrated with the convienience features of TF such as Tensorboard. \nTPU availability is a big thing, though; the free TPU on Colab gets me 27x faster training than I can do on a GPU, which makes quite a difference. last I checked, PyTorch was supposed to have it \"any time soon\" but didn't have it yet, perhaps it does now.\n\npermalinkembedsavegive award[\u2013]bobchennan 3 points4 points5 points 6 months ago\u00a0(0 children)https:\/\/github.com\/pytorch\/xla\/blob\/master\/contrib\/colab\/PyTorch_TPU_XRT_1_13.ipynb\n\npermalinkembedsaveparentgive award[\u2013]BatmantoshReturns 2 points3 points4 points 6 months ago\u00a0(0 children)TPU with Keras on colab? It looks like you don't even need a google cloud account with that. The weights save to colab right?\n\npermalinkembedsaveparentgive award[\u2013]rowanobrian 2 points3 points4 points 6 months ago\u00a0(2 children)When does TPU work well? I mean in which scenario?\nWhen I saw TPU in colab, tried it out on mnist, found no difference.\n\npermalinkembedsaveparentgive award[\u2013]Brudaks 6 points7 points8 points 6 months ago*\u00a0(0 children)MNIST (and CIFAR) is a bad benchmark for speed tests because they run matrix operations on really tiny matrices, which is not representative for anything where speed matters (I guess MNIST would become I\/O limited? or the overhead\/latency of using the remote TPU becomes too much for many tiny operations) - in pretty much every large task you get much, much bigger layers; the same goes for batch sizes - generally for speed reasons you'd use as large batches as your GPU RAM allows (which won't be much if the memory needs for every sample is large), and then the raw performance difference becomes significant; but for MNIST that'd mean having a \"mini\"batch of all samples at once which isn't good for accuracy and convergence. On TPU I see a slight boost (~3x) when doing the same paramaters as on GPU, but the big boost happens by having 16 times larger batches and doing so in large portions to streamline I\/O (the first couple minutes are always much slower for some reason while the remaining hours are at a very stable speed).\nAFAIK RNN's are worse on parallelization and so it might not get a boost (I haven't tried that), but language tasks are now moving to transformer (self-attention) based architectures and TPUs are well suited for that, that's where I get that 27x speed difference; as far as I see from what others are trying with CNN\/ImageNet tasks, you get a ~20x speed difference on that as well over colab's GPUs (K80).\n\npermalinkembedsaveparentgive award[\u2013]SedditorX 1 point2 points3 points 6 months ago\u00a0(0 children)I'm pretty sure you can solve MNIST even with linear regression so TPUs might be overkill. You wouldn't use GPUs to multiply two integers quickly.\n\npermalinkembedsaveparentgive award[\u2013]Captain_Flashheart 20 points21 points22 points 6 months ago\u00a0(1 child)Keras \/ Tensorflow here. PyTorch seems more popular in academia the past 12 months or so, but I've yet to meet anyone working with PyTorch at work. It's always tensorflow or something really old they picked up while still at university. Maybe I'll become a tensorflow dinosaur as well? ;)\n\npermalinkembedsavegive award[\u2013]Richard_wth 11 points12 points13 points 6 months ago\u00a0(0 children)I met a Snapchat engineer at a conference. He said they used PyTorch for research as well as product...but I\u2019m a TensorFlow dinosaur as well.\n\npermalinkembedsaveparentgive award[\u2013]sieisteinmodel 6 points7 points8 points 6 months ago\u00a0(1 child)What about JAX?\n\npermalinkembedsavegive award[\u2013]farmingvillein 5 points6 points7 points 6 months ago\u00a0(0 children)Like part of the Google Brain team, interesting point: https:\/\/github.com\/tensorflow\/tensor2tensor\/tree\/master\/tensor2tensor\/trax\n\npermalinkembedsaveparentgive award[\u2013]ice_aggregate 4 points5 points6 points 6 months ago\u00a0(0 children)TensorFlow + Keras since I'm much more familiar with the tools and have been using them for 3-4 years now. Switching would mean relearning another system and unless I have a strong reason to move, I'm sticking with what I know.\n\npermalinkembedsavegive award[\u2013]grappling_hook 3 points4 points5 points 6 months ago\u00a0(0 children)I use tensorflow, never really tried pytorch though. Maybe for my next project.\n\npermalinkembedsavegive award[\u2013]Professor_Entropy 3 points4 points5 points 6 months ago*\u00a0(0 children)I wanted to move from pure keras to using tf.keras since that is what tf 2.0 is all about. Decided to never write any tf code from scratch after wasting time due to this old tf.keras issue which hasn't been fixed yet. When I was getting the error I questioned my abilities and it affected my confidence.\n\u200b\nTried pytorch, learnt it in a day, loved it. Intuitive, customizable, fast, consistent and less headache. I still need to use tensorflow since google and openai release their models in tf. We can train BERT on TPU only through google's official tf repository, as pytorch repositories don't support it yet.\n\npermalinkembedsavegive award[\u2013]GradMiku 2 points3 points4 points 6 months ago\u00a0(1 child)I'm going to move to PyTorch, because i tested 2 different implementations of the same architecture(CapsNet) and in keras\/tensorflow the training time was 6h and the same epochs and data the training in PyTorch only takes one hour\n\npermalinkembedsavegive award[\u2013]dhruvdh 0 points1 point2 points 6 months ago\u00a0(0 children)You should note that CapsNet is non-traditional so it makes sense that neural network frameworks are not optimized for those. In my experience PyTorch is slightly faster too, but I don't think just trying out CapsNet and concluding PyTorch is faster is a good idea.\n\npermalinkembedsaveparentgive award[\u2013]Reiinakano 6 points7 points8 points 6 months ago*\u00a0(9 children)Every time this question comes up, I've seen Pytorch completely win the usability argument.\nI really want to switch everything to Pytorch but I depend on a lot of Google research code written only in Tensorflow.\n\npermalinkembedsavegive award[\u2013][deleted] 6 months ago\u00a0(2 children)[deleted]\n\n[\u2013]SedditorX 6 points7 points8 points 6 months ago\u00a0(0 children)For all of tensorflow's flaws, this is something obvious that's always neglected in the debate. Pytorch users on this forum loudly crowd out these kinds of threads and sometimes downvote dissenting opinions.\nIMO the best way to make the ecosystem better for everyone is to be constructive with criticism. A rising tide raises all ships and all that.\n\npermalinkembedsavegive award[\u2013]NicolasGuacamole 1 point2 points3 points 6 months ago\u00a0(5 children)Port the models to pytorch. It\u2019s usually straightforward.\n\npermalinkembedsaveparentgive award[\u2013]Reiinakano 2 points3 points4 points 6 months ago\u00a0(1 child)Is it straightforward for something like https:\/\/github.com\/tensorflow\/lucid\/?\n\npermalinkembedsaveparentgive award[\u2013]NicolasGuacamole 0 points1 point2 points 6 months ago\u00a0(0 children)Probably straightforward but time consuming\n\npermalinkembedsaveparentgive award[\u2013]Ouitos 4 points5 points6 points 6 months ago\u00a0(2 children)It's clearly not. It can take some time to figure out the subtle differences between the different default parameters of your module and how you can make the algorithm behave exactly the same (and for some papers, it's critical to have the exact same algorithm or you might not converge at all).\nThis is not due to the fact that tensorflow and pytorch are too different, but rather than most research code is poorly documented (as is tradition) and theoretical knowledge of the algorithm is often not enough to port it.\nHowever, I do advise you to port to pytroch, as it can be a rewarding experience in terms of what you'll learn.\n\nIt takes a good understanding of the paper and some ML untold subtleties to make a port work with the exact same results as the paper reported ones\nit's useful for other researchers, and a github with many stars is always good for your CV.\nand finally you are never lost since you have a reference implementation that is supposed to work.\n\n\npermalinkembedsaveparentgive award[\u2013]NicolasGuacamole -5 points-4 points-3 points 6 months ago\u00a0(1 child)Thanks for the lecture I didn\u2019t ask for. Funnily enough I\u2019ve got lots of experience porting models and implementing from papers in the dark ages of Caffe (1) and piles of theano spaghetti. It was doable if tricky then and I\u2019ve every confidence it is now with these nicer modern frameworks.\n\npermalinkembedsaveparentgive award[\u2013]Ouitos 4 points5 points6 points 6 months ago\u00a0(0 children)I'm sorry you took my comment as condescending, the \"you\" was aimed toward general discussion than you specifically.\nThat being said, I invite you to try now too. My point is independant to ease of use, you will get a minimum theoretical clone easily but you won't get easily the exact same results: as long as some differences will lie between frameworks (they tend to disappear but they do exist, such as convolution padding and weight initialization functions to name a few), the port won't be straight forward since these subtle differences will be implicitly here.\n\npermalinkembedsaveparentgive award[\u2013]Overload175 1 point2 points3 points 6 months ago\u00a0(0 children)Still use TensorFlow, admittedly out of sheer force of habit though\n\npermalinkembedsavegive award[\u2013]MagicMurderBagYT 1 point2 points3 points 6 months ago\u00a0(0 children)Pytorch. It's just better for me than tensorflow.\n\npermalinkembedsavegive award[\u2013]trexdoor 4 points5 points6 points 6 months ago\u00a0(18 children)Neither, I have my own self-written ANN framework. It is not very advanced but I had used it in several projects successfully, of which the latest was license plate reading.\nIs there anyone else here who are using their self made libraries? Or am I the sole outlier?\n\npermalinkembedsavegive award[\u2013]Necryotiks 1 point2 points3 points 6 months ago\u00a0(1 child)Is it on github.\n\npermalinkembedsaveparentgive award[\u2013]trexdoor -1 points0 points1 point 6 months ago\u00a0(0 children)No.\n\npermalinkembedsaveparentgive award[\u2013]MachineIntelligence 1 point2 points3 points 6 months ago\u00a0(0 children)Funny enough what got me hooked on Machine Learning was continuing a project from my intro to AI course in college. After graduating I spent multiple months, without researching the topic any further, building out a ANN framework in Java with its own network configuration file.\nObject oriented neurons (ReLU,Sigmoid) , no matrix algebra, only stochastic gradient descent, no additional optimizers. Very naive but it works and I was super proud of it because I learned a lot from it! And I find the simplicity of it charming, despite it's inefficiencies.  https:\/\/github.com\/NicholasLePar\/Simple-Java-Neural-Network\nObviously after taking Deeplearning.ai and reading more content out there I realized how stubborn I was not to explore the space more and learn the proper way of building these frameworks. Leveraging vectorization, regularization, mini-batches, different optimizers. I am now building out another framework in Python because I love the idea of just building out these models in a simple way that is easily digestable for myself. I'll keep you posted when I push that one out on github.\n\npermalinkembedsaveparentgive award[\u2013]Mastiff37 1 point2 points3 points 6 months ago\u00a0(0 children)I have some capabilities written up in C++, like basic dense and convolutional networks, max pooling, a handful of activations, etc.  They worked, but I eventually caved because stuff is moving fast and every new feature is a fair bit of work to get working properly.  For mine I didn't do autodiff, so any new loss function needed the gradients to be worked out manually.  There's also the whole issue of GPU support if that matters for your application.\nI would expect many large corporations would have their own libraries going though, for deployment in embedded applications if nothing else.\n\npermalinkembedsaveparentgive award[\u2013]enjakuro 1 point2 points3 points 6 months ago\u00a0(4 children)Why would someone vote this down?\n\npermalinkembedsaveparentgive award[\u2013][deleted] 4 points5 points6 points 6 months ago\u00a0(2 children)I didn't downvote, but I will say this: unless OP is Joe Redmon wizard level, I don't think custom ML libs should be used for projects beyond coursework final projects or as learning exercises. \nCoding up autodiff, convnets, etc. from scratch can be invaluable experiences. You learn great many things, including how easy it is to mess things up by introducing silent failures.\nConsequently, using a custom library for research or production level deployment is a big no-no. Too risky for silent bugs, the code isn't easily understood by nor readily shareable with the community, etc. \nMaybe this is why people downvote. Maybe people view it as boasting. Or maybe they're jealous someone can code from scratch what they can only do from keras API. This is Reddit after all.\n\npermalinkembedsaveparent[\u2013]trexdoor 1 point2 points3 points 6 months ago\u00a0(1 child)I disagree on a few points but thank you for your input.\nI have to say, there are many companies that are using their own libraries. One of them where I worked started making their OCR engine about 20 years ago. There were no publicly available libraries then so they had to make everything from scratch - and they stuck to it because it worked well... And I had to say, in some ways their libraries were more advanced than what is used in academic research.\n\npermalinkembedsaveparentgive award[\u2013]sorrge 0 points1 point2 points 6 months ago\u00a0(0 children)Not Pytorch!\n\npermalinkembedsaveparentgive award[\u2013]enjakuro 0 points1 point2 points 6 months ago*\u00a0(8 children)Why would someone vote this down?\nEdit: thanks for your answers! I'm studying multilingual text analysis and just made 'first contact' with tensorflow xD I can see now why you should use common libraries\n\npermalinkembedsaveparentgive award[\u2013]farmingvillein 1 point2 points3 points 6 months ago\u00a0(7 children)Probably because it is unlikely that the user here is doing anything meaningful in either production or research environment.  This makes the user's response look a lot like noise.\nNo one doing SOTA research is using anything custom, unless they are very specifically trying to solve something exceedingly specific that the current frameworks don't support.  This clearly isn't the case here.\nNo one is doing production-level work by rolling their own framework, unless 1) they've been in production for many, many years and have legacy code or 2), again per research, they have exceedingly specific needs (maybe getting onto very specific hardware).  \"License plate reader\" not germane here.\nSince the user isn't doing anything serious, this is a little like taking a poll like \"What game development framework do you use?  Unity or XYZ?\", and someone responding that they built their own in Lisp.  \nTechnically responsive to the question, but really just indicative of highly idiosyncratic choices made for entirely idiosyncratic reasons; not helpful or representative.\n\npermalinkembedsaveparentgive award[\u2013]trexdoor 1 point2 points3 points 6 months ago\u00a0(6 children)You are making tons of false assumptions there.\nThanks for your response anyway. I suspect this is mostly representative of the way of thinking in this \"community\".\n\npermalinkembedsaveparentgive award[\u2013]farmingvillein 0 points1 point2 points 6 months ago*\u00a0(5 children)What false assumptions?\nYou're definitely not doing SOTA research.\nProduction--there's literally zero good engineering reason to build your own framework, unless #1 or #2 that I listed qualifies.  Which I highly doubt.  \nPut another way, what are you doing so special that it your use cases requires a different framework than Google, Facebook, Amazon, Salesforce, most people deploying to mobile, etc.?\nEducate us.  No one knows your use case but you.\n\npermalinkembedsaveparentgive award[\u2013]trexdoor 2 points3 points4 points 6 months ago\u00a0(4 children)First, what is this snobbish remark regarding me not doing SOTA research? Even if it is true, why do you even bring it up? This is not a subreddit strictly for academic researchers and people playing with the latest SOTA techniques, is it? Seriously, are you gate keeping or what?\nI am doing machine learning at my job, if I count well for more than 15 years now. I think I have the same entitlement and right to participate in \/r\/MachineLearning as the young guns who who are in majority here. I felt that OP's question was addressed to me just as to any other member. I gave my humble answer, so what?\nSecond, to give you an idea of what I had been doing recently, a licence plate reader engine. I used ANN's to find lines of text, to read the text, to check for additional logos on the plates. That's a whole bunch of machine learning, isn't it... And not because I want to brag but I have to add, yes, all written by me in C++.\nYou should know that these LPR engines cannot be deployed in the cloud at some cases for security reasons, they are usually running on the customer's closed server park, or even better, on the camera itself. Now these cameras have very limited HW capabilities, only an Atom or an ARM processor without any special HW acceleration that could be used for ANN calculations. That's the reason for the custom library. Very limited HW resources, and the task demands a very fast engine that can detect plates as small as 20 pixels in height on a 2 megapixel image at min 10 fps. You have no chance if you want to do this with the big frameworks mentioned here by others.\n\npermalinkembedsaveparentgive award[\u2013]farmingvillein 0 points1 point2 points 6 months ago\u00a0(3 children)\nYou have no chance if you want to do this with the big frameworks mentioned here by others.\n\nYou can almost certainly do this on Tensorflow with Google's tooling.  The footprint can get exceedingly small and tight.\nThis sounds like you aren't actually familiar with the current frameworks.\nUnless you're dealing with truly ancient technology, in which case see my original disclaimer in both my notes re:hardware requirements.\n\npermalinkembedsaveparentgive award[\u2013]trexdoor 2 points3 points4 points 6 months ago\u00a0(2 children)Lol, at this point you are just throwing shit at me.\nOur library is the product of many years of hard work by me and my teammates. It has several features that is not or not easily available in the mainstream libraries. If we need something new then we can add it to our framework, you know, we are skilled programmers.\nYou seem to know nothing about the challenges of writing fast algorithms on embedded systems, and you surely do not know the capabilities of our framework, yet you are readily suggesting that it is \"ancient technology\". Such a nice guy you are.\n\npermalinkembedsaveparentgive award[\u2013]farmingvillein 1 point2 points3 points 6 months ago*\u00a0(1 child)Again, as I wrote originally:\n\nNo one is doing production-level work by rolling their own framework, unless 1) they've been in production for many, many years and have legacy code or 2), again per research, they have exceedingly specific needs (maybe getting onto very specific hardware).\n\nYou are telling me you have 1) legacy code and 2) specific hardware needs.  You choose to get and responded in an offended manner, when both of these qualifiers apply to you.  And then you dribble out the fact that they apply to you on a post-by-post basis, getting progressively more offended.\nFurther, this reinforces my original point, which was that someone asking \"what frameworks do you use for ML?\" and then stating that you use a custom platform...which was apparently built up over years...is relevant to basically no one looking to understand framework trade-offs because 1) you have legacy concerns and 2) you have apparently deep, specific hardware concerns which neither bothered to qualify up front, or to articulate in a way that advances the discussion, i.e., highlights what specific hardware limitations require something so custom.\nYes, we're all aware that there is actually a lot of COBOL still sitting on IBM mainframes, but this is not how anyone would chose to cold-start solving a problem today.  \nI'm sure I'm not unique in this thread--I know plenty of people who do and have worked on embedded systems, including higher-end requirements than \"2 megapixel image at min 10 fps\" for a license plate reader.  In the vast majority of cases, eg TF is and will be more than sufficient, and there is a large array of support that will push that further.  If you are actually trying to contribute to the discussion, then explain where current solutions are deficient.   \n\"[O]nly an Atom or an ARM processor without any special HW acceleration that could be used for ANN calculations\" is not a sufficient reason, in that TF can support many of those use cases.\n\"We started getting going a while back when TF support for the edge was worse and built up a library\" is totally a valid engineering reason--but that goes back to my aforementioned legacy code qualifier, and is largely uninteresting to anyone trying to understand current framework tradeoffs.\nLastly, I was originally responding a poster asking why this post was being voted down.  I am not a solo agent \"taking down\" your post--while I cannot speak for everyone's reasons as to why your post was voted down, I can provide context on why I think the collectivity of the subreddit is not finding your post additive to the discussion.  Try to take my commentary in the context of this broader feedback, rather than any particular point you want to disagree with me on.  I am apparently not alone here.\n\npermalinkembedsaveparentgive award[\u2013]TheFlyingDrildo 0 points1 point2 points 6 months ago\u00a0(0 children)pytorch.  so easy and painless to just set up some custom model and start training.\nthinking of switching to flux tho based on how much i love julia\n\npermalinkembedsavegive award[\u2013]vajra_ 0 points1 point2 points 2 months ago\u00a0(0 children)Tensorflow is shite - kept alive by money pumping from Google - and trying to copy Pytorch concepts. Its a freaking mess. The only reason I have to use TF is because of weirdos who started DL with TF and can't move on.\n\npermalinkembedsavegive award[+]CyberDainz comment score below threshold-9 points-8 points-7 points 6 months ago*\u00a0(5 children)Google is much bigger corp than facebook, so it is future-proof, and I bet on tf.keras\n\npermalinkembedsavegive award[\u2013]vegetableagony 4 points5 points6 points 6 months ago\u00a0(2 children)Based on market cap it looks like Google is only about 50% larger than Facebook. Both are extremely large advertising driven US-based tech firms.\n\npermalinkembedsaveparentgive award[\u2013]CyberDainz -3 points-2 points-1 points 6 months ago\u00a0(1 child)market cap is nothing. Google is giga corp, that provides a lot of free services to users, and develops large amount of software. Facebook is just a social network.\nSorry but no, pytorch has no future.\nGood luck stay on the dying nn framework.\n\npermalinkembedsaveparentgive award[\u2013]GradMiku 0 points1 point2 points 6 months ago\u00a0(0 children)The quality of tour projects depends of your abilities not your framework \"\"fanbase\"\".\nThe number developers of those frameworks are very similar, so PyTorch is not \"\"dying\"\"\nare you chosen your frameworks only because popularity? and i recently test PyTorch and is much faster that Tensorflow at training time\n\npermalinkembedsaveparentgive awardaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 23522 on  r2-app-030c3614bd34d7a45  at 2019-11-20 21:41:49.223814+00:00 running a5676e6 country code: US."
  },
  "24":{
    "title":"[D] TensorFlow is dead, long live TensorFlow! : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-gaming-pics-worldnews-funny-todayilearned-tifu-aww-movies-videos-Jokes-gifs-science-mildlyinteresting-Showerthoughts-nottheonion-television-UpliftingNews-OldSchoolCool-dataisbeautiful-sports-personalfinance-explainlikeimfive-GetMotivated-TwoXChromosomes-askscience-nosleep-IAmA-space-LifeProTips-Futurology-gadgets-books-food-Art-Music-WritingPrompts-photoshopbattles-EarthPorn-DIY-Documentaries-history-creepy-listentothis-philosophy-announcements-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  29 Mar 2019369 points (92% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave820,752 readers2,364 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X186  \u00b7 38 comments How to detect AI Snake oil177  \u00b7 41 comments [D] Early coauthorship with top scientists predicts success in academic careers5  \u00b7 2 comments [Discussion] Advice needed: Feeling trapped by lack of management\/strategy, no implemented models.20  \u00b7 7 comments [D] Regarding the ability of neural networks to learn \"simple\" examples first3  \u00b7 1 comment [P] Machine Learning Flight Rules7  \u00b7 1 comment [Research] Announcing Kaolin - PyTorch Library for Accelerating 3D Deep Learning Research221  \u00b7 13 comments [P] How to apply machine learning and deep learning methods to audio analysis3  \u00b7 1 comment [D] Is it ill-advised to perform transfer learning with generalized linear models?21  \u00b7 15 comments [P] askgpt.com I built a simple ui to converse with gpt-2219  \u00b7 15 comments [R] How Machine Learning Can Help Unlock the World of Ancient Japan (by Alex Lamb)Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7368369370Discussion[D] TensorFlow is dead, long live TensorFlow! (self.MachineLearning)submitted 7 months ago by milaworldArticle about the TensorFlow's decision to drop legacy functionally to embrace Keras full-on.\nIn a nutshell: TensorFlow has just gone full Keras. Those of you who know those words just fell out of your chairs. Boom!\nWhy must we choose between Keras\u2019s cuddliness and traditional TensorFlow\u2019s mighty performance? What don\u2019t we have both?\n\u201cWe don\u2019t think you should have to choose between a simple API and scalable API. We want a higher level API that takes you all the way from MNIST to planet scale.\u201d\u200a\u2014\u200aKarmel Allison, TF Engineering Leader at Google\nhttps:\/\/hackernoon.com\/tensorflow-is-dead-long-live-tensorflow-49d3e975cf04?sk=37e6842c552284444f12c71b871d3640\n\n165 commentssharesavehidereportall 165 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]tidier 114 points115 points116 points 7 months ago\u00a0(8 children)My experience with PyTorch and TF so far is: PyTorch is designed as a Python module, first and foremost. TF always felt like a (very powerful) external library with a Python API. With PyTorch, I can reason through most of it from a Python perspective, from architecting code to debugging errors.\nI'm tired of seeing \"look at this 5-liner to train MNIST\/ImageNet\" examples. That tells me nothing about how it would be like actually working with the framework.\nI want to see examples that go \"Here's some code with an error. It's actually because of this subtle mistake. This is how you would actually find out and fix it.\"\nOr \"We had this crazy idea to do X. No one would think of doing X, and you wouldn't actually think it's possible but actually you can with our framework and here's how you would do it.\"\nA code excerpt that looks like\nfrom superbestlibrary import models, datasets\n\nmodel = models.ResNet151\ndata = datasets.ImageNet\nmodel.train(data.train)\n\nprint(model.eval(data.val).accuracy())\n\ntells me absolutely nothing.\n\npermalinkembedsavegive award[\u2013]RoboticElfJedi 32 points33 points34 points 7 months ago\u00a0(5 children)This. I\u2019m pretty done with MNIST at this point. Now take your model and show me how to freeze one layer and retrain, look at the activations of a particular neuron, create a layer of a new kind. \n\npermalinkembedsaveparentgive award[+][deleted] 7 months ago\u00a0(4 children)[removed]\n\n[\u2013]RoboticElfJedi 13 points14 points15 points 7 months ago\u00a0(2 children)Jesus reddit. \nThe point isn\u2019t that things shouldn\u2019t be good for beginners, they should.  I also want to see the internals and the ability to do more advanced stuff. \n\npermalinkembedsavegive award[\u2013]JonnyK74 7 points8 points9 points 7 months ago*\u00a0(1 child)Yeah, and it's even more than that. I'm a beginner at TF but a very experienced programmer, and \"beginner\" cookie cutter examples make it very difficult to actually move on from being a beginner. Showing real-world examples of solving moderately difficult problems is much more useful to beginners.\n\npermalinkembedsaveparentgive award[\u2013][deleted] 3 points4 points5 points 7 months ago\u00a0(0 children)Exactly this. Treating an already obscure topic as a black box where even the things you know and can reason about are part of it,  renders the topic impossible to understand and internalize. \nI find PyTorch to be great on alleviating the whole even the code is a black box. There are plenty of models online that show what\u2019s happening and allow me to search and learn on my own without having a mental pagefault every time I branch to read about something.\n\npermalinkembedsaveparent[\u2013]AyEhEigh 5 points6 points7 points 7 months ago\u00a0(0 children)I mean, you can always have beginner examples and advanced examples.  They aren't exclusive of each other.\n\npermalinkembedsavegive award[\u2013]GoofAckYoorsElf 8 points9 points10 points 7 months ago\u00a0(0 children)This needs to be a sticky in every fucking programming forum!\n\npermalinkembedsaveparentgive award[\u2013]mmirman 7 points8 points9 points 7 months ago\u00a0(0 children)I started out working with TF.  I would have never had the idea to differentiate over raytracing or abstract interpretation had I continued.\n\npermalinkembedsaveparentgive award[\u2013]perceptron01 129 points130 points131 points 7 months ago\u00a0(14 children)Jesus Christ what is this post? It has some random funny meme image after each paragraph\n\npermalinkembedsavegive award[\u2013]wiltors42 60 points61 points62 points 7 months ago\u00a0(0 children)welcome to the world of medium ML articles\n\npermalinkembedsaveparentgive award[\u2013]MorrisMustang 48 points49 points50 points 7 months ago\u00a0(2 children)EU proofing the article. no biggie.\n\npermalinkembedsaveparentgive award[\u2013]whatdidusaybro 1 point2 points3 points 7 months ago\u00a0(1 child)what are you talking about, that will all get taken down after the shiznitz by EU gets in effect\nit's counter proofing to be exact\nor is this the joke? \/swoosh?\n\npermalinkembedsaveparentgive award[\u2013]MorrisMustang 3 points4 points5 points 7 months ago\u00a0(0 children)Like child proofing...\n\npermalinkembedsaveparentgive award[\u2013]DeepBlender 21 points22 points23 points 7 months ago\u00a0(0 children)It is a touch over the top for my taste too. However, it closely resembles my experience with TensorFlow 2.0. It is such a huge improvement and I really enjoy working with it!\n\npermalinkembedsaveparentgive award[\u2013]osipov 14 points15 points16 points 7 months ago\u00a0(2 children)It's a weird Googler fetish for meme images. Source: former Googler.\n\npermalinkembedsaveparentgive award[\u2013]gokstudio 1 point2 points3 points 7 months ago\u00a0(0 children)Blame \/ Thank MemeGen\n\npermalinkembedsaveparentgive award[\u2013]GoofAckYoorsElf 1 point2 points3 points 7 months ago\u00a0(0 children)Go away, Axel Voss!\n\npermalinkembedsaveparentgive award[\u2013]d8sconz 2 points3 points4 points 7 months ago\u00a0(0 children)Like that damn plinky plink music they add to every. single. video. tutorial now.\n\npermalinkembedsaveparentgive award[\u2013]killingisbad 2 points3 points4 points 7 months ago\u00a0(0 children)Really makes concentrating hard\n\npermalinkembedsaveparentgive award[\u2013]dt_bui 1 point2 points3 points 7 months ago\u00a0(0 children)Google is a meme loving company\n\npermalinkembedsaveparentgive award[\u2013]Vikram8 0 points1 point2 points 7 months ago\u00a0(0 children)Just like Siraj's videos\ud83d\ude02\n\npermalinkembedsaveparentgive award[\u2013]siblbombs 133 points134 points135 points 7 months ago\u00a0(23 children)If I survived switching from Theano to Tensorflow, I'll survive switching to TF2\n\npermalinkembedsavegive award[\u2013]cucuska2 175 points176 points177 points 7 months ago\u00a0(14 children)I never really got over the fact that hats were introduced into TF2.\n\npermalinkembedsaveparentgive award[\u2013]lstama 61 points62 points63 points 7 months ago\u00a0(10 children)TensorFlow 2, Team Fortress 2, Titanfall 2.\n\npermalinkembedsaveparentgive award[\u2013]cucuska2 52 points53 points54 points 7 months ago\u00a0(7 children)Tensor Fortress 2, Team Fall 2, TitanFlow 2?\n\npermalinkembedsaveparentgive award[\u2013]oblivioncntrlsu 56 points57 points58 points 7 months ago\u00a0(5 children)Team Tensor Titan 2: Fortress Flow \nComing This Fall.\n\npermalinkembedsaveparentgive award[\u2013]Cypher1235 15 points16 points17 points 7 months ago\u00a0(3 children)2 Tensor 2 Flow\n\npermalinkembedsaveparentgive award[\u2013]UnhappySquirrel 20 points21 points22 points 7 months ago\u00a0(1 child)2 Tensors 1 Flow\n\u200b\nI immediately regret typing that.\n\npermalinkembedsaveparentgive award[\u2013]badpotato 2 points3 points4 points 7 months ago\u00a0(0 children)Look like the project finally reached some sort of maturity. \n\npermalinkembedsaveparentgive award[\u2013]2Punx2Furious 0 points1 point2 points 7 months ago\u00a0(0 children)\n\npermalinkembedsaveparentgive award[\u2013]cucuska2 8 points9 points10 points 7 months ago\u00a0(0 children)You are a next-level madlad.\n\npermalinkembedsaveparentgive award[\u2013]sk_2013 5 points6 points7 points 7 months ago\u00a0(0 children)Tensor Fall 2 was a weak followup, I felt like.\n\npermalinkembedsaveparentgive award[\u2013]GoofAckYoorsElf 0 points1 point2 points 7 months ago\u00a0(0 children)TF2 (ROS transform framework)\n\npermalinkembedsaveparentgive award[\u2013]emilazeri92 -1 points0 points1 point 7 months ago\u00a0(0 children)\/r\/titanfall2\n\npermalinkembedsaveparentgive award[\u2013]automated_reckoning 10 points11 points12 points 7 months ago\u00a0(0 children)... I'd buy a TF2 hat. \n\npermalinkembedsaveparentgive award[\u2013]stilloriginal 3 points4 points5 points 7 months ago\u00a0(0 children)That was so much later it really should have been called tf3\n\npermalinkembedsaveparentgive award[\u2013]siblbombs 1 point2 points3 points 7 months ago\u00a0(0 children)At least its free2play.\n\npermalinkembedsaveparentgive award[\u2013]p-morais 26 points27 points28 points 7 months ago\u00a0(4 children)\nIf I survived switching from Theano to Tensorflow, I'll survive switching to Pytorch\n\nFTFY\n\npermalinkembedsaveparentgive award[\u2013]maokei 2 points3 points4 points 7 months ago\u00a0(2 children)DL4J anyone?\n\npermalinkembedsaveparentgive award[\u2013][deleted] 7 months ago\u00a0(1 child)[deleted]\n\n[\u2013]gokstudio 1 point2 points3 points 7 months ago\u00a0(0 children)Most real-world companies\n\npermalinkembedsavegive award[\u2013]siblbombs 3 points4 points5 points 7 months ago\u00a0(0 children)No thanks, I'm not sold on eager (I don't do that much research).\n\npermalinkembedsaveparentgive award[\u2013][deleted] 7 months ago\u00a0(1 child)[deleted]\n\n[\u2013]siblbombs 6 points7 points8 points 7 months ago\u00a0(0 children)I actually am a big fan of graph-based instead of eager, also I use tensorflow serving pretty aggressively, so pytorch doesn't really capture my interest.\n\npermalinkembedsavegive award[\u2013]st8ic 58 points59 points60 points 7 months ago\u00a0(16 children)This honestly looks a lot like an April fool's post. Judging by all the \"aNyOnE cAn Do aI nOw\" platitudes in this article, it looks like this is Tensorflow's attempt to compete for users in the ML hype war.  \nAs a long-time Tensorflow user, I don't really give a shit about Keras but as long as they still have all the same functionality available without using their canned keras layers, I'm okay with learning the new API.\n\npermalinkembedsavegive award[\u2013]TheOneRavenous 25 points26 points27 points 7 months ago\u00a0(8 children)Writer works at Google...\n\npermalinkembedsaveparentgive award[\u2013]epicwisdom 1 point2 points3 points 7 months ago\u00a0(7 children)And an executive, apparently - which is noteworthy since last I checked Googlers number in the tens of thousands, so \"works at Google\" may not mean much when it comes to making strong claims about the direction of one of their biggest open source libraries.\n\npermalinkembedsaveparentgive award[\u2013]osipov -1 points0 points1 point 7 months ago\u00a0(6 children)@quaesita is not an executive. Just gave herself a self-inflated title.\n\npermalinkembedsaveparentgive award[\u2013]epicwisdom 0 points1 point2 points 7 months ago\u00a0(5 children)https:\/\/www.gcppodcast.com\/post\/episode-128-decision-intelligence-with-cassie-kozyrkov\/ appears to be an official source which corroborates her job title \/ experience, though of course \"executive\" is not a real title. Seems significantly higher up the chain than most SWEs.\n\npermalinkembedsaveparentgive award[\u2013]osipov -2 points-1 points0 points 7 months ago\u00a0(4 children)\n\"corroborates\"\n\non the podcast they just cite whatever she put as her job title in Teams, google's internal directory. she is an L7 at google with a lot of diversity headwind. \n\npermalinkembedsaveparentgive award[\u2013]epicwisdom 0 points1 point2 points 7 months ago\u00a0(3 children)\"Diversity headwind\" is your subjective political bias, completely irrelevant. Most SWEs peak at L5 at Google; I never checked the exact distribution, but roughly speaking L7 ought to be the top 2-5%. It's about as high as you can get before VP\/SVP, unless you're Jeff Dean, so I'm inclined to listen to them about products they would reasonably have some insight on.\n\npermalinkembedsaveparentgive award[\u2013]osipov -2 points-1 points0 points 7 months ago\u00a0(2 children)\n\"Diversity headwind\" is your subjective political bias\n\nhere's another biased statement for you. look up the dictionary under IYI. your picture is there.\n\npermalinkembedsaveparentgive award[\u2013]epicwisdom 0 points1 point2 points 7 months ago\u00a0(1 child)Lol. First, make a claim without evidence, that practically can't be verified, then resort to childish insults. I guess that's all you have to say on the matter.\n\npermalinkembedsaveparentgive award[\u2013]osipov -1 points0 points1 point 7 months ago\u00a0(0 children)If you can't stand insults or need evidence to convince you that water is wet then get off the internet. Go back to your Pleasure Island of a safe space and don't forget to graze at your local MK.\n\npermalinkembedsaveparentgive award[\u2013]blitzzerg 11 points12 points13 points 7 months ago\u00a0(4 children)To me it's just so stupidly dumb to label everything now as \"keras\". I have never used tensorflow for doing neural nets\n\npermalinkembedsaveparentgive award[\u2013]st8ic 18 points19 points20 points 7 months ago\u00a0(2 children)yeah they're definitely after the \"I want to learn how to write a MNIST classifier in a 10 minute tutorial\" market. I just hope that it's not more difficult for us who just need auto-differentiation in python.\n\npermalinkembedsaveparentgive award[\u2013]akshayka 4 points5 points6 points 7 months ago\u00a0(0 children)You don't have to use Keras if you don't want to. There's nothing stopping you from using TF 2.0 as a library for numerical computation and automatic differentiation; in fact, 2.0 encourages this kind of \"differentiable programming,\" at least for \"advanced\" users.\nhttps:\/\/www.tensorflow.org\/alpha\/tutorials\/eager\n\npermalinkembedsaveparentgive award[\u2013]bones_and_love 3 points4 points5 points 7 months ago\u00a0(1 child)Is there an official announcement from Google you can find?\n\npermalinkembedsaveparentgive award[\u2013]akshayka 2 points3 points4 points 7 months ago\u00a0(0 children)https:\/\/www.tensorflow.org\/alpha\nhttps:\/\/medium.com\/tensorflow\/whats-coming-in-tensorflow-2-0-d3663832e9b8\n\npermalinkembedsaveparentgive award[\u2013]dfarber 21 points22 points23 points 7 months ago\u00a0(1 child)is it 4\/1 already?\n\npermalinkembedsavegive award[\u2013][deleted] 11 points12 points13 points 7 months ago\u00a0(0 children)I got a good laugh from their memetic doge definition of Tensor.\nThe entire piece is a joke, and obviously so assuming you have any experience in optimizing graphs of tensors and submitting them to tensorflow and using the keras library.  \nThere's a lot of misinformation in the community, and this is a beautiful addition to that polluting disinformation.\n\npermalinkembedsaveparent[\u2013]blitzzerg 27 points28 points29 points 7 months ago*\u00a0(5 children)Well at least now I'm motivated enough to leave tensorflow and switch to pytorch\n\npermalinkembedsavegive award[\u2013]youbehasbeen 5 points6 points7 points 7 months ago\u00a0(3 children)Granted there's still a lot I don't know, but I don't understand how this would make you want to switch to pytorch? Is it just a matter of \"now I have to learn something new, may as well it be pytorch\" ?\n\npermalinkembedsaveparentgive award[\u2013]blitzzerg 7 points8 points9 points 7 months ago\u00a0(2 children)to me this is the problem:\nTensorflow was originally created as an \"automatic differentiation\" library, which is useful for a lot of things, one of them is doing neural networks at \"low level\" (on the contrary Keras is making them at high level). With this update they seem to have made a huge shift (at least that's what I think) to integrate everything into Keras, even if it's just at a naming level, forgetting about other users like me that do not use Tensorflow to code neural nets.\n\npermalinkembedsaveparentgive award[\u2013]epicwisdom 6 points7 points8 points 7 months ago\u00a0(0 children)I don't see why you think they're getting rid of that. There are obviously plenty of researchers at Google who use more features in TF than just Keras, so even from a purely self-serving point of view, there's no advantage in narrowing TF's applications.\n\npermalinkembedsaveparentgive award[\u2013][deleted] 5 points6 points7 points 7 months ago\u00a0(0 children)Yeah, I thought TensorFlow was great because it's a linear algebra library with auto-diff, pretty much. Keras already served the purpose it was needed for. I'm not sure why they need to integrate.\nHopefully they keep some of the low-level API. I haven't read the article yet.\n\npermalinkembedsaveparent[\u2013]BastiatF 0 points1 point2 points 7 months ago\u00a0(0 children)Do it! Your future self will thank you.\n\npermalinkembedsaveparentgive award[\u2013][deleted] 7 months ago\u00a0(1 child)[removed]\n\n[\u2013]Overload175 1 point2 points3 points 7 months ago\u00a0(0 children)Can you give an example?\n\npermalinkembedsaveparentgive award[\u2013]ThisIsMyStonerAcount 70 points71 points72 points 7 months ago\u00a0(53 children)Who cares about TF as long as we have Pytorch. \n\npermalinkembedsavegive award[\u2013]zzzthelastuser 26 points27 points28 points 7 months ago\u00a0(1 child)nothing wrong with some healthy competition\n\npermalinkembedsaveparentgive award[\u2013]khanstein 7 points8 points9 points 7 months ago\u00a0(0 children)And that is most probably why we had eager execution and now this transition maybe faster than it would take otherwise. \n\npermalinkembedsaveparentgive award[\u2013]bencbartlett 8 points9 points10 points 7 months ago\u00a0(1 child)\nWho cares about TF as long as we have Pytorch.\n\nC O M P L E X   T E N S O R S\n\u200b\n\npermalinkembedsaveparentgive award[\u2013]koolaidman123 28 points29 points30 points 7 months ago\u00a0(9 children)i love pytorch for its ease of use, but currently almost all the rl work is done in tensorflow, so a lot of the resources aren't available to pytorch users. i've had to start learning tf to run some rl experiments\n\npermalinkembedsaveparentgive award[\u2013]rantana 18 points19 points20 points 7 months ago\u00a0(0 children)It seems odd to use an end to end framework for one of the fields with the least end to end solutions (non-differentiable environment, reward, actions, etc). \n\npermalinkembedsaveparentgive award[\u2013]cwaki7 10 points11 points12 points 7 months ago\u00a0(1 child)Really? It seems to be that pytorch is especially better in RL because of the way the graph computations are done and how easy it is to do some logic on the cpu then seamlessly go back to computing on the gpu. I learned tensorflow a long time ago and had little knowledge at the time so perhaps I missed the benefit tf has to offer in RL? \n\npermalinkembedsaveparentgive award[\u2013]koolaidman123 0 points1 point2 points 7 months ago\u00a0(0 children)i mean that there's comparatively few resources for rl using pytorch. most tutorials\/classes all seem to use tf so it was hard for me to find nice implementation of algorithms done in pytorch\n\npermalinkembedsaveparentgive award[\u2013]p-morais 8 points9 points10 points 7 months ago\u00a0(4 children)I don\u2019t know. Using static graphs in RL feels clumsy and weird, like you\u2019re mixing two totally different languages\/styles of programming. I know some big groups use TF (namely Berkeley\/OpenAI and Google) but I think there\u2019s enough resources on GitHub that switching to Pytorch should be painless.\n\npermalinkembedsaveparentgive award[\u2013]koolaidman123 2 points3 points4 points 7 months ago\u00a0(3 children)i'd love it if you can point out some pytorch resources for learning RL! the only one i've found to be fairly popular is this one https:\/\/github.com\/qfettes\/DeepRL-Tutorials, but i'm not sure if there are other\/better resources for code implementation\n\npermalinkembedsaveparentgive award[\u2013]p-morais 9 points10 points11 points 7 months ago\u00a0(1 child)https:\/\/github.com\/ikostrikov is great \nhttps:\/\/github.com\/vitchyr\/rlkit is also good\nI think those two cover most mainstream algorithms, and are what I usually look at for reference.\n\npermalinkembedsaveparentgive award[\u2013]koolaidman123 0 points1 point2 points 7 months ago\u00a0(0 children)that's fantastic, thanks! pytorch is infinitely easier to read than legacy tf code \n\npermalinkembedsaveparentgive award[\u2013]Nikhil_Iyer6 0 points1 point2 points 7 months ago\u00a0(0 children)https:\/\/github.com\/navneet-nmk\/pytorch-rl\n\npermalinkembedsaveparentgive award[\u2013]MoreDonuts 10 points11 points12 points 7 months ago*\u00a0(13 children)Pytorch pros and cons:\nPros:\nBetter syntax, ease of use, flexibility\nCons:\nNo Flatten layer included, because the devs really hate Sequential\nEdit:\nDisgusting cancer according to Pytorch devs:\ndqn_model = nn.Sequential(\n    nn.Conv2d(4, 32, 8, stride=4),\n    nn.ReLU(),\n    nn.Conv2d(32, 64, 4, stride=2),\n    nn.ReLU(),\n    nn.Conv2d(64, 64, 3, stride=1),\n    nn.ReLU(),\n    nn.Flatten(),\n    nn.Linear(3456, 512),\n    nn.ReLU(),\n    nn.Linear(512, env.action_space.n)\n)\n\nInstead, feast your eyes on the best practices:\nclass DQN(nn.Module):\ndef __init__(self, h, w, outputs):\n    super(DQN, self).__init__()\n    self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n    self.bn1 = nn.BatchNorm2d(16)\n    self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n    self.bn2 = nn.BatchNorm2d(32)\n    self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n    self.bn3 = nn.BatchNorm2d(32)\n\n    def conv2d_size_out(size, kernel_size = 5, stride = 2):\n        return (size - (kernel_size - 1) - 1) \/\/ stride  + 1\n    convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n    convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n    linear_input_size = convw * convh * 32\n    self.head = nn.Linear(linear_input_size, outputs)\n\ndef forward(self, x):\n    x = F.relu(self.bn1(self.conv1(x)))\n    x = F.relu(self.bn2(self.conv2(x)))\n    x = F.relu(self.bn3(self.conv3(x)))\n    return self.head(x.view(x.size(0), -1))\n\n\npermalinkembedsaveparentgive award[\u2013]jcjohnss 6 points7 points8 points 7 months ago\u00a0(9 children)One of the first things I do in a new PyTorch project is usually implement Flatten and GlobalAvgPool layers so I can write the former:\nhttps:\/\/github.com\/facebookresearch\/clevr-iep\/blob\/master\/iep\/models\/layers.py#L51\nhttps:\/\/github.com\/google\/sg2im\/blob\/master\/sg2im\/layers.py#L62\n\npermalinkembedsaveparentgive award[\u2013]MoreDonuts 1 point2 points3 points 7 months ago\u00a0(8 children)Yeah, same. I\u2019m sure we\u2019re not alone! The devs don\u2019t want to implement it because of some bizarre application of the slippery slope fallacy. \n\npermalinkembedsaveparentgive award[\u2013][deleted] 7 months ago*\u00a0(7 children)[deleted]\n\n[\u2013]MoreDonuts 0 points1 point2 points 7 months ago\u00a0(6 children)You can\u2019t use it with Sequential, so you either have to write your own Flatten every time, or not use Sequential. The point is that the devs really hate Sequential, even though its declarative style is ideal for many use cases. \n\npermalinkembedsavegive award[\u2013][deleted] 7 months ago*\u00a0(5 children)[deleted]\n\n[\u2013]MoreDonuts 1 point2 points3 points 7 months ago\u00a0(4 children)I just find things written with Sequential to be much more readable and easy to work with. It reminds me of my previous time in fields that actually cared about software engineering, lol \n\npermalinkembedsavegive award[\u2013]dpineo -1 points0 points1 point 7 months ago\u00a0(2 children)I suppose Sequential is like ML's version of the goto statement.  It's a perfectly good programming structure that is sometimes the ideal tool to concisely deal with the job at hand, but there's people that for some reason would rather twist and torture their code in an effort to avoid it.\n\npermalinkembedsaveparentgive award[\u2013]epicwisdom 2 points3 points4 points 7 months ago\u00a0(0 children)Sequential makes the easy thing easy. There are no added complications; it only limits what you can do without making larger changes, if in the future Sequential isn't a good fit.\ngoto might make some things deceptively easy, but it also adds significant complications. I've never thought to myself, \"Wow, a goto here would make life so much easier.\" (Obviously this doesn't hold if you deal with very low-level programming, but I doubt that includes much of the \/r\/machinelearning audience.)\n\npermalinkembedsaveparentgive award[\u2013]RUSoTediousYet 0 points1 point2 points 7 months ago\u00a0(0 children)It's not that hard to make a Flatten (or in general, a Reshape Layer) though :>. \n\npermalinkembedsaveparentgive award[\u2013]Billy737MAX 0 points1 point2 points 7 months ago\u00a0(1 child)How nice and pretty the code looks doesn't matter, the quality of the API is what matters, and that above example seems very limited\/unextendable\n\npermalinkembedsaveparentgive award[\u2013]MoreDonuts 0 points1 point2 points 7 months ago\u00a0(0 children)You\u2019re probably not thinking about it the right way. It requires declarative patterns rather than imperative ones. It kind of reminds me of React js, for instance. I might do a blog post at some point. \n\npermalinkembedsaveparentgive award[\u2013]bartturner 9 points10 points11 points 7 months ago\u00a0(21 children)TF is more popular but this move helps with the biggest weakness with TF.\nIt is a lot harder to find things that use PyTorch.  Most use TF.\n\npermalinkembedsaveparentgive award[\u2013]BeatLeJuce 18 points19 points20 points 7 months ago\u00a0(20 children)I guess this strongly depends. I personally feel like almost no-one uses TF anymore. Everyone I know and every research paper I read in the last year or two (that isn't from Google) uses PyTorch.\n\npermalinkembedsaveparentgive award[\u2013]soraki_soladead 13 points14 points15 points 7 months ago\u00a0(3 children)This is probably strongly based on field. I almost exclusively see TF papers but if you're in NLP I could see Pytorch appearing more popular there since RNNs in TF were terrible for a long time.\n\npermalinkembedsaveparentgive award[\u2013]mmirman 1 point2 points3 points 7 months ago\u00a0(2 children)I'm working in adversarial (as in security) ML, and RL.  The vast majority of the new non-google\/deepmind papers that I've seen have been for PyTorch.\n\npermalinkembedsaveparentgive award[\u2013]soraki_soladead 0 points1 point2 points 7 months ago\u00a0(1 child)Out of curiosity, excluding Google\/DeepMind and OpenAI, which RL labs use PyTorch?\n\npermalinkembedsaveparentgive award[\u2013]mmirman 0 points1 point2 points 7 months ago\u00a0(0 children)Most of the interesting RL papers I\u2019m concerned with haven\u2019t been coming out of \u201cRL Labs\u201d as much as a wide variety of individual research groups studying adversarial ml at universities.  its true though that google\/deepmind\/openai do have an outsized impact with the small percentage of the papers they do contribute though.  \n\npermalinkembedsaveparentgive award[\u2013]techlos 8 points9 points10 points 7 months ago\u00a0(12 children)from my own experience - people who mostly work in development and deployment tend to use tensorflow, whereas the research crowd has always been about torch\/pytorch. TF seems great if you're running a model across dozens of TPUs and write code focused on scalability... but at least for me, it's absolutely terrible for rapid prototyping of ideas. Try implementing the backpropamine paper in old TF, it's a nightmare to get it working properly\n\npermalinkembedsaveparentgive award[\u2013]UncleOxidant 5 points6 points7 points 7 months ago\u00a0(8 children)Trying to read old TF code is a nightmare as well.\n\npermalinkembedsaveparentgive award[\u2013]chocoladisco 11 points12 points13 points 7 months ago\u00a0(7 children)Trying to read research code is a nightmare in general.\n\npermalinkembedsaveparentgive award[\u2013]UncleOxidant 2 points3 points4 points 7 months ago\u00a0(6 children)Indeed. Why is coding such a neglected skill among academics?\n\npermalinkembedsaveparentgive award[\u2013]samsungofme 9 points10 points11 points 7 months ago\u00a0(5 children)for most academics in ML\/AI, code is secondary, and more of a proof of concept and a necessity for running experiments. that code is abandoned as soon as your paper's published, the project funding it drops, the graduate student who wrote it leaves your group or loses interest in supporting it, etc. The story changes if you are a systems researcher, or being funded by an agency like DARPA that really wants code (only somewhat, though). At the end of the day, we're academics, not coders; we get paid for developing new ideas, not writing great code. \n\npermalinkembedsaveparentgive award[\u2013]UncleOxidant 7 points8 points9 points 7 months ago\u00a0(2 children)\nwe get paid for developing new ideas, not writing great code.\n\nAs someone working in a research group in a large corp, I understand that. However, as someone who's lately had to take some of that academic code and try to make heads or tails of it, I also think that maybe academics might do well to develop their coding skills.  Lots of papers are being published in ML now with code (made available on github usually) and results - the code is really as important as the text of the paper for reproducing the paper's results. We're finding a lot of cases where we run code from the paper and yet cannot reproduce the results from the paper. We also find cases where the text of the paper is lacking in describing how the actual algorithm works - so we look at their code to try to figure out what they were intending. \n\npermalinkembedsaveparentgive award[\u2013]techlos 6 points7 points8 points 7 months ago\u00a0(1 child)The worst part is researchers not commenting their code.  It barely takes any time to write a couple of lines to explain what a chunk of code is doing, and yet a good chunk of research code has barely anything to let other people know what's going on.\nI'd take a thousand lines of well commented spaghetti code over a thousand lines of neat, undocumented code any day.\n\npermalinkembedsaveparentgive awardcontinue this thread[\u2013]mmirman 4 points5 points6 points 7 months ago\u00a0(0 children)A major source of citations is from code adoption, and code adoption comes from having maintained good code.  Bigger and better institutions are highly incentivized to push for maintained code as they need students who go on to be professors with lots of citations to maintain their status as top institutions.\n\npermalinkembedsaveparentgive award[\u2013]cafedude 2 points3 points4 points 7 months ago\u00a0(0 children)But the code is big part of communicating your new ideas these days. If the code is inscrutable you're not getting your ideas across effectively.\n\u200b\n\npermalinkembedsaveparentgive award[\u2013]sseveran 1 point2 points3 points 7 months ago\u00a0(2 children)This seems pretty true. We are a TF shop and that is not likely to change, in fact we are investing more into adopting and extending things like tensorboard and TFX. I still appreciate the pytorch is out there even if we would not use it as it's useful to have multiple tools exploring the design space. I would not want a mono-culture. I think TF is fine rapid prototyping if you work in right way. As someone with years of Haskell experience TF has been pretty natural, static compilation and lazy which was pretty easy to work with. We also write a lot of tests. I hated the original queues and like tf.data a lot better. XLA is cool and powerful but under documented. I still prefer estimators to Keras but maybe in TF2 keras will have all the same capabilities.\n\u200b\nThere is still a significant amount papers being written that use TF and I don't really understand assertions otherwise. Still its super easy to port pytorch to TF usually so its not a big deal when something is written in pytorch.\n\npermalinkembedsaveparentgive award[\u2013]techlos 6 points7 points8 points 7 months ago\u00a0(1 child)\nI think TF is fine rapid prototyping if you work in right way\n\ni'm going to have to respectfully disagree, at least with a clarification - for rapid prototyping using already implemented modules, it's just as flexible. However, at least with the old version of tensorflow... well you're stuck with a static graph.\nI've been working on a hybrid reinforcement learning method where the weights, layer sizes, layer types, and recurrence of the network are themselves defined within a CPPN - essentially, the network architecture changes on the fly, similar to the hyperNEAT idea, but without a fixed base network and using gradient descent rather than neuroevolution. \nWith pytorch, it was pretty easy to find a method to insert or remove layers on the fly, and while it was tricky i did find a working method so that the structure of the model itself was differentiable. I wouldn't even know how to approach the idea with tensorflow, because so much of the design behind it is based off the assumption that you define a model, and then you train that model. Static graphs are great for efficient use of computation resources, but they're limiting.\n\npermalinkembedsaveparentgive award[\u2013]sseveran 1 point2 points3 points 7 months ago\u00a0(0 children)I mean that will always be an issue with a static graph, which is the one real reason to use pytorch over TF, and one which is very under discussed. In TF it would be quite painful (or at least a lot of work) since you would need to build some of your own abstractions. If there is no base network to work from then indeed one would be really trying to do something that TF was not designed to do. And I applaud your actual criticism instead of what many people say which is something along the lines of \"TF is stupid and no one but google uses it\".\n\npermalinkembedsaveparentgive award[\u2013]bartturner 2 points3 points4 points 7 months ago\u00a0(2 children)TF is easily the most popular.  Plus YT videos and even University use TF more often than anything else.\nSame with examples and articles, etc.   Fixing the API will only increase.\nTF has over 120k stars on GitHub\nhttps:\/\/github.com\/tensorflow\/tensorflow\ntensorflow\/tensorflow - GitHub\n\npermalinkembedsaveparentgive award[\u2013]MasterSama 11 points12 points13 points 7 months ago\u00a0(0 children)Usually those who stared TF, dont go back and remove it when they start using a new framework! \nApart from that, What differentiates PyTorch from TF\/Keras IMHO, is the beautiful syntax\/API it offers. \nIts just lovely, they way everything is set is just lovely. I came from a MS C#\/dotnet background and I just love it. \nIts very neat and straight forward thats  just lovable. \nStill, this is great news, Keras API is 100 times better than the tensorflows lowlevel API. \nAs long as the companies behind  these frameworks, don't screw us all, all competition is welcomed and appreciated greatly :)\n\npermalinkembedsaveparentgive award[\u2013]BernieFeynman 3 points4 points5 points 7 months ago\u00a0(0 children)Idk what universities you are referring too, pytorch is def used the most in academia.  The litmus test is whatever stanford uses, which is pytorch for most dl classes.\n\npermalinkembedsaveparentgive award[\u2013]DeepBlender 0 points1 point2 points 7 months ago\u00a0(0 children)TensorFlow users.\n\npermalinkembedsaveparentgive award[\u2013][deleted] 7 months ago\u00a0(1 child)[deleted]\n\n[\u2013]BastiatF 0 points1 point2 points 7 months ago\u00a0(0 children)But it's no longer the research standard\n\npermalinkembedsavegive award[\u2013][deleted] 7 months ago*\u00a0(5 children)[deleted]\n\n[\u2013]dtrillaa -2 points-1 points0 points 7 months ago\u00a0(4 children)TF 2.0 is going to be the exact same API as PyTorch 1.0  essentially\n\npermalinkembedsavegive award[\u2013][deleted] 7 months ago*\u00a0(3 children)[deleted]\n\n[\u2013]DeepBlender 1 point2 points3 points 7 months ago\u00a0(2 children)Not sure if I can follow you. According to my understanding, you basically wrote that TensorFlow 2.0 is not going to be good because the pre-release version has technical issues?\n\npermalinkembedsavegive award[\u2013][deleted] 7 months ago*\u00a0(1 child)[deleted]\n\n[\u2013]DeepBlender 0 points1 point2 points 7 months ago\u00a0(0 children)As I am working only with a single GPU, I can't say anything about multi GPU issues.\nHowever, for single GPU, it works like a charm (with the usual pre-release flaws here and there). While the performance is comparable or better in several of my cases, the real benefit is that it is a lot simpler to work with it. The code overall is way more readable and experimenting is a lot easier. If I screw something up, the error messages are not anymore cryptic, but they point you to the right place.\nTensorFlow 2.0 allowed me to work on the problem I care about. So far I didn't have to fight with obscure technicalities.\n\npermalinkembedsavegive award[\u2013]MasterSama 10 points11 points12 points 7 months ago\u00a0(0 children)So the masochist engineers behind tensorflow are fired now? is over for good?! seems to me Pytorch had a great impact on TensorFlow to change path! like this. \nThis is great news for everyone! the porting from one framework to other (basically from all others to Tensorflow! and vice versa) is now a breeze! \nDown with the cursed TF1! looking forward to more beautiful APIs in keras now ( I really love Pytorch\/MxNet APIs they look so natural and easy to use\/remember) \nThe bad thing all the great tutorials for TF1 now need to change to reflect the new change and it takes couple of months I guess. but still great news. \n\u200b\n\npermalinkembedsavegive award[\u2013]ReinforcementBoi 8 points9 points10 points 7 months ago\u00a0(12 children)PyTorch FTW \\m\/\n\npermalinkembedsavegive award[\u2013]Overload175 1 point2 points3 points 7 months ago\u00a0(11 children)Wait till you need to serve your model, TF is still superior in that respect.  \n\npermalinkembedsaveparentgive award[\u2013]logicchains 9 points10 points11 points 7 months ago\u00a0(0 children)Not if you want to serve it in C++. PyTorch gives you a nice header file and static library, TF gives you... \"Port your entire build system over to Bazel or shove off!\".\n\npermalinkembedsaveparentgive award[\u2013]ReinforcementBoi 0 points1 point2 points 7 months ago\u00a0(9 children)What do you mean by serve a model\n\npermalinkembedsaveparentgive award[\u2013]Overload175 0 points1 point2 points 7 months ago\u00a0(8 children)Export it, deploy it to production. With TF serving you could deploy your model through a Docker container with a preinstalled TF Serving image. Does PyTorch offer an alternative to exporting the graph to ONNX? \n\npermalinkembedsaveparentgive award[\u2013]dpineo 9 points10 points11 points 7 months ago\u00a0(5 children)PyTorch allows you to \"trace\" your model, essentially recording all the computations so they can be replayed on live data like a macro.  The trace can be loaded with torchlib, which is the pure C++ library that's part of PyTorch, completely removing any Python dependency.  I'm using it on my current project for deploying to production and it works great!\n\npermalinkembedsaveparentgive award[\u2013]Overload175 1 point2 points3 points 7 months ago\u00a0(1 child)TIL, thanks! Is this a 1.0 feature? \n\npermalinkembedsaveparentgive award[\u2013]dpineo 3 points4 points5 points 7 months ago\u00a0(0 children)Yes.  See: https:\/\/pytorch.org\/tutorials\/advanced\/cpp_export.html\nAlso note that there is a related but slightly different PyTorch concept called \"TorchScript\" for dealing with data-dependent control flow: https:\/\/pytorch.org\/docs\/stable\/jit.html\n\npermalinkembedsaveparentgive award[\u2013]brunocas 0 points1 point2 points 7 months ago\u00a0(2 children)Excuse my ignorance, but how feasible would be to run this c++ code on a micro controller such as teensy? I have a few ideas for a uC project and I've wondered about this.\n\npermalinkembedsaveparentgive award[\u2013]dpineo 0 points1 point2 points 7 months ago\u00a0(1 child)PyTorch supposedly works on ARM, but you will need to build it yourself, and you still have to worry about your memory + time budget.  \nYou might want to look into NVIDIA's new Nano board.  It's a bit more expensive ($99), but I'm confident will give a much more problem-free development experience.\n\npermalinkembedsaveparentgive award[\u2013]brunocas 0 points1 point2 points 7 months ago\u00a0(0 children)Ok I will have a look at the nano, it will be too big for most of my applications though.\n\npermalinkembedsaveparentgive award[\u2013]amnezzia 1 point2 points3 points 7 months ago\u00a0(1 child)i really don't get this, if you are talking about dockers, how is deploying pytorch any different from deploying any other python model, be it scikit-lear, any gbm libs, or just some custom monstrosity, what is so special about that tf serving image?\n\npermalinkembedsaveparentgive award[\u2013]slaweks 0 points1 point2 points 7 months ago\u00a0(0 children)Python not involved.\n\npermalinkembedsaveparentgive award[\u2013]Overload175 2 points3 points4 points 7 months ago\u00a0(0 children)Google seems to be at that liminal stage right now, transitioning from v1 to v2. But updating the tutorials to include eager execution and tf.keras ASAP is a good idea, they\u2019re a bit of a mess at the moment. \n\npermalinkembedsavegive award[\u2013]terrrp 5 points6 points7 points 7 months ago*\u00a0(0 children)Tf1 was such a shit show. Every 3 months previous code didn't work. There at least like 4 official high level apis with ample samples that did not work after 1 month of publishing. The graph programming model was completely at odds with python and loading or fine-tuning was a pain in the ass.\nThey kept adding new shit that only became more complex and felt like some marketed corporate product rather than an open source library.\n0 reasons to use over pytorch, and they've already lost the favor of a large share of ppl like me who are not taking time to learn the 'beginner' keras. Not to mention pytorch has better internal docs and I can get any model working in c++ in minutes\n\npermalinkembedsavegive award[\u2013]mrathi12 3 points4 points5 points 7 months ago\u00a0(0 children)Amazing!\n\npermalinkembedsavegive award[\u2013]Ularsing 4 points5 points6 points 7 months ago\u00a0(0 children)Sweet. Tf.keras was the bomb. Glad to see they're going all-in.\n\npermalinkembedsavegive award[\u2013]progfu 1 point2 points3 points 7 months ago\u00a0(0 children)Am I the only one who is missing the tf.layers and static graphs? Yes I know they're still there and that I can trace them with @tf.function. But before we had nice declarative interface, and now everything is imperative.\n\npermalinkembedsavegive award[\u2013]LegacyAngel 1 point2 points3 points 7 months ago\u00a0(0 children)Everytime a post like this comes out, my decision to switch to pytorch ages ago makes me giddier\n\npermalinkembedsavegive award[\u2013]MarxSoul55 3 points4 points5 points 7 months ago\u00a0(0 children)I know folks here don't really like fchollet, but I think this is a great accomplishment for him. He created a really nice API (IMO) and it ended up being a big part of one of the most popular deep learning frameworks. I respect him for that, regardless of all the petty politics.\n\npermalinkembedsavegive award[\u2013]pvl 2 points3 points4 points 7 months ago\u00a0(0 children)Not all is bad in TF, the logo is cool. Oh wait, they changed it! \n\npermalinkembedsavegive award[\u2013]BastiatF 3 points4 points5 points 7 months ago*\u00a0(0 children)Or you could switch to Pytorch which has had a sensible API since the beginning, doesn't keep adding incoherent ones every other day and doesn't have a marketing department desperately trying to sell you fake \"revolutions\". \n\npermalinkembedsavegive award[\u2013]SyAbleton 0 points1 point2 points 7 months ago\u00a0(0 children)I called this ages ago.\nhttps:\/\/www.darrenabramson.com\/this-is-good-and-true\/\nNo it wasn't my meme, so technically someone else called it before I did.\n\npermalinkembedsavegive award[\u2013]rajarahulray 0 points1 point2 points 7 months ago\u00a0(0 children)Such a big decision by Google... I just started with tensor flow...but it's good to know that Keras is the new Tensorflow...\n\npermalinkembedsavegive award[\u2013]senortipton 0 points1 point2 points 7 months ago\u00a0(0 children)Funny this should happen. I was reading a book about ML and python a month back and some dude interrupted me to say I should learn Keras. \n\npermalinkembedsavegive award[\u2013]dziejopiswawel 0 points1 point2 points 7 months ago\u00a0(0 children)gluon s better\n\npermalinkembedsavegive award[\u2013]skool_101 0 points1 point2 points 7 months ago\u00a0(0 children)ThanosFlow\n\npermalinkembedsavegive award[\u2013]artificial_intelect 0 points1 point2 points 7 months ago\u00a0(0 children)3 months ago Tensorflow realized that Pytorch is about to rock their world.\nTF execs: Let's rewrite TF to effectively be Pytorch.... I mean let's make it usable.\nMy friend makes this joke: With the tf 2.0 release was like, soooooo lets take TF and just make it a wrapper for pytorch.\n\npermalinkembedsavegive award[\u2013]skhadem 0 points1 point2 points 7 months ago\u00a0(0 children)I've used PyTorch for personal projects and have had to use TF for work recently. I loved the level of abstraction with PyTorch: subclassing nn.model and overriding .forward(), calling .zero_grad() and .backward() with each loop, you really understand what is going on while still using the powerful auto grad tools. Although it seems possible with tensorflow eager execution, you have to dig reallyyy hard to find how to do it. Torch has references for many levels of abstraction, but tensorflow only emphasizes their \"how to train a neural network in 10 lines\". To me it seems PyTorch is starting to be geared towards industry as well as research much better; tensorflow is focusing on non-developers, and I don't see why. \n\npermalinkembedsavegive award[\u2013]Pronoob_me 0 points1 point2 points 7 months ago\u00a0(0 children)As someone who has recently started with tensorflow and have only heard about keras being a higher level api, could someone explain it?\n\npermalinkembedsavegive award[\u2013]yangzhou95 0 points1 point2 points 7 months ago\u00a0(0 children)Wasted too much time learning tf\n\npermalinkembedsavegive award[\u2013]vajra_ 0 points1 point2 points 2 months ago\u00a0(0 children)Tensorflow is SHIT. Knew it from the very first few lines of code I read of it. Kept alive by forceful money pumping by Google, wannabe nerds who just show off and don't really know anything and Asian seniors trying to code random GAN paper for their CVs and don't understand wtf they're doing. The amount of human effort that is being wasted in this shit is astounding.\n\npermalinkembedsavegive award[\u2013]AhnoWrong -1 points0 points1 point 7 months ago\u00a0(0 children)WOW! I fell from my chair!\n\npermalinkembedsavegive award[\u2013]chessbucket -1 points0 points1 point 7 months ago\u00a0(0 children)YAY\n\npermalinkembedsavegive award[\u2013]examachine 0 points1 point2 points 7 months ago\u00a0(0 children)Good news, interoperability is worth it :?\n\npermalinkembedsavegive award[\u2013]bartturner -5 points-4 points-3 points 7 months ago\u00a0(8 children)This was really smart on Google.  \nFran\u00e7ois Chollet now works at Google and makes sense to use Keras.\n\npermalinkembedsavegive award[\u2013]dfarber 5 points6 points7 points 7 months ago\u00a0(7 children)i don't get it, google has like 1000 smarter people working on DL than fchollet. plus like 100000 who are better SW engineers.\n\npermalinkembedsaveparentgive award[\u2013]bartturner 16 points17 points18 points 7 months ago\u00a0(6 children)He came up with a good API.   Numbers do not always matter.  Also being smarter does not always mean creative.\n\npermalinkembedsaveparentgive award[+]dfarber comment score below threshold-14 points-13 points-12 points 7 months ago\u00a0(5 children)yeah, but creative doesn't always mean good. and his api is dogshit.\n\npermalinkembedsaveparentgive award[\u2013]bartturner 5 points6 points7 points 7 months ago\u00a0(3 children)I disagree.  Did you prefer the TF API?\n\npermalinkembedsaveparentgive award[\u2013]NewFolgers 9 points10 points11 points 7 months ago\u00a0(2 children)Which one? I kid, I kid (but not really).\n\npermalinkembedsaveparentgive award[\u2013]bartturner 5 points6 points7 points 7 months ago\u00a0(1 child)How about any before 2.0?\nI also purchased an edge TPU to play and another reason glad to see this move by Google.\n\npermalinkembedsaveparentgive award[\u2013]NewFolgers 1 point2 points3 points 7 months ago*\u00a0(0 children)I think you've misunderstood me [Edit: well, actually.. I think I probably misunderstood your reply to me, and you were just filling in the detail of what I'm alluding to a bit]. TensorFlow 1.x API is unquestionably a disaster (due to too much choice, and annoying complexity and overhead for most things, with no value gained in introductory uses). Reading the official introductions to TensorFlow, it reads like a parody. It leaves me wondering WTF I'm even supposed to begin in terms of doing anything, and it also fails to introduce what the hell is really going on with the graph for people interested in more advanced development\/deployments, perhaps better tooling, etc. I say this after having completed projects using a few of its APIs, and working with others' code using a few of them. Today, I still feel the best way to learn TensorFlow is to learn PyTorch and then convert the code to TF. I hope that changes with TF 2.0.\n\npermalinkembedsaveparentgive award[\u2013]Dagusiu 4 points5 points6 points 7 months ago\u00a0(0 children)The Keras API was the first one get it at least half-right. From a beginner's standpoint, it's night-and-day better than anything that existed before it.\n\npermalinkembedsaveparentgive award[+]Jehovacoin comment score below threshold-31 points-30 points-29 points 7 months ago\u00a0(0 children)With the change to TF2, it will be much easier to implement functions that move towards AGI. This is exciting.\n\npermalinkembedsavegive awardaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 2424 on  r2-app-08a86a06ad3cd72de  at 2019-11-20 21:51:39.277330+00:00 running a5676e6 country code: US."
  },
  "25":{
    "title":"[D] Why is PyTorch as fast as (and sometimes faster than) TensorFlow? : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-gaming-pics-worldnews-funny-todayilearned-tifu-aww-movies-videos-Jokes-gifs-science-mildlyinteresting-Showerthoughts-nottheonion-television-UpliftingNews-OldSchoolCool-dataisbeautiful-sports-personalfinance-explainlikeimfive-GetMotivated-TwoXChromosomes-askscience-nosleep-IAmA-space-LifeProTips-Futurology-gadgets-books-food-Art-Music-WritingPrompts-photoshopbattles-EarthPorn-DIY-Documentaries-history-creepy-listentothis-philosophy-announcements-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  25 Aug 2019269 points (96% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave820,769 readers1,926 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X196  \u00b7 38 comments How to detect AI Snake oil176  \u00b7 42 comments [D] Early coauthorship with top scientists predicts success in academic careers6  \u00b7 2 comments [Discussion] Advice needed: Feeling trapped by lack of management\/strategy, no implemented models.18  \u00b7 7 comments [D] Regarding the ability of neural networks to learn \"simple\" examples first5  \u00b7 1 comment [P] Machine Learning Flight Rules5  \u00b7 1 comment [Research] Announcing Kaolin - PyTorch Library for Accelerating 3D Deep Learning Research219  \u00b7 13 comments [P] How to apply machine learning and deep learning methods to audio analysis4  \u00b7 1 comment [D] Is it ill-advised to perform transfer learning with generalized linear models?20  \u00b7 16 comments [P] askgpt.com I built a simple ui to converse with gpt-2223  \u00b7 15 comments [R] How Machine Learning Can Help Unlock the World of Ancient Japan (by Alex Lamb)Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7268269270Discussion[D] Why is PyTorch as fast as (and sometimes faster than) TensorFlow? (self.MachineLearning)submitted 2 months ago * by student_at_uwSince both libraries use cuDNN under the hood, I would expect the individual operations to be similar in speed. However, TensorFlow (in graph mode) compiles a graph so when you run the actual train loop, you have no python overhead outside of the session.run call. In PyTorch, you are in Python a lot due to the dynamic graph, so I would expect that to add some overhead. Not to mention the fact that having a static graph means you can graph optimizations like node pruning and ordering operations. But in many benchmarks I see online, PyTorch has no problems keeping up with TensorFlow on GPUs.\nA specific example is the Adam implementations in both libraries:\nhttps:\/\/github.com\/pytorch\/pytorch\/blob\/master\/torch\/optim\/adam.py\nhttps:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/tensorflow\/python\/training\/adam.py\nPyTorch has all the ops as you would expect. For TensorFlow in the {_resource}_apply_dense case (which is the common case, AFAIK), TensorFlow has a dedicated C++ implementation.  So here, TensorFlow does not spend extra time in Python AND it has an optimized implementation in C++. In this case, why isn't the TensorFlow version straight up faster?\n\u200b\nI've heard that PyTorch is better optimized on the cuDNN level. Can anyone provide more details about this? What's preventing TensorFlow from doing the same thing?  The only optimization I know of is that PyTorch uses the NCHW format (which is better optimized for cuDNN) whereas TensorFlow by default uses  NHWC.  UPDATE: Looks like the new Volta GPUs perform better with the NHWC  format (TensorFlow's default): https:\/\/devblogs.nvidia.com\/tensor-core-ai-performance-milestones\/\n\u200b\nI saw these two discussions but did not see a satisfactory answer:\nhttps:\/\/www.reddit.com\/r\/MachineLearning\/comments\/7ujc6y\/d_can_someone_give_a_technical_explanation_as_to\/\nhttps:\/\/www.reddit.com\/r\/MachineLearning\/comments\/8iguaw\/d_why_is_tensorflow_so_slow\/\n\u200b\nUPDATE: Looks like the new Volta GPUs perform better with the NHWC  format (TensorFlow's default): https:\/\/devblogs.nvidia.com\/tensor-core-ai-performance-milestones\/\n\n44 commentssharesavehidereportall 44 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]SR2Z 103 points104 points105 points 2 months ago\u00a0(5 children)The key here is asynchronous execution - unless you are constantly copying data to and from the GPU, PyTorch operations only queue work for the GPU.  Python calls to torch functions will return after queuing the operation, so the majority of the GPU work doesn't hold up the Python code.      That moves the bottleneck from Python to CUDA, which is why they perform so similarly.\n\npermalinkembedsavereportgive awardreply[\u2013]huberloss 25 points26 points27 points 2 months ago\u00a0(4 children)TF builds an execution graph that is then processed by the C++ backend, meaning that the only work you do in Python is setting up the graph (at least in TF1.x). I don't think TF will move data to\/from GPU unless needed (i.e., op1 runs on CPU and op2 on GPU and op3 on CPU -> this will result in copying to\/from GPU). TF has executors which will run everything asynchronously as well (meaning that independent nodes will be executed in such a way that you get to satisfying the output nodes ASAP). \nRegarding OP's point, I actually don't know why one is sometimes faster. The only guess I can have is that the data format, or maybe the ways certain ops call CUDA\/cuDNN.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]student_at_uw[S] 13 points14 points15 points 2 months ago\u00a0(2 children)Quick update on data format, looks like the new Volta GPUs perform better with the NHWC format (TensorFlow's default): https:\/\/devblogs.nvidia.com\/tensor-core-ai-performance-milestones\/. But, PyTorch still beats TF in many cases on Volta according to this:  https:\/\/github.com\/u39kun\/deep-learning-benchmark.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tedivm 7 points8 points9 points 2 months ago\u00a0(0 children)The benchmarks you're pointing to are a year and a half old and use what are not considered to be older versions of, well, everything. I'd definitely take it with a grain of salt.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]huberloss 5 points6 points7 points 2 months ago\u00a0(0 children)I guess another issues is what instruction set are those libraries compiled against also... I can imagine that an AVX enabled build will be faster than one without that. Honestly there are a lot of variables that are involved so unless you control the full tool chain you can't compare things correctly.\nAnother example ... in anaconda I can't find pytorch and TF linked against the same version of cuDNN or CUDA.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]piadodjanho 2 points3 points4 points 2 months ago\u00a0(0 children)The data input pipeline in tensoflow is separated from the training logic. If you don't follow the optimization technics described on the tf docs, it is easy to to starve the GPU (or TPUs).\n\npermalinkembedsaveparentreportgive awardreply[\u2013]entarko 56 points57 points58 points 2 months ago\u00a0(6 children)Like you said, both libraries use cuDNN so most of the algorithms used at a low level are similar.\nMy understanding is that the execution in PyTorch is, by default, asynchronous. What this means is that a python command that executes something on GPU makes a call but does not wait for the result of that call, unless the very next operation needs that result. So the only difference in speed for GPU operations is the time needed by the python calls, which in total is small compared to the actual computations on the GPU.\nThis does not explain why sometimes PyTorch is faster, and this comes in part from the NCHW (although it is not always true because NHWC is better optimized for convolutions with groups which need concatenations on the C axis) but also from the choice of the algorithms for different operations (benchmark flag of cuDNN).\n\npermalinkembedsavereportgive awardreply[\u2013]student_at_uw[S] 12 points13 points14 points 2 months ago\u00a0(4 children)Interesting, I didn't know about the benchmark flag (discussion here)!  That's a neat optimization; I'm curious as to why this flag doesn't exist in TensorFlow. Perhaps the graph compilation does the low-level algorithm selection for you?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]entarko 11 points12 points13 points 2 months ago\u00a0(2 children)Probably, although I am not very familiar with TF (inability to have deterministic behavior was a no-go for me).\nYou need to be careful with the benchmark flag, it is not always the best thing to use and can make computations much slower than not using it. Also take a look at the deterministic flag, which typically uses more memory but results in deterministic behaviors and most of the time a speed improvement compared to no flag at all.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]realhamster 0 points1 point2 points 2 months ago\u00a0(1 child)With deterministic you mean setting the rng seeds right? Not sure why I had assumed that TF had better support for deterministic behaviour than pytorch, as far as I am aware there are some pytorch operation that don't support being deterministic, but its good to know that TF also has problems with this!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]entarko 0 points1 point2 points 2 months ago\u00a0(0 children)Nope. I mean obtaining the same result for the same computation. There are indeed some operations that don't support it but I don't need them. In TF, AFAIK there simply is no way of doing it.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]dbalchev 2 points3 points4 points 2 months ago\u00a0(0 children)It exists, but it's not documented and it's On my default\nhttps:\/\/stackoverflow.com\/questions\/45063489\/first-tf-session-run-performs-dramatically-different-from-later-runs-why\n\npermalinkembedsaveparentreportgive awardreply[\u2013]soulslicer0 0 points1 point2 points 2 months ago\u00a0(0 children)yes, and you can use cudasynchronize to sync your stuff. The C++ Pytorch API gives you even lower control like cuda streams\n\npermalinkembedsaveparentreportgive awardreply[\u2013]BatmantoshReturns 17 points18 points19 points 2 months ago\u00a0(2 children)While we're on this topic, does anyone know why the huggingface pytorch Bert so lightweight compared to the Tensorflow versions. People have trouble running the official Tensorflow Bert, even on multiple powerful GPUs, where as Huggingface Bert runs smoothly on a Colab k80 GPU.\n\npermalinkembedsavereportgive awardreply[\u2013]kale_divergence 1 point2 points3 points 2 months ago\u00a0(1 child)I think the Huggingface version is stripped down significantly, with just bare pytorch and a model loader + tokenizer\n\npermalinkembedsaveparentreportgive awardreply[\u2013]BatmantoshReturns 2 points3 points4 points 2 months ago\u00a0(0 children)Anyone know what parts are stripped down? As far as I can tell it has the same architecture.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]patrickkidger 7 points8 points9 points 2 months ago\u00a0(5 children)Not directly related to PyTorch vs TensorFlow, but since NCHW vs NHWC got brought up, I'm hopeful someone here might know the answer...\nWhy is it that batch size N is first and not last? It seems to me that having it last would typically give a speedup due to cache locality.\nThe fact that most datasets aren't in that format shouldn't be a big deal: the overhead of a single copy into an N-last format (i.e. prior to feeding it into a neural network) should be minor compared to the benefits of having an N-last format throughout the rest of the computation.\n\npermalinkembedsavereportgive awardreply[\u2013]programmerChilli 5 points6 points7 points 2 months ago\u00a0(1 child)I think you're right in that putting batch dimension last could allow for some very interesting optimizations (think about all the vectorization).\nHowever, what happens if you have a small batch size? Think a batch size of 2 (maybe 3 would be even worse). All of a sudden the amount of vectorization you can do along the batch dimension is miniscule and you've spread the rest of your data for not much gain.\nThere's actually a couple of frameworks that used this format back in the day. Check out Neon from Nervana.\nActually, looking around just now, I found this very interesting comment from someone who worked on Neon. I think it's roughly what I said, although it seems the reality is a lot more complicated.\nhttps:\/\/github.com\/soumith\/convnet-benchmarks\/issues\/93#issuecomment-192621350\nI guess the main answer is that people tried, but for a confluence of reasons, some political\/some technical, we've currently settled on batch size as the first dimension.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]patrickkidger 1 point2 points3 points 2 months ago\u00a0(0 children)I take your point about small batch sizes. I think that it should be possible to efficiently vectorise even then by \"repeat interleaving\" the kernel but it's true that sounds like less of a sure-fire thing.\nThanks for the link, that was very interesting reading!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]ProfessorPhi 1 point2 points3 points 2 months ago\u00a0(0 children)Hmm, my initial thinking is that it's a row major vs column major thing. Neural nets in Julia use n in the last dim.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Ecclestoned 1 point2 points3 points 2 months ago\u00a0(0 children)Yeah you have your orders reversed. NCHW is a width-major format, i.e. the width is what is packed first. Each cache line will contain sequential spatial data for a single channel of a single input, not independent batches. \nThis means that the locality of convolutions in the width and height dimensions is exploited first, with the operations naively parallelized across batches (because they are totally independent). \nThat being said, if you look at the cuDNN library calls, it will sometimes auto-magically convert to an NHWC format under the hood. This is all part of the automatic algorithm selection that it does and works with practically all frameworks. It might end up using matrix multiply, Winograd, or FFT convolutions depending on dimensions.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]LtCmdrData 1 point2 points3 points 2 months ago*\u00a0(0 children)I think you have your thinking reversed or I don't understand what you mean. \ncuDNN Tensor descriptors  are represented in descreasing order of the strides (just like C\/C++\/Numpy arrays are). This is called row major or lexicographical access order.   The last index has most locality, first has least. This is why N is  first.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]geneing 1 point2 points3 points 2 months ago\u00a0(3 children)It's surprising that TF is not able to optimize static graphs any better than the dynamic graphs of Pytorch and TF Eager. Anybody knows why?\n\npermalinkembedsavereportgive awardreply[\u2013]SR2Z 1 point2 points3 points 2 months ago\u00a0(0 children)This presentation goes over some of the optimizations TF does.\nThe basic gist of it is that a lot of these optimizations provide small benefits or are also handled when you write PyTorch code:\n\nTF discards nodes from the graph if they aren't involved in the output - this is a feature inherent to the lazy gradient evaluation in PyTorch, and it wouldn't calculate anything you didn't explicitly ask for anyways.\nTF does simple math optimizations like factoring and pre-evaluating constants that are really easy to do by hand in PyTorch.\nTF tries to re-order and merge nodes in the graph so that it can take better advantage of cache locality, but many of the CUDA operations that people do on the GPU already have their own schemes to minimize cache stalls.\n\nIt's really hard for TF to make further meaningful optimizations after both the user and the CUDA guys have picked all of the low-hanging fruit.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]student_at_uw[S] 0 points1 point2 points 2 months ago\u00a0(1 child)TF in graph mode is definitely much faster than TF Eager, but is no faster than PyTorch it seems. I hope someone has an answer, this is my main question as well.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]programmerChilli 2 points3 points4 points 2 months ago\u00a0(0 children)Despite my downvotes on my comment :'(, I maintain that it's a combination of the facts that 1. Both rely heavily on operator libraries like cudnn, 2. Tensorflow inherently has a lot of overhead, 3. Tensorflow sometimes makes bad decisions. \nYou're not gonna find a single obvious issue. Tensorflow's static graph API gives strictly more opportunity to optimize. If there was a simple reason why questions like this keep popping up do you really think Google wouldn't have fixed it? They already changed their whole API because people like eager  more - you think they wouldn't do what it takes to fix an obvious performance issue?\nAlso, although not completely relevant since Tensorflow doesn't use XLA by default (I wonder why...), here's some examples of where XLA made things slower. This is for the people who disagreed that Tensorflow messing up could be part of the reason.\nhttps:\/\/stackoverflow.com\/questions\/44523812\/tensorflow-xla-makes-it-slower\nhttps:\/\/github.com\/tensorflow\/tensorflow\/issues\/30791\nhttps:\/\/devtalk.nvidia.com\/default\/topic\/1058729\/mixed-precision-and-tensor-cores\/tensorflow-ssd_resnet50-runs-faster-on-tensorflow-gpu-than-xla-enabled-19-07-py2-container-\/\n\npermalinkembedsaveparentreportgive awardreply[\u2013]un_om_de_cal 1 point2 points3 points 2 months ago\u00a0(0 children)In my experience moving a project from PyTorch to TF, while the basic training operations - forward prop, backprop, update parameters - were faster in PyTorch, some more unusual operations involving argmax and slicing were way slower compared to TF. So maybe PyTorch is better optimized for the more common operations that are typically benchmarked, while TF is optimized for a wider range of operations?\nAnother thing that comes to mind is that the Pytorch tutorials do the data augmentation on the CPU, while the TF ones on the GPU (at least the ones I saw some 1-2 years ago when I started working with it). If you implement your project like this you will do some of the computing on the CPU, which could be more efficient as long as you don't run out of CPU. (I've had the problem of the CPU becoming a bottleneck).\n\npermalinkembedsavereportgive awardreply[+]programmerChilli comment score below threshold-10 points-9 points-8 points 2 months ago\u00a0(12 children)What I've heard is that Tensorflow tries to do a lot of optimizations automatically, and usually gets at least one of them wrong. Thus, it ends up having subpar performance in practice compared to PyTorch.\n\npermalinkembedsavereportgive awardreply[\u2013]piadodjanho 11 points12 points13 points 2 months ago\u00a0(11 children)I don't think this is accurate.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]programmerChilli -2 points-1 points0 points 2 months ago*\u00a0(10 children)Can you elaborate? If anything, I thought my comment was too generically true.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]piadodjanho 4 points5 points6 points 2 months ago*\u00a0(9 children)If you know the processing unit architecture you can generate code that is proven to be faster than the naive implementation. In some cases, the performance won't be optimal because the cost of optimization might be too large (like in ML, you can fall into a local minima).\nEach vendor focus in creating the best numeric library for your system. For instance, MKLL for Intel CPUs, CuDNN for NVdias GPUs and XLA for Google TPUs. But the XLA is also optimized to generate code that run fast at high end GPUs as well. But as today it performs terrible in Intel GPUs, but better if nothing was done.\nBy the way, AFAIK the XLA is the only one that actually does optimization. The others are only implement a tunned kernel. In theory (I haven't look), you can use XLA with CuDNN or MKLL for example.\nIf you are comparing apples to apples, the optimize code will always run faster.\nThere are a few really good optimizer with tuning capabilities to achieve great performance, such TVL and Halide with gradients. Both perform better (as today) than tf or torch. TVL can be used in conjunction with others frameworks as well.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]programmerChilli 5 points6 points7 points 2 months ago*\u00a0(8 children)First of all, XLA utilizes MKLDNN on CPU's and CuDNN for Nvidia GPUs. The only place where they (by necessity) implement their own kernels is for TPU's.\nSecond, I think you're confusing a couple different concepts here. XLA is not comparable to MKLDNN\/CuDNN. MKL\/CuDNN\/Eigen\/cublas are \"operator libraries\" - they're handwritten implementations of basic operations often provided by the vendors. XLA is a whole IR (like LLVM) which compiles down operations and tries to optimize them. It's true that XLA actually does code-gen for your framework, but it's still a distinctly higher level of abstraction than the other libraries you mention.\nAlso, I don't know why you're so confident that \"optimized\" code will always run faster than non-optimized code. For example, it's well known that -O3 will often run slower than -O2 for CPP compilers. Optimization isn't some magic flag that you apply to your code that makes it run faster - it involves making tradeoffs that you hope will speed up your code.\nRe: your last point. Halide is a completely different approach to optimizing image pipelines. It simply separates the functional description from the schedule. It has an autotuner that can try to automatically come up with your schedule. TVM is essentially Halide + some operator libraries + some other goodies.\nBasically, it's a completely different model from the other things you mentioned.\nReading over your comment, I guess my main question is: what in your comment contradicts what I said other than the statement about optimized code running faster?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]piadodjanho -2 points-1 points0 points 2 months ago\u00a0(7 children)Most of the thing you pointed out have been addressed in your comment have been addressed in my OP.\n\nFirst of all, XLA utilizes MKLDNN on CPU...\nSecond, I think you're confusing a couple different concepts here. XLA is not comparable to MKLDNN\/CuDNN.\n\nWhat I said:\n\nBy the way, AFAIK the XLA is the only one that actually does  optimization. The others are only implement a tunned kernel. In theory  (I haven't look), you can use XLA with CuDNN or MKLL for example.\n\nThen, you said:\n\nI don't know why you're so confident that \"optimized\" code will always run faster than non-optimized code. \n\nWhat I said:\n\nIf you are comparing apples to apples, the optimize code will always run faster.\n\nWe are talking about fusing, alignment, storage optimization etc. I thought this could be inferred by the context. Next time I will try not to make assumptions about the reader.\nWhat you said:\n\nBasically, it's a completely different model from the other things you mentioned.\n\nWhat I said:\n\nThere are a few really good optimizer with tuning capabilities to achieve great performance, such TVL and Halide with gradients. Both perform better (as today) than tf or torch. TVL can be used in conjunction with others frameworks as well.\n\n\npermalinkembedsaveparentreportgive awardreply[\u2013]huberloss 2 points3 points4 points 2 months ago\u00a0(3 children)FYI - before getting to XLA grappleralso does graph rewriting.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]piadodjanho -1 points0 points1 point 2 months ago\u00a0(2 children)XLA is a numeric library. I shouldn't know about the graph.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]programmerChilli 2 points3 points4 points 2 months ago\u00a0(1 child)XLA definitely does graph rewriting. It's not the same graph as the Tensorflow graph, but it has enough information for them to do graph level optimizations.\nSearch up XLA HLO. That's what they call their IR.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]piadodjanho 0 points1 point2 points 2 months ago\u00a0(0 children)\nThe input language to XLA is called \"HLO IR\", or just HLO (High Level Optimizer).\n\nFrom XLA Architecture.\nBut you are right, it does preserve some information that could potentially be used to reconstruct the graph.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]programmerChilli 1 point2 points3 points 2 months ago\u00a0(2 children)Your comment is still confusing me.  Let's focus on the only relevant point as opposed to the other points I'm contending. I'll fuse your context into your initial comment.\nYou: \n\nIf you are comparing apples to apples, the optimize code will always run faster... We are talking about fusing, alignment, storage optimization etc.\n\nMe:\n\nI don't know why you're so confident that \"optimized\" code will always run faster than non-optimized code. \n\nI don't understand how adding the context addresses the point. You don't always want to fuse ops, and storage optimization basically describes 90% of the decisions in Halide schedules. My point stands. It's possible to apply fusion or \"storage optimizations\" and make your code slower.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]piadodjanho 0 points1 point2 points 2 months ago\u00a0(1 child)I mean, technically things go awary. But if you know the computer architecture, you can create a darn good scheduler, especially if you only have to worry about the limited use case of neural networks. Honestly, I don't know the intricacies of XLA compiler. I'm talking about my experience with other schedulers. Also, the tensorflow can mess up in the graph optimization before passing to the XLA.\nBut I still find hard to believe the a \"-O0\" XLA code will run slower than \"-O3\" code. Maybe if you do something very unusual... IDK. XLA is different normal compilers, but I can see a non XLA code running faster than a \"-O3\" XLA code though. But this is apples to oranges comparation.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]programmerChilli 1 point2 points3 points 2 months ago\u00a0(0 children)I suppose that if we're simply talking about the performance of Tensorflow vs PyTorch, XLA isn't even relevant (it's not on by default and many benchmarks don't enable it).\nI think you're completely right that it's possible that the graph is messed up before it even gets to XLA. Tensorflow has many optimization passes, and it's not clear how they interplay with each other.\nFundamentally, there's no reason why PyTorch should be faster than Tensorflow. PyTorch's eager mode doesn't give a lot of room for optimization (no graph to optimize over), not compared to the years of effort that Google has put into graph optimizations.\nReally, the only reason Tensorflow should run slower than Pytorch on a benchmark is either A. The overhead is too high, B. They're messing up somewhere.\n\npermalinkembedsaveparentreportgive awardreply[+]CyberDainz comment score below threshold-8 points-7 points-6 points 2 months ago\u00a0(2 children)faster , slower, better, stronger.\nAnyway I bet on google rather than facebook.\n\u200b\nalso plaidML faster than both torch and tf.\n\npermalinkembedsavereportgive awardreply[\u2013]diggerdu 0 points1 point2 points 2 months ago\u00a0(1 child)\nplaidML\n\nincredible, opencl slower than highly optimized CUDA\n\npermalinkembedsaveparentreportgive awardreply[\u2013]CyberDainz 0 points1 point2 points 2 months ago\u00a0(0 children)my tests show different.\nplaidML generates superior optimized gpu kernel, this is why it faster than other frameworks.\n\npermalinkembedsaveparentreportgive awardreply[+]jacksparrowlegends comment score below threshold-29 points-28 points-27 points 2 months ago\u00a0(0 children)because package written in c++ . c++> literally everything else in speed\n\npermalinkembedsavereportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 17941 on  r2-app-030c3614bd34d7a45  at 2019-11-20 22:45:11.869977+00:00 running a474380 country code: US."
  },
  "26":{
    "title":"[Discussion] Next AI winter? Do you think that deep learning solutions will be used in production? : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-funny-worldnews-tifu-pics-television-gaming-todayilearned-aww-gifs-movies-Jokes-personalfinance-Showerthoughts-nottheonion-videos-science-TwoXChromosomes-mildlyinteresting-IAmA-sports-explainlikeimfive-books-LifeProTips-OldSchoolCool-dataisbeautiful-nosleep-space-UpliftingNews-gadgets-Art-Futurology-history-GetMotivated-food-creepy-askscience-EarthPorn-DIY-WritingPrompts-photoshopbattles-Music-Documentaries-announcements-listentothis-philosophy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  08 Nov 20190 points (43% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave821,345 readers1,847 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X152  \u00b7 53 comments [R] [1911.08265] Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model60  \u00b7 3 comments [R] MarioNETte: Few-shot Face Reenactment Preserving Identity of Unseen Targets4 [R] Video Analysis: MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model6  \u00b7 2 comments [D] Does EfficientNet really help in real projects ?25  \u00b7 2 comments [R] Announcing the IKEA Furniture Assembly Environment for Long-Horizon Complex Manipulation Tasks269  \u00b7 69 comments How to detect AI Snake oil21  \u00b7 7 comments [P] I created an unofficial Google Colab notebook sharing site for researchers to showcase their work.12  \u00b7 1 comment [D] Spacy word vectors of dissimilar words match exactly\u00b7 1 comment [D] Must read papers on application of NNs to 3D data, most importantly point clouds4  \u00b7 6 comments [D] Help! How much does your data change in serious ML projects?Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7000Discussion[Discussion] Next AI winter? Do you think that deep learning solutions will be used in production? (self.MachineLearning)submitted 13 days ago by jasabdomML\/AI is gaining traction, but actually not a lot of solutions are being deployed in production, especially in corporations. In startups sure, because very often the main product is AI-based, but I have serious doubts whether regular corporations will continue investing in machine learning engineers. There is still enthusiasm, but not a lot of successful stories, both in CV and NLP (https:\/\/medium.com\/tooploox-ai\/how-to-optimize-your-operations-with-ai-nlp-d3180f2670e3).\n\n22 commentssharesavehidereportall 22 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]poiluducul 19 points20 points21 points 13 days ago\u00a0(5 children)CV using ML\/AI is used by A LOT of major companies in production.\nEvery phone manufacturer use some form of it for there camera.\nEvery car companies is using it for self driving car.\nMany industrial manufacturer use it for default detection and more.\nSotware companies like Adobe are pushing it with AI Sensei.\nAny security based on camera's uses it.\nJohn deere use of AI in the agricultural market is almost unmatched (and consurning).\nThat's just of the top of my head and without talking about what FANGs do ...\n\npermalinkembedsavereportgive awardreply[\u2013]seanv507 2 points3 points4 points 11 days ago\u00a0(0 children)I guess we disagree on terms. ML AI solutions are definitely being used by the big manufacturers.. Samsung etc\nThis will continue.. so there will be no ai winter.\nHowever, the bubble that any company can improve their processes with ML will burst.  It's only those corporation with a lot of data that benefit.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]elcric_krej 1 point2 points3 points 13 days ago\u00a0(2 children)\nEvery phone manufacturer use some form of it for there camera.\n\nHasn't Google switched to a much simpler traditional signal processing algorithm for hdr photos ?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]poiluducul 3 points4 points5 points 13 days ago*\u00a0(1 child)\nHasn't Google switched to a much simpler traditional signal processing algorithm for hdr photos ?\n\nHDR is based on computational photography but their Pixel Neural Core doen't support tensorflow for no reason. HDR is not just a one step process, they can use ML during the image stabilisation, choosing wich shots to ignore, optimise the HDR parameters depending on the subject type, just the identification of the subject is ML and a lot more. And after the photo is taken the Google photo app takes over for classification, tagging, editting etc. And HDR is only one thing, stabilisation, denoising, night sight, color correction, depth detection, setting selection. ML is just one part of the equation, it is often just a complement to computational photography. And honestly the line blures a lot between ML and computational photography depending on the technics used. Specialy since ML\/AI doesn't actually means the same thing deping on who you ask or anything at all ^^\n\npermalinkembedsaveparentreportgive awardreply[\u2013]roeschinc 2 points3 points4 points 12 days ago\u00a0(0 children)Lots of Apple's camera processing uses ML as well and is one of the main applications using their ML HW accelerator in the phones.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sfsdfd 1 point2 points3 points 11 days ago*\u00a0(0 children)When it comes to incorporating machine learning and specifically machine vision into everyday computing, we\u2019re really at the beginning of the curve, not the end.\nThis moment is equivalent to the Internet in 2006, maybe two years into web 2.0 - or computer graphics in 2005. It might have been easy to say: \u201cThe interesting and groundbreaking stuff has been done; what comes next is just boring incremental refinement.\u201d Neither claim would have been correct. The applicability and power of each new capability for computing just needed people who were creative and clever enough to do what others hadn\u2019t done yet.\nThe modern era of machine learning has a long way to go before it even starts to slow down. The needs and priorities of the profession will change, just as they do in every rapidly evolving field. People who get on board now will begin the process of developing a long, deep knowledge base - by 2025, they\u2019ll be able to explain comprehensively how we got there. It will be both a technically and financially valuable skill set.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]KindaKnowKarate 4 points5 points6 points 12 days ago\u00a0(0 children)There's still significant friction around infrastructure that holds companies back from using ML in production. The big gap for production ML software isn't around the ML itself, but around pipeline issues like model serving and maintenance, in my experience.\nSome of the most exciting projects in ML right now, imo, are around infra:  \n\nData Version Control (DVC)\nCortex\nMLflow\n\n\npermalinkembedsavereportgive awardreply[\u2013]mimighost 8 points9 points10 points 13 days ago\u00a0(0 children)Google had improved their 10% of the search requests by using BERT:\nhttps:\/\/www.blog.google\/products\/search\/search-language-understanding-bert\/\nThis alone could probably bring them like hundreds of millions of dollars.\nWinter? Maybe not, but cool down might be the word. The realization that we might have approach the limit what we can achieve within current paradigm, doesn't mean its winter, it is back to reality.\n\npermalinkembedsavereportgive awardreply[\u2013]theakhileshrai 2 points3 points4 points 12 days ago\u00a0(0 children)Apple's iPhone has a dedicated machine learning chip this year. Google has lots of algorithms that are AI specific in pixel. How does this qualify as AI winter?\n\npermalinkembedsavereportgive awardreply[\u2013]elcric_krej 5 points6 points7 points 13 days ago\u00a0(0 children)We're not entering an AI winter, we're entering a normalisation period where growth stops, or rather goes back to the standard 1-6% \/ y rate of other domains. Salaries stop going up, new positions are scarce, you either need a PhD or some pretty impressive credentials to get hired in a semi-desirable position... Things which are standard in most scientific fields.\n\npermalinkembedsavereportgive awardreply[\u2013]phobrain 3 points4 points5 points 13 days ago*\u00a0(2 children)The villagers will come with torches and pitchforks in the night to reclaim their souls, and you will blend in with them thanks to your wizardly use of full-on GPT-2, snatching them into your own sack and selling on to the highest anonymous bidder.\nEdit: .. and that bidder's last name will end in 'utin', so all the more sensible villagers will be directed into the most confusingly addictive, disabling relationships imaginable by any dating apps they attempt to use, and news about harm from something they do a lot like vaping might not make it into their news feed. You really have to break some eggs to rescue capitalism from people who think about alternatives, at least that's how they kept communism running so long. We are soooo much better at mind control now!\n\npermalinkembedsavereportgive awardreply[\u2013]farmingvillein 2 points3 points4 points 12 days ago\u00a0(1 child)Gpt-2, is that you?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]phobrain -1 points0 points1 point 11 days ago*\u00a0(0 children)[answering a different, offscreen question:] \nI was busy once, and as far as I can tell, I haven't thought deeply since - the high is just too overpowering and you can never fully regain the perspective of indolence, so matter how hard you work at aping its forms, norms, odors, appearance, and attitude. Life is cruel but just -- and temporary, anyway, so Viva! For once, just try not changing an item of clothing for a year -- you'll see it doesn't work. :-(\nI was merely opting to ape gpt-2, for fun until accidentally inhaling my snot during a typing triathlon caused a paradigm shift, leaving me unable to see around things that aren't even there, but cautiously optimistic that we will somehow live within the machines we leave behind.\nEdit: just got matrix i,j vs. j,i traversal\/sorting right at last, pending verification, so I really need that ape job bad.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Chocolate_Pickle 4 points5 points6 points 13 days ago\u00a0(1 child)A lot of Business Intelligence stuff can be solved with data+regression. \nYou only commit time, effort, and money into fancy stuff when the basic stuff isn't good enough.\n\npermalinkembedsavereportgive awardreply[\u2013]Northwulf 0 points1 point2 points 12 days ago\u00a0(0 children)Well said.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Murillio 2 points3 points4 points 13 days ago\u00a0(2 children)I don't know where you got the notion that dl isn't used in production. I've worked for multiple companies that use it in production - and no, it isn't just startups.\n\npermalinkembedsavereportgive awardreply[\u2013]jasabdom[S] 1 point2 points3 points 13 days ago\u00a0(1 child)From my experience in banking industry, but I guess it is linked with interpretability and robustness issues. Banking is heavily regulated.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]poiluducul 4 points5 points6 points 13 days ago\u00a0(0 children)\nFrom my experience in banking industry, but I guess it is linked with interpretability and robustness issues. Banking is heavily regulated.\n\nI have friends who work\/ed for banks in different countries and they use a lot of general ML with time series, NLP\/CV for document classifications, NLP\/CV for identity verification and  general ML for fraud prevention.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]yusuf-bengio 3 points4 points5 points 13 days ago\u00a0(0 children)In my experience, CV is intensively used in industry and NLP is gaining momentum. In terms of \"classical\" domains, such as sales\/data warehouse analysis, good-old-fashion Machine Learning models are still dominating.\nDomains where AI\/Deep Learning failed to deliver value to companies is Reinforcement Learning, automation (except CV applications), anything remotely related to safety and legally constrained applications.\n\npermalinkembedsavereportgive awardreply[\u2013]--iRON-- 2 points3 points4 points 13 days ago\u00a0(0 children)Currently for CV nothing works better than CNNs and they are extensively used in production. Deep learning not only allows to create solutions that actually work, but oftentimes requires much less research and effort.\n\npermalinkembedsavereportgive awardreply[+]TritriLeFada comment score below threshold-6 points-5 points-4 points 13 days ago\u00a0(1 child)I think one of the reasons CNNs are not used in production is they are not robust, maybe because they have bad representations. For example those representations should be 3D, not 2D. Also our models should be able to detect by themselves the subparts of an image. They should also be naturally biased toward using shape and not texture.\nHaving those properties would also make models more interpretable, which is another reason they are not used, I think.\nSo I don't think the current architectures will be used in production.\n\npermalinkembedsavereportgive awardreply[\u2013]Taxtro1 0 points1 point2 points 9 days ago\u00a0(0 children)But... they are used.\n\npermalinkembedsaveparentreportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 1294 on  r2-app-0d287fb0f47e023d8  at 2019-11-21 15:41:03.749499+00:00 running 65cc4c1 country code: US."
  },
  "27":{
    "title":"[D] Regression tasks with \"duplicate samples\" : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-funny-worldnews-tifu-pics-television-gaming-todayilearned-aww-gifs-movies-Jokes-personalfinance-Showerthoughts-nottheonion-videos-science-TwoXChromosomes-mildlyinteresting-IAmA-sports-explainlikeimfive-books-LifeProTips-OldSchoolCool-dataisbeautiful-nosleep-space-UpliftingNews-gadgets-Art-Futurology-history-GetMotivated-food-creepy-askscience-EarthPorn-DIY-WritingPrompts-photoshopbattles-Music-Documentaries-announcements-listentothis-philosophy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  08 Nov 20190 points (40% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave821,347 readers1,858 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X154  \u00b7 53 comments [R] [1911.08265] Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model59  \u00b7 3 comments [R] MarioNETte: Few-shot Face Reenactment Preserving Identity of Unseen Targets6 [R] Video Analysis: MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model6  \u00b7 2 comments [D] Does EfficientNet really help in real projects ?24  \u00b7 2 comments [R] Announcing the IKEA Furniture Assembly Environment for Long-Horizon Complex Manipulation Tasks275  \u00b7 69 comments How to detect AI Snake oil19  \u00b7 7 comments [P] I created an unofficial Google Colab notebook sharing site for researchers to showcase their work.15  \u00b7 1 comment [D] Spacy word vectors of dissimilar words match exactly\u00b7 1 comment [D] Must read papers on application of NNs to 3D data, most importantly point clouds5  \u00b7 6 comments [D] Help! How much does your data change in serious ML projects?Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7000Discussion[D] Regression tasks with \"duplicate samples\" (self.MachineLearning)submitted 13 days ago * by Doo0oogAssume there is a data set {(x_i, y_i)}, 0<=i<n, there exist some samples that have the same x value but different y values (x_i == x_j && y_i != y_j) because there is noise when collecting data.\nA common method maybe grouping them with a single y, like their mean value.\nBut are there any researches resolving this kind of data without grouping them together?\nIf yes, what is this kind of problems called? Or some keywords for doing search.\nThank you in advance!\n\n11 commentssharesavehidereportall 11 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]SwordOfVarjo 2 points3 points4 points 13 days ago*\u00a0(3 children)This is an ill posed problem as there is not a unique solution (another way of saying this is that the conditional probability of your dependent data is multimodal).\nNo need to group data with mean y values, an l2 loss will actually result in regressing to the mean anyway (which may or may not be acceptable, depending on the data and your goal).\n\npermalinkembedsavereportgive awardreply[\u2013]Doo0oog[S] 0 points1 point2 points 12 days ago\u00a0(0 children)I\u2019ll do some search about this.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]clurdron 0 points1 point2 points 8 days ago\u00a0(1 child)The conditional distribution doesn't have to be multimodal for this to happen.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]SwordOfVarjo 0 points1 point2 points 8 days ago\u00a0(0 children)Yep, that's true, my original post was a bit unclear. It is sufficient to impose ill-posedness however.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]DaLameLama 2 points3 points4 points 12 days ago\u00a0(1 child)Do a literature review on \"supervised learning with noisy labels\". Sounds like that's what you're looking for.\n\npermalinkembedsavereportgive awardreply[\u2013]Doo0oog[S] 0 points1 point2 points 12 days ago\u00a0(0 children)That\u2019s exactly what I\u2019m looking for. Thanks a lot.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]M4mb0[\ud83c\udf70] 1 point2 points3 points 12 days ago\u00a0(3 children)There are two cases:\n1. either it is just noise, in this case standard methods can do\n2. it is not noise but a real effect.\nThe latter can happen when the dataset is missing some important features. For example consider building a model for the average height of a person, given their age. Girls, on average, hit puberty earlier than boys, while boys on average grow a bit bigger than girls when reaching adulthood. If the dataset does not contain the gender as a feature, it will appear that we are trying to model a multi-valued function.\nBut there are actually models that can dirtectly deal with this situation such as mixture of experts. The key is that, what we model is the conditional probability p(y|x). Now usually, this will be an unimodal distribution such as a gaussian and we can simply predict the mean yhat(x)  = E[y|x]. However, in the situation you describe it will be a multimodal distribution like for example a mixture of Gaussians. Then the mean is pointless, and instead we have to use for example use the modes as our prediction, and for a given x, there will be multiple predictions y_1, y_2,... . In fact this technique can allow us to discover that there missing features!\n\npermalinkembedsavereportgive awardreply[\u2013]Doo0oog[S] 0 points1 point2 points 12 days ago\u00a0(2 children)You are right. And we just treat the second case as the source of noise. Could you recommend some papers or links about this case?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]M4mb0[\ud83c\udf70] 0 points1 point2 points 12 days ago*\u00a0(1 child)I don't know how this is really handled in the state of the art, but a starting point could be to look at the mixture of experts model which is for example covered in Bishop.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Doo0oog[S] 0 points1 point2 points 12 days ago\u00a0(0 children)Thank you. I\u2019ll look for that.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]clurdron 0 points1 point2 points 8 days ago*\u00a0(0 children)Classical statistical methods (which are the basis for a lot of ML) assume you have an error term in your dependent variable. If your independent variable is low-dimensional and can only take countably many values, as was often the case when these methods were developed, then you'll likely have identical x values. If you have identical x values, you'll encounter this 'duplicate sample' situation with probability 1. So this isn't a weird scenario. Almost all statistical\/ML methods deal with this situation without taking any special steps.\n\npermalinkembedsavereportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 29608 on  r2-app-08a86a06ad3cd72de  at 2019-11-21 15:43:25.249577+00:00 running 65cc4c1 country code: US."
  },
  "28":{
    "title":"[R] New Graph Classification Data Sets : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-funny-worldnews-tifu-pics-television-gaming-todayilearned-aww-gifs-movies-Jokes-personalfinance-Showerthoughts-nottheonion-videos-science-TwoXChromosomes-mildlyinteresting-IAmA-sports-explainlikeimfive-books-LifeProTips-OldSchoolCool-dataisbeautiful-nosleep-space-UpliftingNews-gadgets-Art-Futurology-history-GetMotivated-food-creepy-askscience-EarthPorn-DIY-WritingPrompts-photoshopbattles-Music-Documentaries-announcements-listentothis-philosophy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsother discussions (1)Want to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  08 Nov 201987 points (95% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave821,350 readers1,856 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X160  \u00b7 54 comments [R] [1911.08265] Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model58  \u00b7 3 comments [R] MarioNETte: Few-shot Face Reenactment Preserving Identity of Unseen Targets4 [R] Video Analysis: MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model6  \u00b7 2 comments [D] Does EfficientNet really help in real projects ?26  \u00b7 2 comments [R] Announcing the IKEA Furniture Assembly Environment for Long-Horizon Complex Manipulation Tasks268  \u00b7 69 comments How to detect AI Snake oil19  \u00b7 7 comments [P] I created an unofficial Google Colab notebook sharing site for researchers to showcase their work.11  \u00b7 1 comment [D] Spacy word vectors of dissimilar words match exactly\u00b7 2 comments [D] Must read papers on application of NNs to 3D data, most importantly point clouds2  \u00b7 6 comments [D] Help! How much does your data change in serious ML projects?Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7868788Research[R] New Graph Classification Data Sets (self.MachineLearning)submitted 13 days ago by nd7141Graph classification has been popular recently, which led to rich development of Graph Kernels and Graph Neural Networks. All papers more or less verify the results on 10-15 benchmark data sets. We found that these data sets (and 40 others) have a lot of isomorphic graphs which leads to (1) train-to-test leakage and (2) incorrect validation comparison. Absurdly, some isomorphic graphs have different classification labels, making it impossible to classify correctly such instances. We explain the reasons why these isomorphic instances appear in data sets in the first place (e.g. meta-data, sizes of graphs, or origin of a data set) and open-source new clean data sets, both in GitHub and in PyTorch-Geometric. \nHere is a link to the paper:  https:\/\/arxiv.org\/abs\/1910.12091 \nHere is more informal blog post about findings.\n\n5 commentssharesavehidereportall 5 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]matja22 5 points6 points7 points 13 days ago\u00a0(3 children)Hi,\nI think so if two graphs are isomorphics, but those graphs node\/edges has different features, it's correct that has different labels.\n\npermalinkembedsavereportgive awardreply[\u2013]nd7141[S] 1 point2 points3 points 13 days ago\u00a0(2 children)Yes, sure, adding node\/edge labels\/attributes into account helps to distinguish the graphs in some cases, but not in all. Table 7 presents the number of isomorphic graphs after considering node labels during isomorphism testing. Also, some data sets don't have any extra information (e.g. IMDB).\n\npermalinkembedsaveparentreportgive awardreply[\u2013]jmmcd 1 point2 points3 points 12 days ago\u00a0(0 children)On the same issue - it's not absurd IMO. in the real world such data can arise. I can imagine an algorithm which eg fails to converge in this situation. So it's good to test algorithms in this way. In fact the inevitable error rate that occurs here is a known thing, the Bayes error.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]seismic_swarm 0 points1 point2 points 11 days ago\u00a0(0 children)Yeah, good find, but it's not absurd. Lot's of datasets are \"impossible\" to predict correctly, and totally violate the principle of being a function; e.g., f(x1) = y1, f(x1) = y2, yet y1 =\/= y2 in the dataset. This stuff slips in because we can't cull the dataset completely and oftentimes x and y are high dimensional.  It's the job of the regression model to pick the best of the multiple options to minimize the overall loss function as much as possible. So maybe choose f(x1) = y1 everytime (instead of  f(x1) = y2) if there are more instances of the first kind. If that all bothers you, then don't do regression\/classification, calculate the full posterior probability distribution.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]TotesMessenger 0 points1 point2 points 11 days ago\u00a0(0 children)I'm a bot, bleep, bloop. Someone has linked to this thread from another place on reddit:\n\n[\/r\/u_burnaevevgeny] [R] New Graph Classification Data Sets\n\n\u00a0If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads. (Info \/ Contact)\n\npermalinkembedsavereportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 24557 on  r2-app-00c1e7e3b6ef84d9b  at 2019-11-21 15:46:35.636549+00:00 running 65cc4c1 country code: US."
  },
  "29":{
    "title":"[D] Please help me find this paper (Foundations of DL)! : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-funny-worldnews-tifu-pics-television-gaming-todayilearned-aww-gifs-movies-Jokes-personalfinance-Showerthoughts-nottheonion-videos-science-TwoXChromosomes-mildlyinteresting-IAmA-sports-explainlikeimfive-books-LifeProTips-OldSchoolCool-dataisbeautiful-nosleep-space-UpliftingNews-gadgets-Art-Futurology-history-GetMotivated-food-creepy-askscience-EarthPorn-DIY-WritingPrompts-photoshopbattles-Music-Documentaries-announcements-listentothis-philosophy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  08 Nov 20196 points (72% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave821,351 readers1,721 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X161  \u00b7 55 comments [R] [1911.08265] Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model60  \u00b7 3 comments [R] MarioNETte: Few-shot Face Reenactment Preserving Identity of Unseen Targets5 [R] Video Analysis: MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model7  \u00b7 3 comments [D] Does EfficientNet really help in real projects ?27  \u00b7 2 comments [R] Announcing the IKEA Furniture Assembly Environment for Long-Horizon Complex Manipulation Tasks270  \u00b7 69 comments How to detect AI Snake oil20  \u00b7 7 comments [P] I created an unofficial Google Colab notebook sharing site for researchers to showcase their work.14  \u00b7 1 comment [D] Spacy word vectors of dissimilar words match exactly\u00b7 2 comments [D] Must read papers on application of NNs to 3D data, most importantly point clouds3  \u00b7 6 comments [D] Help! How much does your data change in serious ML projects?Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7567Discussion[D] Please help me find this paper (Foundations of DL)! (self.MachineLearning)submitted 12 days ago by HenryWJReeveDear all,\nI have been searching for some time now for a paper I read a while ago but misplaced. \nThe paper was very interesting and showed that finding optimisation with with deep neural networks is, in some sense, easier than with shallow neural networks.\nThe authors generated a data set by generating random input data and then using the predictions of a shallow neural network (A) to provide the ground truth labels of those data. They then tried to train another shallow network (B) with same architecture as (A) the one that created the labels, but with different initializations. It was shown that it was very difficult to find the optimal solution for this dataset. They then tried the same task with a deeper network (C) and found the optimal solution.\nIf anyone knows the name of this paper then please let me know where I can find it. I would be eternally grateful!\nMany thanks!\n\n8 commentssharesavehidereportall 8 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]Z13Wolf 4 points5 points6 points 12 days ago\u00a0(1 child)It's not \"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks\" right? \nFrom my understanding of this paper they are at least somewhat related. They mention \"Contemporary experience is that the architectures uncovered by pruning are harder to train from the\nstart, reaching lower accuracy than the original networks.1\", might be one of the papers they quote in the first footnote.\n\npermalinkembedsavereportgive awardreply[\u2013]HenryWJReeve[S] 2 points3 points4 points 12 days ago\u00a0(0 children)Thanks! I don't think this is the original paper we were after, but it is definitely a related phenomenon.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]jeremycohen_ml 4 points5 points6 points 12 days ago\u00a0(1 child)See the 10:40 mark here: https:\/\/www.youtube.com\/watch?v=uC2IGoTE2u4, though in the experiment reported there, (C) was _wider_ than (A), not deeper.\n\npermalinkembedsavereportgive awardreply[\u2013]HenryWJReeve[S] 1 point2 points3 points 12 days ago\u00a0(0 children)Thanks! This looks very relevant. I will check this in detail.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]testable313 1 point2 points3 points 12 days ago\u00a0(1 child)If I recall correctly, there's a few papers that describe this phenomenon\n\npermalinkembedsavereportgive awardreply[\u2013]HenryWJReeve[S] 1 point2 points3 points 12 days ago\u00a0(0 children)Can you remember the names\/authors? Thanks.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]TSM- 1 point2 points3 points 10 days ago*\u00a0(0 children)I came across this quote and reference and, maybe it is the one you were looking for.\n\nRecent studies have begun to formalize the expressive power of deep versus shallow networks, finding that classification boundaries acquire local curvature and expressivity as an exponential function of network depth but not breadth (Poole et al., 2016).\n\n(The referenced paper has about 160 citations on Google Scholar, which is also an indicator.)\nPossibly, if this isn't it the one, it may cite or be cited by the paper that you are looking for.\nLink to Poole et al's (2016) paper:\nhttps:\/\/arxiv.org\/abs\/1606.05340\n\u200b\nedit: Typos and to say, it does not look like exactly the paper you are looking for, but there is some overlap at least!\n\npermalinkembedsavereportgive awardreply[\u2013][deleted] 12 days ago\u00a0(1 child)[deleted]\n\n[\u2013]adventuringraw 2 points3 points4 points 12 days ago\u00a0(0 children)you're assuming the two models had different numbers of parameters. It'd be trivial to have a 'shallow' network with say, 2 hidden layers, and a 'deep' network with 10, and make sure both have exactly the same number of free parameters. A lot of the more foundational mathematical papers (Multilayer feedforward networks are universal approximators for one canonical example) focus on proving convergence for some property as the number of hidden nodes in a single hidden layer goes to infinity. Shallow does not imply low numbers of parameters. In fact, I think I saw another paper somewhere showing that deep networks require significantly less parameters to get the same training efficiency as shallow networks.\n\npermalinkembedsavereportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 6212 on  r2-app-0c0cc74c60fa2d5f3  at 2019-11-21 15:55:08.203938+00:00 running 65cc4c1 country code: US."
  },
  "30":{
    "title":"[D] To use triplet loss or not when classes labels are given. Question about theoretical\/experimental expectations. : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-funny-worldnews-tifu-pics-television-gaming-todayilearned-aww-gifs-movies-Jokes-personalfinance-Showerthoughts-nottheonion-videos-science-TwoXChromosomes-mildlyinteresting-IAmA-sports-explainlikeimfive-books-LifeProTips-OldSchoolCool-dataisbeautiful-nosleep-space-UpliftingNews-gadgets-Art-Futurology-history-GetMotivated-food-creepy-askscience-EarthPorn-DIY-WritingPrompts-photoshopbattles-Music-Documentaries-announcements-listentothis-philosophy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  08 Nov 20198 points (84% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave821,350 readers1,899 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X160  \u00b7 54 comments [R] [1911.08265] Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model62  \u00b7 3 comments [R] MarioNETte: Few-shot Face Reenactment Preserving Identity of Unseen Targets5 [R] Video Analysis: MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model7  \u00b7 2 comments [D] Does EfficientNet really help in real projects ?28  \u00b7 2 comments [R] Announcing the IKEA Furniture Assembly Environment for Long-Horizon Complex Manipulation Tasks268  \u00b7 69 comments How to detect AI Snake oil17  \u00b7 7 comments [P] I created an unofficial Google Colab notebook sharing site for researchers to showcase their work.14  \u00b7 1 comment [D] Spacy word vectors of dissimilar words match exactly\u00b7 2 comments [D] Must read papers on application of NNs to 3D data, most importantly point clouds3  \u00b7 6 comments [D] Help! How much does your data change in serious ML projects?Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7789Discussion[D] To use triplet loss or not when classes labels are given. Question about theoretical\/experimental expectations. (self.MachineLearning)submitted 13 days ago by kmkolasinskiHi, I look for some  theoretical (or experimental) evidences for the superiority (or not) of the triplet loss over cross-entropy loss. Do you know some research papers which try to benchmark following setup?\n\nLet's say we a fixed dataset which contains M images with annotated labels e.g. MNIST dataset.\nThen we train two models (with same architecture), one with regular categorical cross entropy and second one using triplet-loss approach (or contrastive) etc.\n\nSince the dataset and model architectures are fixed (I assume all other hyperparameters are also fixed, maybe expect learning rate and number of epochs), we will have two models trained to minimize different objectives. I wonder if there is some common knowledge to answer following questions:\n\ncan we expect one of the approaches to have better test accuracy ?\ncan we expect one of the approaches to better generalize for new classes (e.g. not present in the training dataset) ? I mean, triplet loss was first used for face recognition, so one would expect that embeddings generated from model trained with triplet loss should be more useful for finding new classes.\nare there other expected differences ? (I'm aware that model trained with triplet loss requires different methodology for measuring performance)\n\nTLDR: different objective function should result in different models. Can we expect the performance differences without training any model?\n\n7 commentssharesavehidereportall 7 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]atlatic 9 points10 points11 points 13 days ago\u00a0(1 child)This is exactly what you're looking for: https:\/\/arxiv.org\/abs\/1902.09229 \ntl;dr: triplet loss is worse than cross-entropy with labels. The former is an upper bound on the latter.\n\npermalinkembedsavereportgive awardreply[\u2013]kmkolasinski[S] 0 points1 point2 points 10 days ago\u00a0(0 children)Great and thanks! Indeed I was looking for such type of paper.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]melgor89 2 points3 points4 points 12 days ago\u00a0(1 child)Some time ago best option was to use both at once as triplet loss convergence is slower than pure softmax. \nNow, there is common belive and theorem tham pure softmax with implementation like in ArcFace is much better than any triplet loss.\n\npermalinkembedsavereportgive awardreply[\u2013]kmkolasinski[S] 0 points1 point2 points 10 days ago\u00a0(0 children)Thanks a lot for pointing me to the ArcFace paper.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]david_picard 1 point2 points3 points 13 days ago\u00a0(2 children)How do you evaluate your model trained with the triplet loss? If you use anything else than a k-nn, then I would bet you are going to get lower accuracy than the model that has an embedded classifier and is trained for that task.\nRemember that metric learning has some origin in improving k-nn classifiers (see the old LMNN paper by Weinberger), which makes it perfectly suited for the few-shot task, but not really for regular classification.\nIn a nutshell, the loss that works best is the one that corresponds to your evaluation setup. In ML, you are already optimizing on the wrong data (compared to regular optimization), you should try to avoid also optimizing on the wrong problem.\n\npermalinkembedsavereportgive awardreply[\u2013]kmkolasinski[S] 0 points1 point2 points 13 days ago\u00a0(1 child)Thanks for comment. For example I want to create a search engine, should I label images with classes (which is hard when number of classes is very large) or should I label pairs\/triplets (which is much easier but requires more data).  You were right that model trained with triplet loss was worse in the k-nn benchmark in my simple experiments. But the question is if one can guarantee it will be always worse regardless dataset, architecture etc. I'm asking for the existence of general rule. Additionally, what about new classes which will appear every day in my system, which approach is more suitable for such case etc. I'm looking for some papers which try to look at both approaches and discuss their potential advantages.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]I_draw_boxes 1 point2 points3 points 4 days ago\u00a0(0 children)\nI'm asking for the existence of general rule.\n\nSoftmax takes into account all classes in each gradient update.  \n\nAdditionally, what about new classes which will appear every day in my system, which approach is more suitable for such case etc.\n\nRetrain the model with the new class or if possible simply deal with the embedding vector in a one shot learning approach.\n\npermalinkembedsaveparentreportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 21963 on  r2-app-02bc31126f0e126dc  at 2019-11-21 15:48:19.868768+00:00 running 65cc4c1 country code: US."
  },
  "31":{
    "title":"[P] How to Identify Business Processes That Can Be Machine Learning-Enabled : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-funny-worldnews-tifu-pics-television-gaming-todayilearned-aww-gifs-movies-Jokes-personalfinance-Showerthoughts-nottheonion-videos-science-TwoXChromosomes-mildlyinteresting-IAmA-sports-explainlikeimfive-books-LifeProTips-OldSchoolCool-dataisbeautiful-nosleep-space-UpliftingNews-gadgets-Art-Futurology-history-GetMotivated-food-creepy-askscience-EarthPorn-DIY-WritingPrompts-photoshopbattles-Music-Documentaries-announcements-listentothis-philosophy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  08 Nov 20196 points (64% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave821,371 readers1,568 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X173  \u00b7 65 comments [R] [1911.08265] Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model66  \u00b7 3 comments [R] MarioNETte: Few-shot Face Reenactment Preserving Identity of Unseen Targets5 [R] Video Analysis: MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model8  \u00b7 3 comments [D] Does EfficientNet really help in real projects ?2  \u00b7 4 comments [D] Must read papers on application of NNs to 3D data, most importantly point clouds28  \u00b7 2 comments [R] Announcing the IKEA Furniture Assembly Environment for Long-Horizon Complex Manipulation Tasks271  \u00b7 70 comments How to detect AI Snake oil18  \u00b7 9 comments [P] I created an unofficial Google Colab notebook sharing site for researchers to showcase their work.12  \u00b7 1 comment [D] Spacy word vectors of dissimilar words match exactly4  \u00b7 6 comments [D] Help! How much does your data change in serious ML projects?Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7567Project[P] How to Identify Business Processes That Can Be Machine Learning-Enabled (self.MachineLearning)submitted 13 days ago by cdossmanIdentifying Business Processes That Can Be Machine Learning-Enabled  \u27a1 What to look for and expect when analyzing workflows for tasks can be automated with Machine Learning \nhttps:\/\/medium.com\/ai%C2%B3-theory-practice-business\/identifying-business-processes-that-can-be-ml-enabled-529cbe90aa84\n\ncommentsharesavehidereportno comments (yet)sorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an accountthere doesn't seem to be anything hereaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 16339 on  r2-app-0d287fb0f47e023d8  at 2019-11-21 16:35:56.737170+00:00 running 65cc4c1 country code: US."
  },
  "32":{
    "title":"[R]Theoretical research paper in GAN's : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-funny-worldnews-tifu-pics-television-gaming-todayilearned-aww-gifs-movies-Jokes-personalfinance-Showerthoughts-nottheonion-videos-science-TwoXChromosomes-mildlyinteresting-IAmA-sports-explainlikeimfive-books-LifeProTips-OldSchoolCool-dataisbeautiful-nosleep-space-UpliftingNews-gadgets-Art-Futurology-history-GetMotivated-food-creepy-askscience-EarthPorn-DIY-WritingPrompts-photoshopbattles-Music-Documentaries-announcements-listentothis-philosophy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  08 Nov 20198 points (91% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave821,419 readers2,231 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X172  \u00b7 67 comments [R] [1911.08265] Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model72  \u00b7 3 comments [R] MarioNETte: Few-shot Face Reenactment Preserving Identity of Unseen Targets11 [R] Video Analysis: MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model12  \u00b7 3 comments [D] Does EfficientNet really help in real projects ?31  \u00b7 2 comments [R] Announcing the IKEA Furniture Assembly Environment for Long-Horizon Complex Manipulation Tasks2  \u00b7 5 comments [D] Must read papers on application of NNs to 3D data, most importantly point clouds274  \u00b7 70 comments How to detect AI Snake oil14  \u00b7 1 comment [D] Spacy word vectors of dissimilar words match exactly19  \u00b7 9 comments [P] I created an unofficial Google Colab notebook sharing site for researchers to showcase their work.8  \u00b7 6 comments [D] Help! How much does your data change in serious ML projects?Welcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7789Research[R]Theoretical research paper in GAN's (self.MachineLearning)submitted 13 days ago by Mushr00mParadiseHello,\nI am doing some research about GAN's, and I am looking for some mathematical\/theoretical articles. I have noticed a lot of papers presenting new types of GAN's with (sometimes) just some minor alterations to the original. Two papers that fall within the category that I am looking for are:\n'On the limitations of First-Order Approximation in GAN Dynamics' ->  https:\/\/arxiv.org\/pdf\/1706.09884.pdf \n'Which training methods for GANs do actually converge?' ->  https:\/\/arxiv.org\/pdf\/1801.04406.pdf \nThey both start from a simple model and are then able to mathematically prove some  properties and then to empirically demonstrate them. \nI hope the question is clear, and thank you in advance!\n\n9 commentssharesavehidereportall 9 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]atlatic 2 points3 points4 points 13 days ago\u00a0(0 children)Numerics of GANs.\n\npermalinkembedsavereportgive awardreply[\u2013]r-scholz 2 points3 points4 points 12 days ago\u00a0(0 children)You may be interested in this paper: https:\/\/arxiv.org\/abs\/1905.12103\n\npermalinkembedsavereportgive awardreply[\u2013]StellaAthena 2 points3 points4 points 13 days ago\u00a0(3 children)You haven\u2019t asked a question at all. You\u2019ve made an observation and linked to two papers. What is your question? Is it \u201cdo les there exist more theoretically oriented research on GANs\u201d?\n\npermalinkembedsavereportgive awardreply[\u2013]Mushr00mParadise[S] 2 points3 points4 points 13 days ago*\u00a0(2 children)Yeah \" do there exist more theoretically oriented research on GANs\u201d is my question, thank you for the answer!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]StellaAthena 2 points3 points4 points 13 days ago\u00a0(1 child)[Some Theoretical Properties of GANs](www.lsta.upmc.fr\/BIAU\/bcst.pdf) might be a good paper to look at, and it references a significant amount of the existing literature.\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Mushr00mParadise[S] 0 points1 point2 points 13 days ago\u00a0(0 children)\nSome Theoretical Properties of GANs\n\nThank you for the help!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]tpapp157 1 point2 points3 points 13 days ago\u00a0(0 children)There's been some interesting theoretical exploration of GANs from a Game Theory perspective and convergence to a Nash Equilibrium.\n\npermalinkembedsavereportgive awardreply[\u2013]Reiinakano 0 points1 point2 points 12 days ago\u00a0(1 child)I know that this person has some theoretical papers on GANs that gain quite some attention on Twitter. However, I have not read them as I do not have the necessary math background \n https:\/\/scholar.google.com\/citations?user=0qytQ1oAAAAJ&hl=en\nAlso check out this blog https:\/\/www.inference.vc\/about\/\n\npermalinkembedsavereportgive awardreply[\u2013]Mushr00mParadise[S] 0 points1 point2 points 10 days ago\u00a0(0 children)Thank you!\n\npermalinkembedsaveparentreportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 612 on  r2-app-0d287fb0f47e023d8  at 2019-11-21 17:22:14.841289+00:00 running 65cc4c1 country code: US."
  },
  "33":{
    "title":"[R] My DeepMind internship project: Large-Scale GANs (BigGAN) : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-funny-worldnews-tifu-pics-television-gaming-todayilearned-aww-gifs-movies-Jokes-personalfinance-Showerthoughts-nottheonion-videos-science-TwoXChromosomes-mildlyinteresting-IAmA-sports-explainlikeimfive-books-LifeProTips-OldSchoolCool-dataisbeautiful-nosleep-space-UpliftingNews-gadgets-Art-Futurology-history-GetMotivated-food-creepy-askscience-EarthPorn-DIY-WritingPrompts-photoshopbattles-Music-Documentaries-announcements-listentothis-philosophy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsother discussions (1)Want to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  01 Oct 2018201 points (92% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave821,728 readers2,380 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X82  \u00b7 20 comments [D] Why does hierarchical Bayesian regression work well on imbalanced data?33  \u00b7 3 comments [R] Video Analysis: MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model186  \u00b7 79 comments [R] [1911.08265] Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model8  \u00b7 4 comments [D] Combining non-text features with text classifier77  \u00b7 3 comments [R] MarioNETte: Few-shot Face Reenactment Preserving Identity of Unseen Targets3  \u00b7 2 comments [D] Is the Python Statsmodels library production grade?15  \u00b7 8 comments [D] Does EfficientNet really help in real projects ?[P] OpenAI Safety Gym2  \u00b7 4 comments [Discussion] Confusion around Multi-Step and Multivariate LSTM Time Series Forecasting5  \u00b7 7 comments [D] Must read papers on application of NNs to 3D data, most importantly point cloudsWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7200201202Research[R] My DeepMind internship project: Large-Scale GANs (BigGAN) (arxiv.org)submitted 1 year ago by ajmooch60 commentssharesavehidereportall 60 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]ajmooch[S] 42 points43 points44 points 1 year ago\u00a0(3 children)u\/chisai_mikan asked:\n\nIn the same motivation as releasing pre-trained ImageNet weights, or architectures\/augmentation methods found using architecture search, it'll be great if the pre-trained networks (however large they may be) can be released for the community to use and tinker with.\n\nI can't promise anything, but I'm working through the process for this--there are a lot of institutional barriers, but I'm a big believer in open-source, and I'm doing what I can. If we can't get the official weights out I'll at least make sure there's some representative code on my github so that people have a reliable implementation to point to. One thing to bear in mind is that even with the training code and gradient accumulation it's literally impossible to train some of these models with anything less than the resources we use (due to cross-replica batchnorm being critical), so I'm currently thinking about ways to ameliorate that (maybe with another normalizer, or some BN tricks I've got squirreled away). \nu\/RickMcCoy asked:\n\nSo my question is, what's your main method for hyperparameter searching? What percentage of your research time was dedicated for it?\n\nI list basically all of the hyperparam searching in the paper, particularly in the final Appendix. I didn't really invest any time in hyperparameter search--I did a grid sweep over learning rates at the very start (before we'd scaled, so this was on N x 8GPU) and found that the settings from SA-GAN were best, so I just stuck with those until instabilities at large-scale gave me reason to halve the learning rates, and then I just stuck with those. The other sweeps aren't really hyperparameter searches in the sense of trying to optimize some metric, they're much more about investigating an effect--how does sample quality \/ \"convergence\/collapse\" speed \/ stability vary as I change the amount of dropout \/ L2 \/ ortho reg? As I mention in the paper, I monitor gradient norms, losses,  spectra, and sample evolution in detail, and there's a lot to be learned there beyond just scores.\nI think a lot about how those who have access to these incredible compute resources (me for one more week!) should best use them, and while I'm sure if you hooked up a couple of TPU pods and ran grid fine-grained grid search you could eke a few more Inception points out of these models, I just don't care about that kind of stuff. I try to avoid being in situations where I need to run grid search, and instead point resources towards actual experiments. I've launched over 3500 jobs since I got here in June, and while tons of those are just one offs (e.g. run this model and collect sample sheets and metrics, test that this new feature is working) basically all of the rest are what I'd call actual experiments--how does this idea affect perf, how do these two things interact, why does this work the way it does. When you're operating at this scale, you also have to be exceptionally parsimonious in how you schedule and manage your experiments and ideas. There literally isn't enough compute in existence for me to run grid search on the 512x512 models, so it was critical to be discerning in what settings to use, what to measure, etc. \n\npermalinkembedsavegive award[\u2013]elder_price666 7 points8 points9 points 1 year ago\u00a0(0 children)Congrats! This work is incredible and loved the detail regarding hyperparams\/failed experiments.\nWe understand it can be sometimes tough to release code given institutional constraints (some of practical, some of it bureaucratic), but the community would appreciate it very much if the code (or even pretrained models!) would  be released.\n\npermalinkembedsaveparentgive award[\u2013]FishZebra 0 points1 point2 points 1 year ago\u00a0(1 child)Maybe in the future you can use random search for parameter optimization as explained here. It seems to perform better than grid search since many of the parameters actually do not contribute that much. Good job anyways!\n\npermalinkembedsaveparentgive award[\u2013]ajmooch[S] 10 points11 points12 points 1 year ago\u00a0(0 children)As explained above, the goal of my HP searches is not to find the best value, but to measure, quantify, and understand an effect. Searching on regularly specified values is more suited to this.\n\npermalinkembedsaveparentgive award[\u2013]zergylord 40 points41 points42 points 1 year ago\u00a0(5 children)I'm convinced half of this sub is secretly DeepMind employees ;)\n\npermalinkembedsavegive award[\u2013]VernorVinge93 -5 points-4 points-3 points 1 year ago\u00a0(4 children)Seems unlikely considering how many deepmind employees there... Google on the other hand...\n\npermalinkembedsaveparentgive award[\u2013]RSchaeffer 7 points8 points9 points 1 year ago\u00a0(3 children)They have around 800 research scientists now, I think...\n\npermalinkembedsaveparentgive award[\u2013]bulletcross 3 points4 points5 points 1 year ago\u00a0(2 children)What are they doing?\n\npermalinkembedsaveparentgive award[\u2013]ajmooch[S] 13 points14 points15 points 1 year ago\u00a0(1 child)I can't speak for anyone else but I guess I just spend all day contemplating dogball.\n\npermalinkembedsaveparentgive award[\u2013]RSchaeffer 1 point2 points3 points 1 year ago\u00a0(0 children)Beyond that, I don't know what anyone else could conceivably do :D\n\npermalinkembedsaveparentgive award[\u2013]ajmooch[S] 50 points51 points52 points 1 year ago\u00a0(1 child)Hi everybody,\nI've been hanging around here slinging memes and dreams for the last couple of years, and it's been my absolute pleasure and privilege to be able to turn my career from loop jockey to, well, whatever you'd call what I'm doing now. This project is sort of an accidental work that started out as me implementing baselines for another project, but by the time I had a working baseline we'd already moved the SOTA by 15 points, so, uh, I never stopped making the baseline better. All of the investigations into instabilities started out with me saying \"oh these are probably just some simple numerical issue or bug in my code, let me get some diagnostics in there and see what's up.\" I don't think I've ever finished the exact research project I've set out to do (all but one of my publications thus far are like this), and I have no idea what the takeaway from that is, but this result is (I hope) fun and interesting (Dogball being my personal favorite result from this).\nI've been rolling a twitter thread about this work, what we learned, and a little bit of the insights we've gained from it, along some additional samples and lemonpicked samples that aren't in the sheets. I'll be answering questions here or on twitter; my DMs are open on both and of course you can always email me.\nAnd yes, I'm aware there's another thread on the front page, but I don't intend to nonymously comment on an anonymous submission page.\n\npermalinkembedsavegive award[\u2013]IborkedyourGPU 30 points31 points32 points 1 year ago\u00a0(0 children)What do you think of the double blind review process for conference papers?\n\npermalinkembedsaveparentgive award[\u2013]funny1man2 29 points30 points31 points 1 year ago\u00a0(14 children)Perhaps you shouldn't be posting about this now. The review process is supposed to be double blind.\n\npermalinkembedsavegive award[\u2013]i_know_about_things 33 points34 points35 points 1 year ago\u00a0(3 children)Yes, nobody would have a clue who used all those  TPUs if it was 100% double blind.\n\npermalinkembedsaveparentgive award[\u2013]gwern 14 points15 points16 points 1 year ago\u00a0(2 children)The 293m image dataset was also a dead give-away. I was like, 'this is probably some Googler, since I haven't seen much use by researchers of the TPUs...' and then I hit the 293m image dataset they've used in some of the earlier scaling-CNNs papers and that clinched it.\n\npermalinkembedsaveparentgive award[\u2013]ajmooch[S] 5 points6 points7 points 1 year ago\u00a0(1 child)To be  clear, all of the samples are from ImageNet.\n\npermalinkembedsaveparentgive award[\u2013]gwern 1 point2 points3 points 1 year ago\u00a0(0 children)Sure, but merely having access to that dataset is a dead give-away, which was my point. Although now that you mention it, it would be fun to compare samples, but since it's proprietary I'm not surprised that you can't share even samples (and definitely not models).\n\npermalinkembedsaveparentgive award[\u2013]maxToTheJ 9 points10 points11 points 1 year ago\u00a0(0 children)\nThe review process is supposed to be double blind.\n\nSeems to me the \u201cdouble blind\u201d review process is broken because isnt the whole point of the process to prevent a bias towards the big labs like google or its  deepmind or FAIR. \nAt the same time these are the exact same groups both most likely to organize posting it publicly in ArXiv and have a PR team with an associated tech comms team push the result. Nobody is suggesting double blind to prevent a bias against \u201cjoe basic\u201d and the summary he posted on his blog with 10 visitors a month.\n\npermalinkembedsaveparentgive award[\u2013]Screye 7 points8 points9 points 1 year ago\u00a0(3 children)\ndouble blind\n\ndouble blind is dead. It is very easy to tell even if the authors are anonymous, where the paper came from.\nWith Axriv, it is almost entirely done for.\nI think open review has an interesting approach, where the paper is public and anonymous until conference results come in.\nHowever, submissions there are innately tied to a submission, and not independent like axriv. (correct me if I am wrong)\n\npermalinkembedsaveparentgive award[\u2013]maxToTheJ 1 point2 points3 points 1 year ago\u00a0(2 children)Open Review also has its own biases especially against more theory and visualization side. I have read interesting papers from an understanding and visualization side that get mediocre reviews for not having SOTA results on some baseline set\n\npermalinkembedsaveparentgive award[\u2013]Screye 0 points1 point2 points 1 year ago\u00a0(1 child)That has nothing to do with open review though. That is just the conference that it hosts.\nIf an application\/ visualization based conference is hosted on open review, then you can expect to see the papers you mention, get accepted .\n\npermalinkembedsaveparentgive award[\u2013]maxToTheJ 0 points1 point2 points 1 year ago\u00a0(0 children)\nThat has nothing to do with open review though. That is just the conference that it hosts.\n\nKind of does because open review isn\u2019t effective as sold\n\npermalinkembedsaveparentgive award[\u2013]ajmooch[S] 6 points7 points8 points 1 year ago\u00a0(3 children)I'm posting the arXiv paper, which is allowed by the conference rules for NIPS\/ICML\/ICLR. I cannot prevent people from finding a public anonymous submission, and I cannot prevent people from sharing it and linking to\/hyping an anonymous submission page. Posting it publicly allows discussions to proceed nonymously, lets me get feedback and answer questions, and pulls the focus to the arXiv version rather than the anonymous page. Should the conference rules change to prohibit arXiv posts I will of course comply. \nIf you think this should change then consider contacting the conference chairs or starting a public discussion (preferably not in my thread =p).\n\npermalinkembedsaveparentgive award[\u2013]AGI_aint_happening 25 points26 points27 points 1 year ago\u00a0(2 children)You are objectively violating the spirit, if not the letter, of double-blind reviewing. You could very easily get feedback and answer questions after the reviewing process is complete in 2.5 months. I know at least a couple senior researchers within Google feel the same.\n\npermalinkembedsaveparentgive award[\u2013]dwf 9 points10 points11 points 1 year ago\u00a0(0 children)The \"spirit\" of something is by definition unwritten and therefore subjective.  On the contrary, the rules explicitly state that arXiv preprints are allowed. If this is a faux pas, conference organizers have a powerful tool in their hands with which to shape behaviour: change the rules. Either forbid deanonymized preprints or abandon the pretense and go back to singly-blind.\n\npermalinkembedsaveparentgive award[\u2013]maxToTheJ 8 points9 points10 points 1 year ago\u00a0(0 children)\nYou are objectively violating the spirit\n\nYup\n\npulls the focus to the arXiv version rather than the anonymous page\n\n\npermalinkembedsaveparentgive award[\u2013]alexmlamb 4 points5 points6 points 1 year ago\u00a0(0 children)So posting to arxiv and promoting is considered to be okay.  In effect it's \"single blind\" + \"opt-out double-blind\".  So you can stay anonymous if you want, but you can also promote your paper.  \n\u200b\n\npermalinkembedsaveparentgive award[\u2013]nicoulaj 4 points5 points6 points 1 year ago\u00a0(1 child)Thank you for this great paper !\n\u200b\nI didn't really get the section about discriminator instability:\n\nThis confirms that D is indeed memorizing the training set; we deem this in line with D\u2019s role, which is not explicitly to generalize, but to distill the training data and provide a useful learning signal for G.\n\nThis is very counter intuitive to me. So that means, if the training set is \"too large\" for the discriminator to memorize, that would degrade the performance of the model ?\n\npermalinkembedsavegive award[\u2013]ajmooch[S] 7 points8 points9 points 1 year ago\u00a0(0 children)Not necessarily. Our specific point with this statement is that it's not necessarily bad from a modeling standpoint if D memorizes the training set. It may be a piece of the stability puzzle (particularly with the hinge loss, if signal from the real samples starts to attenuate as D's outputs all end up beyond the margin) but it's not clear that D learning a compressed-but-memorized version of the training data is harmful to the learning process. FWIW we appear to observe that our models are stable for far longer when trained on a larger dataset, so this may in fact be a critical piece of the puzzle, but we don't have enough evidence to make a solid claim on that.\nA side note, even if G was memorizing the training data exactly, a generative model which (1) memorizes all the training points and (2) can smoothly and meaningfully interpolate between them, with lots of space in between, is something many people would consider a pretty good model. \n\npermalinkembedsaveparentgive award[\u2013]mathijs_p 7 points8 points9 points 1 year ago\u00a0(1 child)This looks very interesting, I wish I had the computer power you have!\nI investigated sampling z-vectors from a more 'narrow' distribution in my bachelor's thesis, finding similar results (increasing quality, decreasing variety). \n\u200b\n\npermalinkembedsavegive award[\u2013]ajmooch[S] 7 points8 points9 points 1 year ago\u00a0(0 children)Nice! There's actually a couple concurrent works that do some of the same things we do, but yours definitely predates all this--I'll be sure to add the reference when we next update!\n\npermalinkembedsaveparentgive award[\u2013]mrconter1 3 points4 points5 points 1 year ago\u00a0(2 children)Impressive! If you wouldn't mind answering me, what do you personally see as the most promising areas where GANs can be used?\n\npermalinkembedsavegive award[\u2013]ajmooch[S] 9 points10 points11 points 1 year ago\u00a0(1 child)Thanks! This is a good question--right now there's a lot of things that look like they could \"potentially\" be powerful, like real-time postprocessing super-res style things in games, maybe style transfer or CycleGAN style domain shifts that are directly learned and interpretably controlled, but for both algorithmic and computational reasons we're still a long ways off from those really taking hold (though there's lots of research pushing this direction). There's some recent work on audio style transfer as well, although GANs for sequences are still embryonic. \nI'm personally more interested in GANs for their power as a representation learning method--I want to build models that can reliably factor complex visual structure into low-dimensional (ideally interpretable but not necessarily) representations, and I want to build methods to reason about these representations, both in situ, in conjunction with other types of networks and learned representations, and for downstream tasks. I'm really inspired by a lot of the related work in this area but for practical reasons it tends to focus on VAEs, and I think there's a lot of cool things to be done with implicit models. \n\npermalinkembedsaveparentgive award[\u2013]mrconter1 0 points1 point2 points 1 year ago\u00a0(0 children)Thank you!\n\npermalinkembedsaveparentgive award[\u2013]Screye 3 points4 points5 points 1 year ago\u00a0(2 children)You just posted this to make us jealous didn't ya ?            \nI am acquainted with GANs on a surface level.\nHave a couple of questions:\n\nIn your experience, what metrics provide the most balanced idea of the quality of generated samples ? What are the strengths\/shortcomings of popular metrics ?\nHow do you differentiate between a generator memorizing and learning actual latent representations of the object we wish to generate ?\nIn my experience, GANs have a huge problem of consistently providing the type of results we see in papers. Published qualitative results often tend to be the best generated samples from experiments.\nDo you think the task of pursuing more consistent results is at odds with obtaining the occasionally excellent, yet inconsistent results ? Are there specific architectural choices that reflect this tradeoff ?\n\nLastly, congrats.\n\npermalinkembedsavegive award[\u2013]ajmooch[S] 6 points7 points8 points 1 year ago\u00a0(1 child)Jealous? Nay, friend, merely to spread the Good Word (that of Dogball)\nThese are all good questions!\n\nI haven't played much with KID but between IS and FID, FID is generally more reliable (there are lots of silly things that can happen around collapse, which make the IS go up when sample quality goes down, which don't affect FID). They're both exceptionally flawed, however--IS only really tells you broadly how \"objecty\" your samples are, assuming you are training on class-conditional ImageNet (the only dataset for which it is suited--no, really, IS is IMO completely useless outside of this unless you have another class-balanced single-object image dataset). FID gives you a broad sense of how much the overall statistics of your samples match the statistics of the training data, but this too is flawed (and dependent on a lot of things like preprocessing--we can actually get lower FID scores if we compare against moments computed with different preprocessing!) Other metrics like AIS might be, perhaps, more informative, but are too slow to be of practical use during training (maybe for final model comparison) but I haven't used it at all so I can't really say one way or the other. All this to say that we definitely need to move away from these metrics, but I didn't have the time or the paper space to do that with this work.\nUsually nearest neighbors tests and interpolations are the go-to here. Sanjeev Arora has this Birthday Paradox test, but IMO it's flawed (it doesn't measure how similar the latent vectors are, just how similar the outputs are, so I think it dramatically underestimates the support of the generator; if any followup work does address this please correct me on this front!). I think that memorization is only a problem if it cooccurs with collapse--if a large subspace of the latent space maps to a single output point which strongly resembles a training point, then you're memorizing in a bad way. If, however, you have a model which maps a single point in the latent space to each training point, but can interpolate between each of those training points smoothly and meaningfully (with plenty of space in between), then I would call that a good generative model. Actually measuring this is difficult and an open research question atm.\nThis is an interesting one--it's sort of the cherrypicking vs random samples vs lemonpicking argument. The truncation trick is, in a way, a method for automatically filtering down to the \"best\" samples the model can produce, which could be analogous to paging through all your samples manually and grabbing the best ones. I included a link to the drive with sample sheets primarily so people could get a more complete sense for what the full range of our samples look like. I don't think that one has to give up consistency of sample quality to push the peak sample quality forward (IMO even our average-worst samples are higher quality than some of the previous best samples ~1 year ago), especially if you split along class lines.\n\nOne of the reasons this is difficult to properly assess is that sample quality varies dramatically between classes, and the way this varies tends to be more a function of the data (how complex it is and how much of it you have relative to its complexity) rather than the quality of your model itself. ImageNet is, funnily enough, sort of a few-shot learning problem for generative models, at least for many of the classes (crowds and people in particular) where there's at most a few thousand images. I think that if you wanted to get consistent-across-class sample quality for all of ImageNet you might need to look into low-shot learning techniques; while you can definitely overfit a GAN to a small single-class dataset like CelebA-HQ, it's really hard to overfit a conditional model to a subset of the dataset, especially if that subset is different.\n\npermalinkembedsaveparentgive award[\u2013]Screye 0 points1 point2 points 1 year ago\u00a0(0 children)Hey, thanks a lot.\nThose answers do clear a lot of my questions.\n\npermalinkembedsaveparentgive award[\u2013]unguided_deepness 2 points3 points4 points 1 year ago\u00a0(0 children)Anyone want to see how well this can be applied to the danbooru dataset?\n\npermalinkembedsavegive award[\u2013]matesteinforth 2 points3 points4 points 1 year ago\u00a0(1 child)https:\/\/www.youtube.com\/watch?v=YY6LrQSxIbc\n\npermalinkembedsavegive award[\u2013]austospumanto 0 points1 point2 points 9 months ago\u00a0(0 children)Thank you. Love this.\n\npermalinkembedsaveparentgive award[\u2013]zergling103 1 point2 points3 points 1 year ago\u00a0(1 child)You should make a video like what the Progressively Growing GAN people did with their work.\n\npermalinkembedsavegive award[\u2013]ajmooch[S] 3 points4 points5 points 1 year ago\u00a0(0 children)Normally I do (I animated my last one and it took, unsurprisingly, a verrry long time) but I don't quite have enough time to put that together right now. I would really like to show some hour-long interps if I can get around to it!\n\npermalinkembedsaveparentgive award[\u2013]Phantine 1 point2 points3 points 1 year ago\u00a0(1 child)Let's talk the biggest, most practical application possible:\nHow feasible do you think it be to use bigGAN to generate card images for Roborosewater?\n\npermalinkembedsavegive award[\u2013]ajmooch[S] 1 point2 points3 points 1 year ago\u00a0(0 children)That's an excellent question--this may not only be the most practical application but possibly the single most important application possible. Maybe you could even condition it on the text--I would be very curious to see how the model tries to render Mointanspalk.\n\npermalinkembedsaveparentgive award[\u2013]scutzzy 1 point2 points3 points 1 year ago\u00a0(4 children)Hello ajmooch, I have some trouble in understanding how to implement the shared embedding and how to combine these embedding with  latent z in each cbn-layer. The channel size in each layer should be different and how do you projection the embedding to different channel size. I think that simply using the fully connected layer won't be able to reduce the number of parameters. Could you please tell me how you did it?\n\npermalinkembedsavegive award[\u2013]ajmooch[S] 1 point2 points3 points 1 year ago\u00a0(3 children)Normally:\nz = normal(size=(batch_size, 128))\nNormally, this would go into the first linear layer which would be of shape\nLinear(128, 1536 * 4*4)\nbut if you use the hierarchical Z, you instead have (for example))\nz = [normal(size=(batch_size, 16)) for _ in range(8)]\nThen the first linear layer receives z[0], and is thus of size\nLinear(16, 153644)\nThen every other layer, which would normally receive\nembedding = shared_embedding(y) in (batch_size, 128)\nAnd project that to the BN gains and biases via\ngain_i = projection_gain_i * embedding + 1\nbias_i = projection_bias_i * embedding\ninstead receives at each layer, concatenate([embedding, z[i]]) (concatenated along the channel axis).\nThis slightly increases the number of parameters at each BN layer but sharply decreases the number of params in the first linear layer. It's a pretty simple architectural difference but it seems to speed up training (to convergence\/crash)\n\npermalinkembedsaveparentgive award[\u2013]scutzzy 1 point2 points3 points 1 year ago\u00a0(2 children)Thank you for your detailed explanation. But I still don't fully understand. Let's assuming h = concatenate([embedding, z[i]]) whose shape should be (batch_size, 128+16), and assuming i_th layer has input shape(batch_size,512,4,4). Then what you mean is to multiply h with a matrix (128+16, 512) to get each channel's gain_i and bias_i? \n\npermalinkembedsaveparentgive award[\u2013]ajmooch[S] 0 points1 point2 points 1 year ago\u00a0(1 child)Yep! separate matrix for each gain_i and bias_i\n\npermalinkembedsaveparentgive award[\u2013]scutzzy 0 points1 point2 points 1 year ago\u00a0(0 children)I get it, thank you very much.\n\npermalinkembedsaveparentgive award[\u2013]bartturner 2 points3 points4 points 1 year ago\u00a0(0 children)Just love how Google\/DeepMind share this type of thing.   \n\npermalinkembedsavegive award[\u2013]Phantine 0 points1 point2 points 1 year ago\u00a0(4 children)There's what, 12000+ total minutes of The Simpsons produced?\nThe simpsons is animated at 24 frames per second\n... How good a performance do you think you could by training it on 17 million frames from the same source?\n\npermalinkembedsavegive award[\u2013]ajmooch[S] 2 points3 points4 points 1 year ago\u00a0(3 children)Good question--I think convolutional architectures aren't as well-suited to doing line drawings and solid colors, (in an ideal world I'd use SPIRAL for that) but given the sheer amount of data it would probably work fine. I've actually been kicking around some ideas for something like this but with more heuristics and traditional CV in the mix to get data-driven user-controllable cartoon models, but it's not something I have the time or resources for right now, and it's not really something I could justify using the Google compute for.\nMaybe if we manage to get more compute-efficient (if you can get BigGAN results with 1\/1000th of the FLOP-hours we used that would be a big win) it would be approachable on a home or 4GPU or 8GPU machine.\n\npermalinkembedsaveparentgive award[\u2013]Vermeille 2 points3 points4 points 1 year ago\u00a0(2 children)GANime (IIRC) has some tricks to enforce lines with sharp edges: they feed, to the discriminator:\n\nreal images, to be tagged as real\nfake images, to be tagged as fake\nreal blurred images to be tagged as fake\n\nso D really learns to discriminates against blurred edges and G learns sharp edges :)\n\npermalinkembedsaveparentgive award[\u2013]ajmooch[S] 1 point2 points3 points 1 year ago\u00a0(1 child)Ah, clever! I hadn't considered that idea--augmenting the inputs to D to encourage a particular behavior is really interesting!\n\npermalinkembedsaveparentgive award[\u2013]Phantine 0 points1 point2 points 1 year ago\u00a0(0 children)I suppose another option is training it to use a different output format entirely.  In principle I could see having the outputs correspond to vector lines and polygons instead of individual pixels being easier to train with, since the output image isn't going to have a lot of shading.\n(Btw have you seen the previews for the next style2paints?  https:\/\/twitter.com\/IlIIlIIIllIllII )\n\npermalinkembedsaveparentgive award[\u2013]gagarin_kid 0 points1 point2 points 10 months ago\u00a0(0 children)Great work! What do you think about the future of generative methods? Where do you see further improvements - is it the scale in resources (like you did) or some algorithmic tweaks?\n\npermalinkembedsavegive award[\u2013]mpividori 0 points1 point2 points 10 months ago\u00a0(0 children)The \"example use\" code included in the TensorflowHub's modules: biggan-128, biggan-256 and biggan-512, seems to implement something different to the truncation trick described in the original paper: \"Large Scale GAN Training for High Fidelity Natural Image Synthesis\".\nI mention the difference between both distribution in a github issue: https:\/\/github.com\/tensorflow\/hub\/issues\/214\nu\/ajmooch  which latent distribution have you considered for the experiments mentioned in the paper? Is it a real truncated normal?\n\npermalinkembedsavegive award[\u2013]Overload175 -1 points0 points1 point 1 year ago\u00a0(0 children)These results(as evidenced by the Inception Score and the FID) are truly incredible. \n\npermalinkembedsavegive awardaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 4074 on  r2-app-021a24231eab972ba  at 2019-11-21 23:41:17.946556+00:00 running 7e0f65a country code: US."
  },
  "34":{
    "title":"[P] These Lyrics Do Not Exist : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-funny-worldnews-tifu-pics-television-gaming-todayilearned-aww-gifs-movies-Jokes-personalfinance-Showerthoughts-nottheonion-videos-science-TwoXChromosomes-mildlyinteresting-IAmA-sports-explainlikeimfive-books-LifeProTips-OldSchoolCool-dataisbeautiful-nosleep-space-UpliftingNews-gadgets-Art-Futurology-history-GetMotivated-food-creepy-askscience-EarthPorn-DIY-WritingPrompts-photoshopbattles-Music-Documentaries-announcements-listentothis-philosophy-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsWant to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  10 Aug 2019163 points (96% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave821,736 readers2,216 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X90  \u00b7 21 comments [D] Why does hierarchical Bayesian regression work well on imbalanced data?36  \u00b7 4 comments [R] Video Analysis: MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model186  \u00b7 79 comments [R] [1911.08265] Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model6  \u00b7 4 comments [D] Combining non-text features with text classifier[P] OpenAI Safety Gym77  \u00b7 3 comments [R] MarioNETte: Few-shot Face Reenactment Preserving Identity of Unseen Targets3  \u00b7 2 comments [D] Is the Python Statsmodels library production grade?14  \u00b7 8 comments [D] Does EfficientNet really help in real projects ?2  \u00b7 4 comments [Discussion] Confusion around Multi-Step and Multivariate LSTM Time Series Forecasting5  \u00b7 7 comments [D] Must read papers on application of NNs to 3D data, most importantly point cloudsWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7162163164Project[P] These Lyrics Do Not Exist (self.MachineLearning)submitted 3 months ago * by itsmybirthday19[removed] 56 commentssharesavehidereportall 56 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]itsmybirthday19[S] 76 points77 points78 points 3 months ago\u00a0(3 children)Input: \ud83c\udf7a (beer emoji)\nOutput:\nVerse 1\nDad I had to have a \ud83c\udf7a\nTo help me get through another day\nWhen I think of the lady I love\nTime to drink that \ud83c\udf7a\n\nPre-Chorus\nThey were drinking \ud83c\udf7a outside of my father's house\nLet's take our time with this \ud83c\udf7a\n\nChorus\nCold \ud83c\udf7a on the floor\nAnd I can see you now\nTo change those words you feed me with lies\nI chug \ud83c\udf7a \ud83c\udf7a \ud83c\udf7a \ud83c\udf7a \ud83c\udf7a\n\nVerse 2\nI've come here again to drink my \ud83c\udf7a again.\nI've come here again to drink my \ud83c\udf7a again.\nOh I'm goin' right on! don't you see?\nJust 'cause I look just fine\n\nPre-Chorus\nOne more \ud83c\udf7a and I'll be in no state to do the things I think I need to\nA place to shake my \ud83c\udf7a\n\nChorus\nCold \ud83c\udf7a on the floor\nAnd I can see you now\nTo change those words you feed me with lies\nI chug \ud83c\udf7a \ud83c\udf7a \ud83c\udf7a \ud83c\udf7a \ud83c\udf7a\n\nBridge\nNeed a friend to sell my \ud83c\udf7a\nOr \ud83c\udf7a and a movie or whatever\n\nChorus\nCold \ud83c\udf7a on the floor\nAnd I can see you now\nTo change those words you feed me with lies\nI chug \ud83c\udf7a \ud83c\udf7a \ud83c\udf7a \ud83c\udf7a \ud83c\udf7a\n\n\npermalinkembedsavereportgive awardreply[\u2013]johnminadeo 12 points13 points14 points 3 months ago\u00a0(0 children)That\u2019s simply amazing!\n\npermalinkembedsaveparentreportgive awardreply[\u2013][deleted] 1 point2 points3 points 3 months ago\u00a0(0 children)That's wonderful, makes me want to seek out a chord progression generator and try to make it work\n\npermalinkembedsaveparentreportreply[\u2013]Observer0x1a4 40 points41 points42 points 3 months ago\u00a0(4 children)Someone needs to run this through a text-to-speech and auto tune with a beat. My wife and I are cracking up over these!\n\npermalinkembedsavereportgive awardreply[\u2013]crikeydilehunter 4 points5 points6 points 3 months ago\u00a0(3 children)Way ahead of you\n\npermalinkembedsaveparentreportgive awardreply[\u2013]cpury 2 points3 points4 points 3 months ago\u00a0(1 child)OMG please share your results!\n\npermalinkembedsaveparentreportgive awardreply[\u2013]crikeydilehunter 0 points1 point2 points 3 months ago\u00a0(0 children)Ok, so I decided to make a full song and it's taking longer. Don't worry, I didn't forget!\n\npermalinkembedsaveparentreportgive awardreply[\u2013][deleted] 1 point2 points3 points 3 months ago\u00a0(0 children)please post results\n\npermalinkembedsaveparentreportreply[\u2013]catandDuck 12 points13 points14 points 3 months ago\u00a0(1 child)Verse 1\nAnd you're f**king your girlfriend\nGo out to the club.\nStay home it's time to do it all night!\nAnd you're f**king your girlfriend\nPre-Chorus\nShe asked if I had a girlfriend well I do\nThat's what my girlfriend told me\nChorus\nWasn't my girlfriend on the day?\nWasn't my girlfriend on the day?\nI have a girlfriend and my heart is not that strong\nI have a girlfriend and my heart is not that strong\nVerse 2\nAnd you can't touch your girlfriend\nIf she don't dig the men\nIt doesn't make your friend a bad guy\nYeah you can't touch your girlfriend\nPre-Chorus\nHe's got a girlfriend too\nHe's got a girlfriend too\nChorus\nWasn't my girlfriend on the day?\nWasn't my girlfriend on the day?\nI have a girlfriend and my heart is not that strong\nI have a girlfriend and my heart is not that strong\nBridge\nHang up the phone girlfriend\nHang up the phone girlfriend\nChorus\nWasn't my girlfriend on the day?\nWasn't my girlfriend on the day?\nI have a girlfriend and my heart is not that strong\nI have a girlfriend and my heart is not that strong\n\npermalinkembedsavereportgive awardreply[\u2013]itsmybirthday19[S] 4 points5 points6 points 3 months ago\u00a0(0 children)Sounds like a country song \ud83e\udd20\n\npermalinkembedsaveparentreportgive awardreply[\u2013]itsmybirthday19[S] 11 points12 points13 points 3 months ago\u00a0(2 children)Example output:\nVerse 1\nWith love and hope inside our eyes from the world we grew\nAnd the love the love our family make\nI'd been here once before\nHe seemed to ask to ride beside me\n\nPre-Chorus\nI need love oh love\nIt's about be in love\n\nChorus\nA little bit of rain there will always be love\nAnd I knew you were in love with me.\nFor the way that our love's become a game\nTo show you I'm in love\n\nVerse 2\nYou make a fool of yourself my love\nYou take what you've been denied\nTo think you've been looking in my eyes\nI don't want a broken love\n\nPre-Chorus\nAnd I've got love all over me\nWhen I'll let you in and we'll see what this love can do\n\nChorus\nA little bit of rain there will always be love\nAnd I knew you were in love with me.\nFor the way that our love's become a game\nTo show you I'm in love\n\nBridge\nAnd heaven opened up high\nI'm in love with you and I always will love you\n\nChorus\nA little bit of rain there will always be love\nAnd I knew you were in love with me.\nFor the way that our love's become a game\nTo show you I'm in love\n\n\npermalinkembedsavereportgive awardreply[\u2013]HDorillion 14 points15 points16 points 3 months ago\u00a0(1 child)Was the input, by any chance, \"Love\"\n\npermalinkembedsaveparentreportgive awardreply[\u2013]itsmybirthday19[S] 7 points8 points9 points 3 months ago\u00a0(0 children)Ha yes! \ud83d\ude0a\n\npermalinkembedsaveparentreportgive awardreply[\u2013]localkhaleesi 10 points11 points12 points 3 months ago\u00a0(1 child)Input: fuck\nVerse 1\nWhat the f**k what the f**k what the f**k?\nThe same they claim when problems pop\nTalk mess up talk mess up talk mess up\nThe same they claim when problems pop\n\nPre-Chorus\nI see the same thing all over the f**king world every single day\nI see the same thing in my women f**k the greed the fake\n\nChorus\nGet the f**k outta here woah I'm on the up\nSee I don't know about you f**k boys\nTell me you're not scared f**k that\nI really don't give a f**k about you girl\n\nVerse 2\nTurn it up and f**k the sun\nCause I know that you count on me\nAnd that's where you belong\nMake your lady wanna f**k me\n\nPre-Chorus\nDon't f**k with me no more oh I'm so cool\nDon't f**k with me no more\n\nChorus\nGet the f**k outta here woah I'm on the up\nSee I don't know about you f**k boys\nTell me you're not scared f**k that\nI really don't give a f**k about you girl\n\nBridge\nI'm tall as f**k but I don't lack\nI f**k with fly b***hes\n\nChorus\nGet the f**k outta here woah I'm on the up\nSee I don't know about you f**k boys\nTell me you're not scared f**k that\nI really don't give a f**k about you girl\n\nthis is amazing.\n\npermalinkembedsavereportgive awardreply[\u2013]crikeydilehunter 5 points6 points7 points 3 months ago\u00a0(0 children)Speaking the language of the gods\n\npermalinkembedsaveparentreportgive awardreply[\u2013]the_zword 9 points10 points11 points 3 months ago\u00a0(1 child)This is my new favorite way to pass time.\n\npermalinkembedsavereportgive awardreply[\u2013]itsmybirthday19[S] 4 points5 points6 points 3 months ago\u00a0(0 children)Ha great to hear! \ud83d\ude01\n\npermalinkembedsaveparentreportgive awardreply[\u2013]lily9423 6 points7 points8 points 3 months ago*\u00a0(0 children)One thought about generating lyrics with consistent theme \u2014 repetition of the topic word is a good start, but could extend to a set of relative \/ peripheral words, and further a storyline!! Think about writing a poem, we could express a topic from different perspectives.  Not sure how your algorithm works but I\u2019d suggest the above.\nAlso curious about if there\u2019s any quantitative metric of evaluating the quality of generated lyrics?\n\npermalinkembedsavereportgive awardreply[\u2013]vincefav 4 points5 points6 points 3 months ago*\u00a0(0 children)I've been working on this myself! How low were you able to get your loss during training? I'm stuck around 1.80 right now with 10,000 songs, and lowering the learning rate doesn't seem to help. Any tips?\nI implemented a few interesting features along the way and I'd be happy to share them.\n\npermalinkembedsavereportgive awardreply[\u2013]poindexter_one 4 points5 points6 points 3 months ago\u00a0(0 children)Amusing Cheese.  (c) 2019 all rights reserved.\nAll I wanted was the cheese\nOf a boy who had it all and wants to go back\nAnd I'll be caught at sea\nWhen you cheese you you always be inside so tight that you gotta bring me paper\nPre-Chorus\nAnd he looked at me as though I were a piece of cheese\nSpit in cheese how could it go wrong\nWho would own the rights to AI generated creative work? The first lawsuit will be \ud83d\ude02\n\npermalinkembedsavereportgive awardreply[\u2013]OPMaster494 4 points5 points6 points 3 months ago\u00a0(1 child)Amazing! Looking forward to more cool projects you\u2019ve got!\n\npermalinkembedsavereportgive awardreply[\u2013]itsmybirthday19[S] 1 point2 points3 points 3 months ago*\u00a0(0 children)Thanks man! \ud83d\ude0e\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Brudaks 3 points4 points5 points 3 months ago\u00a0(3 children)The text are nice and inspiring, but currently it's \"lyrics\" mainly because of the imposed line\/verse\/chorus structure, but If I'm thinking on how to put these words to some random music, then it's very hard to get any rhythm working.\nSo my main suggestion for improvement would be to do some filtering based on syllable count or something like that; i.e. if you have two lines of five syllables then don't put a ten-syllable third line, regenerate it until you get something shorter.\n\npermalinkembedsavereportgive awardreply[\u2013]itsmybirthday19[S] 2 points3 points4 points 3 months ago\u00a0(2 children)Thanks heaps for your feedback\nYes, I am with another project that is working on melody creation (aka HookGen.com)\nI am currently working on syllable count, you can then select if you want solfege (i.e. movable do or fixed do)\nI am currently training on two separate RTX 2080 Tis; which are doing separate experiments to create new beats\nThe idea is that the three projects; melody + lyrics + beat will join together by 2020\nCurrently I generated this song entirely with AI; if you DM me your email I can keep you updated\nLink: https:\/\/soundcloud.com\/djanotherplanet\/be-mine\n\npermalinkembedsaveparentreportgive awardreply[\u2013]kayvane 1 point2 points3 points 3 months ago\u00a0(0 children)Very Impressive!! Do you generate multiple midi\u2019s an overlay them? Or do you have a more complex network which takes inputs from multiple sequences (instruments) to generate the next note?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]LifeFeedback 0 points1 point2 points 3 months ago\u00a0(0 children)Can you say where do you get your dataset? :P\n\npermalinkembedsaveparentreportgive awardreply[\u2013]anor_wondo 2 points3 points4 points 3 months ago\u00a0(0 children)some of it sounds like nier automata robots\n\npermalinkembedsavereportgive awardreply[\u2013][deleted] 3 months ago*\u00a0(1 child)[deleted]\n\n[\u2013][deleted] 1 point2 points3 points 3 months ago\u00a0(0 children)early Swans\n\npermalinkembedsavereportreply[\u2013]BubbyMk2 2 points3 points4 points 3 months ago\u00a0(0 children)Wow, this looks really awesome! I love the idea, and full song generation seems doable (melody + lyrics + beat). The melody generation you've got going on over at HookGen seems really well done, too :)\nCan you provide any details of the network running under the hood? Are you directly using a pretrained model (GPT2, BERT, XLNet, etc.) + fine tuning autoregressively on lyrics, or is there something more complex going on? \nAlso, I saw you're planning on improving with longer training + 17x more data. Are you able to give any info on what that currently looks like? ie. how much data you're using + how long you're training on your 2080Tis?\n\npermalinkembedsavereportgive awardreply[\u2013]SOSRihanna 2 points3 points4 points 3 months ago\u00a0(1 child)\n[removed]\n\nWhy did you remove the text of the post? What's the link?\n\npermalinkembedsavereportgive awardreply[\u2013]itsmybirthday19[S] 1 point2 points3 points 3 months ago\u00a0(0 children)Shows up for me? https:\/\/theselyricsdonotexist.com\/\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sgxadhith 1 point2 points3 points 3 months ago\u00a0(1 child)Amazing!\n\npermalinkembedsavereportgive awardreply[\u2013]itsmybirthday19[S] 0 points1 point2 points 3 months ago\u00a0(0 children)Thanks \ud83d\ude0a\n\npermalinkembedsaveparentreportgive awardreply[\u2013][deleted] 1 point2 points3 points 3 months ago\u00a0(2 children)Shark, housework and death came up with nothing....\n\npermalinkembedsavereportreply[\u2013]itsmybirthday19[S] 3 points4 points5 points 3 months ago\u00a0(1 child)yep, I banned a bunch of words including \"death\", \"murder\", \"kill\" and the \"n\" word etc\n\npermalinkembedsaveparentreportgive awardreply[\u2013][deleted] 4 points5 points6 points 3 months ago\u00a0(0 children)I keep looking for a song to motivate me to do housework. Still has yet to be created.\n\npermalinkembedsaveparentreportreply[\u2013][deleted] 1 point2 points3 points 3 months ago\u00a0(0 children)Topic: Pain\nVerse 1\nBut less was love and more was pain\nAnd you're never like the perfect one\nLike the fool who made this fight\nIf you are deep in pain\n\nPre-Chorus\nYou don't have to feel the pain.\nI'll be there to make sure you feel the pain. <- Best part\n\nChorus\nGive me every kind of pain\nAnd it's an endless road no matter how I try\nTrust in me I will ease your pain\nAll the cares and all the pain\n\nVerse 2\nSorrow is a friend for those who can't face the pain\nSometimes you've got to rise above to survive the freeze of life.\nTill I cannot see your pretty face around me\nI can't hold your hand to make you understand my pain\n\nPre-Chorus\nThough it brings me such pain if I think of what I could do\nYou would still feel the pain of having never had enough\n\nChorus\nGive me every kind of pain\nAnd it's an endless road no matter how I try\nTrust in me I will ease your pain\nAll the cares and all the pain\n\nBridge\nWith a paint that never can wash away\nIt's the pain they feel in small moments\n\nChorus\nGive me every kind of pain\nAnd it's an endless road no matter how I try\nTrust in me I will ease your pain\nAll the cares and all the pain\n\n\npermalinkembedsavereportreply[\u2013]DaddySatoshi 1 point2 points3 points 3 months ago\u00a0(0 children)input: france\noutput:\nVerse 1\n Well she's confused now isn't France?\n How can you say something's a shame?\n I'll be your shelter from the storm\n France waited for me her girl is now all mine  \nPre-Chorus\n Well she's out on the highway\n And if by chance France should meet another  \nChorus\n She's the kind I was hoping for\n France sings I am sitting still\n And France likes the way France feels inside\n Ever since France told me France was  \nVerse 2\n France come down from the stars late night\n France comes down from the stars late night\n Now I can feel this evening cold\n And France believe that she's already been this kind  \nPre-Chorus\n With skin so pale France could be white\n France stayed out all night long  \nChorus\n She's the kind I was hoping for\n France sings I am sitting still\n And France likes the way France feels inside\n Ever since France told me France was  \nBridge\n France will stay with you\n France won't leave you no no  \nChorus\n She's the kind I was hoping for\n France sings I am sitting still\n And France likes the way France feels inside\n Ever since France told me France was\n\npermalinkembedsavereportgive awardreply[\u2013]semikore 1 point2 points3 points 3 months ago\u00a0(0 children)No results with 'gruesome deaths' and 'surgical procedure' :( I guess I'll have to write my own lyrics for my metal band ...\n\npermalinkembedsavereportgive awardreply[\u2013]occasionalupvote 1 point2 points3 points 3 months ago\u00a0(0 children)Chorus\nGot my ass in it you know what I mean\nLike f**k that we just drink ya ass from the window\nLike f**k that we just drink ya ass from the window\nLike f**k that we just drink ya ass from the window\n\n\npermalinkembedsavereportgive awardreply[\u2013]Gardrothard 1 point2 points3 points 3 months ago\u00a0(0 children)Awesome! Great job!\n\npermalinkembedsavereportgive awardreply[\u2013]KayNora 1 point2 points3 points 3 months ago\u00a0(0 children)Simply amazing!\n\npermalinkembedsavereportgive awardreply[\u2013]frequenttimetraveler 1 point2 points3 points 3 months ago\u00a0(0 children)Awesome!. Man you just need to train it to output chords on top of the verses will be hilarious.\n\npermalinkembedsavereportgive awardreply[\u2013]gorillaSpices 1 point2 points3 points 3 months ago\u00a0(0 children)Type in Obama..\n\npermalinkembedsavereportgive awardreply[\u2013]bagi45654 1 point2 points3 points 3 months ago\u00a0(0 children)Input weed\n<pre>\nVerse 1\nBut you don't have to weed your life or you won't\nBut you don't have to smoke just make the feeling stay\nI must for my nation\nHit him with this weed\nPre-Chorus\nI see the weed I don't need the shot\nI'll be the flowers after you weed me out\nChorus\nLook out I got kids\nLook out I got weed\nLook out I got kids\nLook out I got weed\nVerse 2\nDon't roll no weed on the floor\nAnd I dont gotta sell weed to get burnt\nWhat's that I hear now you're right here\nWhat's that I hear now I feel so proud\nPre-Chorus\nI got weed? I got weed in my pocket\nSo I grow mine in a little shade\nChorus\nLook out I got kids\nLook out I got weed\nLook out I got kids\nLook out I got weed\nBridge\nGrowing like a weed without flowers\nGrowing like a weed without weather\nChorus\nLook out I got kids\nLook out I got weed\nLook out I got kids\nLook out I got weed\nResult #4340\nGenerated using TheseLyricsDoNotExist.com\n<\/pre>\n\npermalinkembedsavereportgive awardreply[\u2013]not_personal_choice 1 point2 points3 points 3 months ago\u00a0(0 children)The author has confused eneutions about beer\nVerse 1\nI wouldn't care whose \ud83c\udf7a I drink\nAs long as somebody somewhere has fun.\nIf fun is what you're looking for\nWe weren't gonna drink no \ud83c\udf7a  \nPre-Chorus\nHere come the boys with the wild \ud83c\udf7a fighting\nConstant to hate \ud83c\udf7a and silver and gold  \nChorus\nIt's like throwing a ball that leaves a trail of \ud83c\udf7a\nIt's like throwing a ball that leaves a trail of \ud83c\udf7a\nI'll be your hope I'll be your light I'll be the one you reach\nWhen you need to reach.  \nVerse 2\nWell my old head momma said that drinking \ud83c\udf7a\nIs not the way that a good man should act\nI'm wrong I'm wrong and that's all right with me\nI want to buy you a \ud83c\udf7a  \nPre-Chorus\nNot a drug or a \ud83c\udf7a\nWe've got cocaine and pills and \ud83c\udf7a  \nChorus\nIt's like throwing a ball that leaves a trail of \ud83c\udf7a\nIt's like throwing a ball that leaves a trail of \ud83c\udf7a\nI'll be your hope I'll be your light I'll be the one you reach\nWhen you need to reach.  \nBridge\nOne more \ud83c\udf7a and I'll be in no state to do the things I think I need to\nWasn't this \ud83c\udf7a drinking dog the one's that had to always run  \nChorus\nIt's like throwing a ball that leaves a trail of \ud83c\udf7a\nIt's like throwing a ball that leaves a trail of \ud83c\udf7a\nI'll be your hope I'll be your light I'll be the one you reach\nWhen you need to reach.\n\npermalinkembedsavereportgive awardreply[\u2013]turbod33 1 point2 points3 points 3 months ago\u00a0(0 children)Well they exist, now.\n\npermalinkembedsavereportgive awardreply[\u2013]preemptive_regret 1 point2 points3 points 3 months ago\u00a0(0 children)This is absolutely hilarious. Sent to all my friends and family and we are having the best time with it. Thanks for sharing!\n\npermalinkembedsavereportgive awardreply[\u2013]ledewde_ 1 point2 points3 points 3 months ago\u00a0(0 children)Verse 1\nThe beach is moving but not so slowly\nWhen it's just you and no one else to talk to\nWho wants to sit and talk\nHe is with us on the beach\nPre-Chorus\nAnd its saturday morning and its his moms out on the beach\nAnd then I asked him what we were doing on the beach\nChorus\nYou might see us on the beach\nI might start to freak out\nYou're getting what you can't have.\nI was born in the valley of bullshit diamond beach\nVerse 2\nCome and dance in the beach 'til the break of dawn\nBaby I'll be riding baby with the pages in the page\nCome and dance in the beach 'til the break of dawn\nYou know I feel it coming on\nPre-Chorus\nThe beach and drink till drunk\nSaturday I'll probably spend some time at the beach\nChorus\nYou might see us on the beach\nI might start to freak out\nYou're getting what you can't have.\nI was born in the valley of bullshit diamond beach\nBridge\nI'm that girl you used to see at the beach\nWhere we used to hang out\nChorus\nYou might see us on the beach\nI might start to freak out\nYou're getting what you can't have.\nI was born in the valley of bullshit diamond beach\n\npermalinkembedsavereportgive awardreply[\u2013]usehand 0 points1 point2 points 3 months ago\u00a0(0 children)What kind of model are you using here? Is it GPT-2?\n\npermalinkembedsavereportgive awardreply[\u2013]jetcoff 0 points1 point2 points 3 months ago\u00a0(0 children)Total noob question, but did you write the songwriter in Python or JavaScript? If Python, how did you add the generator to a web page.\n\npermalinkembedsavereportgive awardreply[\u2013]dsengupta16 0 points1 point2 points 3 months ago\u00a0(0 children)Wonderful man. This is what real learning should be about. At the end you should be able to experience the joy of building something by your own hands and intellect.\n\npermalinkembedsavereportgive awardreply[\u2013]lostmsu -1 points0 points1 point 3 months ago\u00a0(0 children)http:\/\/billion.dev.losttech.software:2095\/song\/1070353314\n\npermalinkembedsavereportgive awardreply[\u2013]juancamilog -5 points-4 points-3 points 3 months ago\u00a0(2 children)sorry to poop on your party, but these are not completely original.\n\npermalinkembedsavereportgive awardreply[\u2013]vineetk1998 -1 points0 points1 point 3 months ago\u00a0(0 children)and they doesn't make any sense\n\npermalinkembedsaveparentreportgive awardreply[+][deleted] 3 months ago\u00a0(1 child)[deleted]\n\n[\u2013]carlthome 2 points3 points4 points 3 months ago\u00a0(0 children)You have to open your mind to the idea that some big ass God shit is a youthful way of referring to romantic love. Peace.\n\npermalinkembedsavereportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 20214 on  r2-app-0682b52d812d1f207  at 2019-11-22 00:16:22.126919+00:00 running bbb69ca country code: US."
  },
  "35":{
    "title":"[N] Open-Unmix for Music Separation : MachineLearning",
    "body":"jump to contentmy subredditsedit subscriptionspopular-all-random-users\u00a0|\u00a0news-AskReddit-funny-gifs-worldnews-gaming-todayilearned-pics-aww-Showerthoughts-tifu-videos-personalfinance-dataisbeautiful-movies-nottheonion-TwoXChromosomes-Jokes-mildlyinteresting-sports-television-OldSchoolCool-IAmA-LifeProTips-science-books-explainlikeimfive-EarthPorn-nosleep-UpliftingNews-GetMotivated-askscience-space-Art-WritingPrompts-history-food-Futurology-photoshopbattles-Music-DIY-creepy-gadgets-Documentaries-philosophy-listentothis-announcements-InternetIsBeautiful-blogmore \u00bb\u00a0MachineLearningcommentsother discussions (1)Want to join? Log in or sign up in seconds.|Englishlimit my search to r\/MachineLearninguse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...this post was submitted on  12 Sep 201979 points (94% upvoted)shortlink:  remember mereset passwordloginSubmit a new linkSubmit a new text postGet an ad-free experience with special benefits, and directly support Reddit.get reddit premiumMachineLearningjoinleave822,214 readers2,046 users here nowRules For Posts\n+Research\n+Discussion\n+Project\n+News\n@slashML on Twitter\nChat with us on Slack\nBeginners:\nPlease have a look at our FAQ and Link-Collection\nMetacademy is a great resource which compiles lesson plans on popular machine learning topics.\nFor Beginner questions please try \/r\/LearnMachineLearning , \/r\/MLQuestions or http:\/\/stackoverflow.com\/\nFor career related questions, visit \/r\/cscareerquestions\/\n\nAdvanced Courses\n\nAMAs:\nPluribus Poker AI Team 7\/19\/2019\nDeepMind AlphaStar team (1\/24\/\/2019)\nLibratus Poker AI Team (12\/18\/2017)\nDeepMind AlphaGo Team (10\/19\/2017)\nGoogle Brain Team (9\/17\/2017)\nGoogle Brain Team (8\/11\/2016)\nThe MalariaSpot Team (2\/6\/2016)\nOpenAI Research Team (1\/9\/2016)\nNando de Freitas (12\/26\/2015)\nAndrew Ng and Adam Coates (4\/15\/2015)\nJ\u00fcrgen Schmidhuber (3\/4\/2015)\nGeoffrey Hinton (11\/10\/2014)\nMichael Jordan (9\/10\/2014)\nYann LeCun (5\/15\/2014)\nYoshua Bengio (2\/27\/2014)\n\nRelated Subreddit :\n\nLearnMachineLearning\nStatistics\nComputer Vision\nCompressive Sensing\nNLP\nML Questions\n\/r\/MLjobs and \/r\/BigDataJobs\n\/r\/datacleaning\n\/r\/DataScience\n\/r\/scientificresearch\n\/r\/artificial\n\n\ncreated by kunjaana community for 10 yearsmessage the moderatorsMODERATORSkunjaancavedavenaiveolaf_nijBeatLeJuceMTGTranerHD Hlynssonabout moderation team \u00bbdiscussions in r\/MachineLearning<>X34  \u00b7 9 comments [P] WindHive: ML based coding assistant to boost coding productivity32  \u00b7 5 comments [R] EfficientDet: Scalable and Efficient Object Detection162  \u00b7 32 comments [D] Why does hierarchical Bayesian regression work well on imbalanced data?4  \u00b7 2 comments [D] Uncertainty estimation in DL5 [D] An Open Source Stack for Managing and Deploying ML Models - DVC & Cortex - Tutorial[D] What are some interesting questions we can answer using AI?\u00b7 1 comment [R] Deep neuroethology of a virtual rodent[N] How to convert a NN model from TensorFlow Lite to CoreML9  \u00b7 12 comments [D] Voice Assistant: Better to use a model trained on commands or just use STT?9  \u00b7 6 comments [P] OpenAI Safety GymWelcome to Reddit,the front page of the internet.Become a Redditorand join one of thousands of communities.\u00d7787980News[N] Open-Unmix for Music Separation (self.MachineLearning)submitted 2 months ago by faroit\ud83d\udcdcPaper: https:\/\/joss.theoj.org\/papers\/571753bc54c5d6dd36382c3d801de41d\n\ud83d\udd0aDemo: https:\/\/open.unmix.app\n\ud83d\udd25PyTorch: https:\/\/github.com\/sigsep\/open-unmix-pytorch\n\ud83d\udd3bNNabla: https:\/\/github.com\/sigsep\/open-unmix-nnabla\n\ud83d\udd36TF2: t.b.a.\n\ud83d\udcd3Colab: https:\/\/colab.research.google.com\/drive\/1mijF0zGWxN-KaxTnd0q6hayAlrID5fEQ \nIt is our great pleasure to announce the release of Open-unmix, a MIT-licensed python implementation for DNN-based music separation.\nIn the recent years, deep learning-based systems could break a long-standing crystal ceiling, and finally allow high-quality music separation. This provoked a raising interest from both the industry and the machine learning community (like \/r\/ML)\nHowever, until now, no open-source implementation was available that matches the performance of the best systems proposed more than four years ago. This lead to a waste of time from both the points of view of sheer performance optimization and scientific comparison with the state of the art. Not being able to reproduce state of the art performance makes it difficult to clearly identify the sources for discrepancies and rooms for improvement.\nIn this context, we release Open-Unmix (UMX) as closing this gap by providing a reference implementation for DNN-based music separation. It serves two main purposes. First, it is intended to academic researchers for serving as a baseline method that is easy to compare to and build upon. Second, the availability of a pre-trained model allows bringing music separation to the enthusiastic end users and artists.\nPaper\nOpen-unmix is presented in a paper that has just been published in the Journal of Open Source Software. You may download the paper PDF here\nCode\nOpen-unmix comes in several DNN frameworks:\n\nPytorch\nNNabla\ntensorflow version will be released as soon as Tensorflow 2.0 is out.\n\nWebsite\n\nwe provide extend documentation and further demos on the sigsep website.\n\nhttps:\/\/sigsep.github.io\/open-unmix\/\nDatasets\nOpen-unmix has been especially designed to combine well with the following datasets:\n\nMUSDB18 has become one of the most popular dataset in Source Separation and MIR. We provide full lengths music tracks (~10h duration) of different genres along with their isolated drums, bass, vocals and others stems.\nMUSDB18-HQ: together with Open-Unmix, we also released an additional flavor of the dataset for models that aim to predict high bandwidth of up to 22 kHz. Other than that, MUSDB18-HQ is identical to MUSDB18.\n\n=> Both datasets are available at https:\/\/sigsep.github.io\/datasets\/musdb.html\n\nOpen-unmix also offers a variety of template dataset structures that should be appropriate for many other use cases\n\nNote:\nIf you want to compare separation models to existing source separation literature or if want compare to SiSEC 2018 participants, please use the standard MUSDB18 dataset, instead.\nPre-trained models\nWe provide pre-trained models trained on both MUSDB18 and MUSDB18-HQ that reach state-of-the-art performance of 6.32 dB SDR (median of medians) on vocals on MUSDB18 test data. This significantly outperforms any model we are aware of that was trained on MUSDB18 only.\nThe pre-trained models are automatically bundled\/downloaded when using the pytorch implementation.\nFurther information for both models such as evaluation scores can be downloaded from zenodo:\n\numx: https:\/\/doi.org\/10.5281\/zenodo.3370486\numxhq: https:\/\/doi.org\/10.5281\/zenodo.3370489\n\nTutorial\nOpen-unmix was recently proposed during a tutorial held at EUSIPCO 2019. This features:\n\nA recent overview into current source separation method with a focus on deep learning\nA lecture on spectrogram models and wiener filtering\nVisualizations and results of Open-Unmix compared to state-of-the-art\n\nThe slides of the tutorial as well as self-contained colab notebooks can be found on the tutorial site.\nRelated tools\nOpen-unmix is part of a whole ecosystem enabling easy research on source separation for Python users. Several distinct and independent projects were released in the recent years in this effort to make it possible for researchers to reproduce state of the art performance in this domain.\nnorbert\nA reliable python package that implements the multichannel wiener filter and related filtering methods.\nhttps:\/\/github.com\/sigsep\/norbert\nmusdb\nWe released the new version 0.3.0 of our popular musdb tools. This releases makes it simpler to use musdb inside your data loading framework thus we pro\nhttps:\/\/github.com\/sigsep\/sigsep-mus-db\nmuseval\nmuseval makes it easy to compare the performance of any new method under investigation to both Open-unmix and the participants of SiSEC18.\nhttps:\/\/github.com\/sigsep\/sigsep-mus-eval\nUMX-Pro\nPlease note that we are also working on some version of open-unmix that has been trained on a significantly larger dataset and that achieves unprecedented separation performance. Please feel free to contact us for demonstrations \/ industrial collaborations \/ licensing on this matter.\nWe look forward to your feedback and we hope that you will find Open-unmix useful!\n\n11 commentssharesavehidereportall 11 commentssorted by: besttopnewcontroversialoldrandomq&alive (beta)Want to add to the discussion?Post a comment!Create an account[\u2013]hakantakiri 2 points3 points4 points 2 months ago\u00a0(1 child)Awesome! I'll play with it for hours. Just to point out a little error: your inference.md  reference in \"Using the PyTorch version\" section is giving a 404 error\n\npermalinkembedsavereportgive awardreply[\u2013]faroit[S] 0 points1 point2 points 2 months ago\u00a0(0 children)thanks for the pointer. I just fixed the dead link\n\npermalinkembedsaveparentreportgive awardreply[\u2013]data-alchemy 0 points1 point2 points 2 months ago\u00a0(1 child)I've been giving it a try. As a humble engineer and as a musician, results are just impressive. Some songs may not work properly if (I guess) they are too far away from the original dataset, but some extracts are nearly perfect.\nRemix as an art is going to know a new era :)\n\npermalinkembedsavereportgive awardreply[\u2013]faroit[S] 1 point2 points3 points 2 months ago\u00a0(0 children)thanks. We would actually like to share more commercial tracks. Do you know what would be the best place to share exerpts of separated tracks? youtube? soundcloud?\n\npermalinkembedsaveparentreportgive awardreply[\u2013]sicp4lyfe 0 points1 point2 points 2 months ago\u00a0(1 child)Very nice. Can your algorithm work online or does inference need to process the whole song?\n\npermalinkembedsavereportgive awardreply[\u2013]faroit[S] 1 point2 points3 points 2 months ago\u00a0(0 children)the model has a parameter that allows to do inference online. However the pre-trained model we released (umx and umxhq) is using information from the full track because that does slightly improve the quality\n\npermalinkembedsaveparentreportgive awardreply[\u2013]Maplernothaxor 0 points1 point2 points 2 months ago\u00a0(1 child)How long does the notebook YouTube example take to run? Been running it on the provided video and it hasn\u2019t produced results in an hour.\n\npermalinkembedsavereportgive awardreply[\u2013]faroit[S] 0 points1 point2 points 2 months ago\u00a0(0 children)Hi. Thanks for your feedback. I just testet it again (using the GPU kernel). The 30s REM track took less than 10s to process. You might want to watch if the kernel has crashed. That happens sometimes\n\npermalinkembedsaveparentreportgive awardreply[\u2013]ChapDDR 0 points1 point2 points 1 month ago\u00a0(1 child)I am looking into speech\/music separation to use in for example tv-shows.\nWhile the paper and examples mainly try to obtain separate instruments from the mixture, could this model also be trained to separate normal (acted) speech and music from noisy movie audio? Or should I use a more generic speech separation algorithm?\n\npermalinkembedsavereportgive awardreply[\u2013]faroit[S] 0 points1 point2 points 1 month ago\u00a0(0 children)open-unmix is only trained on singing voice. While this is still a valid task in a broadcasting scenario, I would recommend to try a speech separation first.\n\npermalinkembedsaveparentreportgive awardreplyaboutblogaboutadvertisingcareershelpsite rulesReddit help centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2019 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.Advertise - technology\u03c0\u00a0Rendered by PID 28149 on  r2-app-0d52253d52c07e3b5  at 2019-11-22 15:40:58.350770+00:00 running 611e8fd country code: US."
  }
}